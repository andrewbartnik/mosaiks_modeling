{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe56655",
   "metadata": {},
   "source": [
    "# Modeling Crop Yield\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4f19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import geopandas\n",
    "\n",
    "import pyarrow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f0e8f",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "#### Choose a satellite.\n",
    "\n",
    "For a description of the Landsat 8 mission, see the US Geological metadata [here.]()\n",
    "\n",
    "For a description of the Sentinel 2 mission, see the US Geological metadata [here.]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb13001c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "satellite = \"landsat-8-c2-l2\"\n",
    "# satellite = \"sentinel-2-l2a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ab70e",
   "metadata": {},
   "source": [
    "#### Choose band combination.\n",
    "\n",
    "For a description of **Landsat** bands, see the [US Geological Survey documentation here.](https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites)\n",
    "\n",
    "For a description of **Sentinel bands**, see the [US Geological Survey documentation here.](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-sentinel-2#:~:text=4%20bands%20at%2010%20meter,%2Dinfrared%20(842%20nm)\n",
    "\n",
    "According to our results, bands **(insert band selection here)** result in the best model performance for Landsat, and **(insert band selection here)** result in the best model performance for Sentinel for the task of predicting maize yields in Zambia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6155e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sentinel 2 bands\n",
    "# bands = \"2-3-4\"\n",
    "# bands = \"2-3-4-8\"\n",
    "# bands = \"2-3-4-5-6-7-8-11-12\"\n",
    "\n",
    "#### Landsat 8 bands\n",
    "bands = \"1-2-3-4-5-6-7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ecb9d",
   "metadata": {},
   "source": [
    "#### Choose the number of points that were featurized.\n",
    "\n",
    "Each value in the following chunk represents the amount of thousands of points that were featurized in each respective feature file. These points represent a uniform subset of the spatial grid of Zambia. Points are spaced at uniform intervals for each selection, measured in kilometers in the longitudinal direction for each set of features. The kilometer distance interval differs for each selection below; 42,000 points results in the smallest uniform distance between points, and 4,000 points results in the greatest uniform distance between points. Selecting a greater quantity of points results in a denser spatial sample, which increases computational cost and time, but increases the spatial resolution of the model. Regardless of the quantity of points selected, each point is buffered by the same distance, resulting in a 1km^2 cell around each point.\n",
    "\n",
    "These specific options point quantities is a result of uniformly increasing the distance between points in units of kilometers prior to matching satellite images to each point. These options represent the number of points that fall within the borders of Zambia, and the numbers have been rounded to the nearest thousandth for consistency in naming files. See the [CropMOSAIKS Featurization repository](https://github.com/cropmosaiks/Featurization) for more information regarding how these distances we calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a903025",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 15\n",
    "# points = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b135301",
   "metadata": {},
   "source": [
    "#### Choose to keep only areas with crops (`True`) or to keep all points (`False`)\n",
    "\n",
    "Selecting `True` applies a \"cropland mask\" to the spatial grid of Zambia. This retains only the regions of the country in which maize is  grown, according to the **(insert source here)**. As a result, the spatial extent of the features that are fed into the model are highly subset for the specific task at hand: modeling maize yields. According to our results, selecting `True` **(insert increases or decreases here)** model performance.\n",
    "\n",
    "Selecting `False` results in modeling with the maximum spatial extent of the features, with more generalized features as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def9380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_mask = True\n",
    "crop_mask = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede5fbb",
   "metadata": {},
   "source": [
    "Choose a weighted average (`True`) or a simple mean (`False`) to use when collapsing features to administrative boundary level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccb6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_avg = True\n",
    "weighted_avg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0aad3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Choose which months to use in the model.\n",
    "\n",
    "Note that months 10, 11, and 12 get pushed to the next year because the growing season (November - May) spans the calendar year. Maize is planted in November, starts to change color with maturity in May, and is harvested in June - August. According to our results, subsetting the months to **(insert month selection here)** increases model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1a5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "month_range = [         4, 5, 6, 7, 8, 9            ]\n",
    "\n",
    "# month_range = [      3, 4, 5, 6, 7, 8, 9            ]\n",
    "# month_range = [            5, 6, 7, 8, 9            ]\n",
    "# month_range = [         4, 5, 6, 7, 8               ]\n",
    "# month_range = [            5, 6, 7, 8               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15b7c5",
   "metadata": {},
   "source": [
    "#### Impute NA values by descending group levels (True) or `scikit learn`'s simple imputer (False)\n",
    "\n",
    "Imputing \"manually\" by descending group levels imputes NA values in multiple \"cascading\" steps, decreasing the proportion of inoutated values with each step. First, the NA values are imputed at by both `year` and `district`, which should yield imputed values that most closely match the feature values that would be present in the data if there was no clouds obscuring the satellite images. Next, the remaining NA values that could not be imputed by both `year` and `district` are imputed by only `district`. Lastly, the remaining NA vlaues that could not be imputed by both `year` and `district` or by just `district` are imputed by `year` only. This option gives the user more control and transparency over how the imputation is executed.\n",
    "\n",
    "Imputing using `scikit learn`'s simple imputer executes standard imputation, the details of which can be found in the `scikitlearn` documentation [here.](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9662e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_manual = True\n",
    "# impute_manual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1779b1fa-929e-41a9-a83b-c9023a6832bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_2013 = True\n",
    "# include_2013 = False\n",
    "\n",
    "if include_2013 & (satellite == \"landsat-8-c2-l2\") & (month_range == [4, 5, 6, 7, 8, 9]):\n",
    "    month_start = 4\n",
    "else:\n",
    "    month_start = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06291c4",
   "metadata": {},
   "source": [
    "### Unchanging parmaters\n",
    "\n",
    "The parameters in the following chunk are set for the country of Zambia for with 1000 features, regardless of the satellite selected. The start years for each satellite reflect the respective years that Landsat 8 and Sentinel 2A missions began.\n",
    "\n",
    "The number of features is set to 1000 to serve as a staple parameter among the several other parameters varied during the model optimization process. Changing this parameter in the following code chunk will result in an error because featurizing landsat imagery for a different number of features was outside the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026f29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = \"ZMB\"\n",
    "num_features = 1000\n",
    "\n",
    "if satellite == \"landsat-8-c2-l2\":\n",
    "    year_start = 2013 # Landsat\n",
    "else:\n",
    "    year_start = 2015 # Sentinel\n",
    "    \n",
    "year_end = 2019\n",
    "year_end_crops = 2019\n",
    "\n",
    "data_dir = \"/capstone/mosaiks/data\"  \n",
    "# data_dir = \"data\"  \n",
    "feature_file_name = (f'{satellite}_bands-{bands}_{country_code}_{points}k-points_{num_features}-features')\n",
    "weight_file_name = (f'{country_code}_crop_weights_{points}k-points')\n",
    "\n",
    "if points == \"4\":\n",
    "    marker_sz = 60\n",
    "elif points == \"15\":\n",
    "    marker_sz = 15\n",
    "elif points == \"24\":\n",
    "    marker_sz = 10\n",
    "else:\n",
    "    marker_sz = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6bb69",
   "metadata": {},
   "source": [
    "## Administrative boundaries \n",
    "\n",
    "Administrative boundaries reflect the **(insert number of districts in dataset)** district boundaries within the country of Zambia. A district can be likened to a state within the larger U.S.A. We subset the spatial grid to district level becuase the crop yield data is at the district level of specificity. The features are originally produced at higher spatial resolution, then summarized to the district level in order to train the model with ground-truth crop data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28fd026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /Users/hveirs/.conda/envs/mosaiks/share/proj failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"fiona/ogrext.pyx\", line 136, in fiona.ogrext.gdal_open_vector\n",
      "  File \"fiona/_err.pyx\", line 291, in fiona._err.exc_wrap_pointer\n",
      "fiona._err.CPLE_OpenFailedError: /capstone/cropmosaiks/data/boundaries/gadm36_ZMB_2.shp: No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21538/2670892063.py\", line 1, in <module>\n",
      "    country_shp = geopandas.read_file(f'{data_dir}/boundaries/gadm36_{country_code}_2.shp')\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/geopandas/io/file.py\", line 259, in _read_file\n",
      "    return _read_file_fiona(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/geopandas/io/file.py\", line 303, in _read_file_fiona\n",
      "    with reader(path_or_bytes, **kwargs) as features:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/fiona/env.py\", line 457, in wrapper\n",
      "    return f(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/fiona/__init__.py\", line 335, in open\n",
      "    colxn = Collection(\n",
      "            ^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/fiona/collection.py\", line 234, in __init__\n",
      "    self.session.start(self, **kwargs)\n",
      "  File \"fiona/ogrext.pyx\", line 587, in fiona.ogrext.Session.start\n",
      "  File \"fiona/ogrext.pyx\", line 143, in fiona.ogrext.gdal_open_vector\n",
      "fiona.errors.DriverError: /capstone/cropmosaiks/data/boundaries/gadm36_ZMB_2.shp: No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1049, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1003, in get_records\n",
      "    lines, first = inspect.getsourcelines(etb.tb_frame)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/inspect.py\", line 1252, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hveirs/.conda/envs/mosaiks/lib/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "country_shp = geopandas.read_file(f'{data_dir}/boundaries/gadm36_{country_code}_2.shp')\n",
    "country_shp = country_shp.rename(columns = {'NAME_2': 'district'})[['district', 'geometry']]\n",
    "country_shp.district = country_shp.district.replace(\"MPongwe\", 'Mpongwe', regex=True)\n",
    "country_districts = country_shp.district.sort_values().unique().tolist()\n",
    "country_shp = country_shp.set_index('district')\n",
    "country_shp.shape\n",
    "country_shp.plot(figsize = (12,10), linewidth = 1, edgecolor = 'black' )\n",
    "# country_shp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ba4ec",
   "metadata": {},
   "source": [
    "## Crop yield\n",
    "\n",
    "Zambian maize yield data reflects the predicted annual maize yield provided by farmers in the month of May, when the maize matures and changes colors prior to harvest, which allows the farmers to estimate what their yield will be in the following months. These predictions are in units of metric tons per hectare and provide valuable insight to the Zambian government as they plan for the quanitites of food to import into the country in the future. For more metadata, see the websites for the [Central Statistics Office of Zambia (CSO)](https://www.zamstats.gov.zm/) and the [Summary statistics from CSO.](https://www.zamstats.gov.zm/agriculture-environment-statistics/)\n",
    "\n",
    "In order to standardize the names of all districts shared between the geoboundaries and the crop yield data, we correct for spelling, dashes, and apostrophes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1cc9106",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/capstone/cropmosaiks/data/crops/cfs_maize_districts_zambia_2009_2018.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m crop_df_full \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/crops/cfs_maize_districts_zambia_2009_2018.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m crop_df_full \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/crops/cfs_maize_districts_zambia_2009_2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m crop_df_full \u001b[38;5;241m=\u001b[39m crop_df_full[crop_df_full\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m year_end_crops]\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/mosaiks/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/capstone/cropmosaiks/data/crops/cfs_maize_districts_zambia_2009_2018.csv'"
     ]
    }
   ],
   "source": [
    "crop_df_full = pd.read_csv(data_dir+'/crops/cfs_maize_districts_zambia_2009_2018.csv')\n",
    "crop_df_full = pd.read_csv(data_dir+'/crops/cfs_maize_districts_zambia_2009_2022.csv')\n",
    "crop_df_full = crop_df_full[crop_df_full.year <= year_end_crops]\n",
    "crop_df_full.district = crop_df_full.district.replace(\n",
    "    {\"Itezhi-tezhi\": 'Itezhi-Tezhi',\n",
    "     \"Kapiri-Mposhi\": 'Kapiri Mposhi',\n",
    "     \"Kapiri mposhi\": 'Kapiri Mposhi',\n",
    "     \"Shang'ombo\": 'Shangombo',\n",
    "     \"Chienge\": 'Chiengi'\n",
    "    }, regex=True)\n",
    "crop_districts = crop_df_full.district.sort_values().unique().tolist()\n",
    "crop_df = crop_df_full[['district', 'year', 'yield_mt']]\n",
    "ln = len(crop_df[crop_df.year == 2016].district)\n",
    "crop_df = crop_df.set_index('district')\n",
    "ln\n",
    "crop_df_full\n",
    "# crop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(crop_districts) - set(country_districts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c55cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(country_districts) - set(crop_districts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_crop = geopandas.GeoDataFrame(crop_df.join(country_shp), crs = country_shp.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace3e2f",
   "metadata": {},
   "source": [
    "## Crop land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.read_feather(f\"{data_dir}/weights/{weight_file_name}.feather\")\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_gdf = geopandas.GeoDataFrame(\n",
    "    weights, \n",
    "    geometry = geopandas.points_from_xy(x = weights.lon, y = weights.lat), \n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "weights_gdf.plot(figsize = (12,10),\n",
    "                 cmap = 'inferno',\n",
    "                 markersize = marker_sz,\n",
    "                 alpha = .9,\n",
    "                 column = 'crop_perc')\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.crop_perc = weights.crop_perc.fillna(0)\n",
    "# #weights.crop_perc = weights.crop_perc + 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa5a1f",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Append annual features files together into one file: `features_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55409ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = geopandas.GeoDataFrame()\n",
    "\n",
    "for yr in range(year_start, year_end + 1):\n",
    "    print(f\"Opening: {feature_file_name}_{yr}.feather\")\n",
    "    features_x = pd.read_feather(f\"{data_dir}/features/{satellite}/{feature_file_name}_{yr}.feather\")\n",
    "    \n",
    "    # concatenate the feather files together, axis = 0 specifies to stack rows (rather than adding columns)\n",
    "    features = pd.concat([features, features_x], axis=0)\n",
    "    \n",
    "    print(\"feature.shape\", features.shape)\n",
    "    print(\"Appending:\", yr)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294dc17-63b0-4888-a4af-1bba7047ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.where(\n",
    "    ((features.year == year_start) & \n",
    "     (features.month >= month_start)) | \n",
    "    (features.year > year_start),\n",
    "    True, False\n",
    ")\n",
    "features = features[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry months October, November, and December over to the following year's data\n",
    "# these months represent the start of the growing season for the following year's maize yield\n",
    "features['year'] = np.where(\n",
    "    features['month'].isin([10, 11, 12]),\n",
    "    features['year'] + 1, \n",
    "    features['year'])\n",
    "\n",
    "features = features[features['year'] <= year_end]\n",
    "\n",
    "features.sort_values(['year', 'month'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8539a4a",
   "metadata": {},
   "source": [
    "### Filter month range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the features to only the month range selected at the top of the notebook\n",
    "features = features[features.month.isin(month_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ff055",
   "metadata": {},
   "source": [
    "### Pivot wider\n",
    "Here we pivot the data from long format to wide by indexing on 'lon', 'lat', 'year', 'month' and using the unstack function. We then map column names based on the month index and the associated features so month '01' is appended to each feature for that month making 0_01, 1_01 etc. This results in a Tidy data structure, with each row representing an image, and each column representing a feature for a certain month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.set_index(['lon','lat', \"year\", 'month']).unstack()\n",
    "features.columns = features.columns.map(lambda x: '{}_{}'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9b16e",
   "metadata": {},
   "source": [
    "### Replace \"inf\" values with `NaN`\n",
    "\n",
    "Infinity values are the result of **(insert reason here)**. We replace them with `NaN` because **(insert reason here)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features = features.reset_index()\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a234a9c",
   "metadata": {},
   "source": [
    "### Attach crop weights\n",
    "Attach weight to each point (% area cropped of surrounding 1 km^2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(weights.set_index(['lon', 'lat']), on = ['lon', 'lat'])\n",
    "features = features.drop([\"geometry\"], axis = 1)\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3147c",
   "metadata": {},
   "source": [
    "### Mask croppped regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d65ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any 1 km^2 cell with a crop percentage > 0 will be retained\n",
    "# the mask will not be applied if crop_mask is set to False at the top of this notebook\n",
    "if crop_mask:\n",
    "    features = features[features.crop_perc > 0]\n",
    "else:\n",
    "    pass\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3acd3",
   "metadata": {},
   "source": [
    "### Make \"features\" a `GeoDataFrame`\n",
    "\n",
    "The coordinate reference system is set to EPSG 4326 - WGS 84, the latitude/longitude coordinate system based on the Earth's center of mass, used by the Global Positioning System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = geopandas.GeoDataFrame(\n",
    "    features, \n",
    "    geometry = geopandas.points_from_xy(x = features.lon, y = features.lat), \n",
    "    crs='EPSG:4326'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d6ff1",
   "metadata": {},
   "source": [
    "### Plot any single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f447f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mn = 9\n",
    "# yr = 2017\n",
    "# feature = 999\n",
    "\n",
    "# features[features.year == yr].plot(\n",
    "#     column = f\"{feature}_{mn}\",\n",
    "#     figsize = (10,10),\n",
    "#     marker='H',\n",
    "#     # legend = True,\n",
    "#     markersize = marker_sz,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66e85d",
   "metadata": {},
   "source": [
    "### Drop 'lat' and 'lon' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b47a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant independent lon and lat columns now that they are in a geometry column\n",
    "features = features.drop(['lon', 'lat'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c25e0",
   "metadata": {},
   "source": [
    "### Join features to country geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fba002",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sjoin(country_shp, how = 'left', predicate = 'within')\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c217e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# na = features[adm_features.isna().any(axis = 1)]\n",
    "# na.plot(figsize = (10,10), markersize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3230ad6",
   "metadata": {},
   "source": [
    "### Correct column names and drop geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84705c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (\n",
    "    features\n",
    "    .dropna(subset=['index_right'])\n",
    "    .rename(columns = {\"index_right\": \"district\",})\n",
    "    .reset_index(drop = True)\n",
    ")\n",
    "points = features.copy()\n",
    "points = features[['geometry']]\n",
    "features = features.drop(['geometry'], axis = 1)\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca644884",
   "metadata": {},
   "source": [
    "### Impute missing values\n",
    "\n",
    "Imputing \"manually\" by descending group levels imputes NA values in multiple \"cascading\" steps, decreasing the proportion of inoutated values with each step. First, the NA values are imputed at by both `year` and `district`, which should yield imputed values that most closely match the feature values that would be present in the data if there was no clouds obscuring the satellite images. Next, the remaining NA values that could not be imputed by both `year` and `district` are imputed by only `district`. Lastly, the remaining NA vlaues that could not be imputed by both `year` and `district` or by just `district` are imputed by `year` only. This option gives the user more control and transparency over how the imputation is executed.\n",
    "\n",
    "Imputing using `scikit learn`'s simple imputer executes standard imputation, the details of which can be found in the `scikitlearn` documentation [here.](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "\n",
    "The imputation approach depends on the selection made at the top of this notebook for `impute_manual`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9cfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the number of cells in the features dataframe, based on the amount of rows (images), months, and feature columns\n",
    "num_cells = len(features) * len(month_range) * num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca7eda-15bb-4d0f-8706-f8665424aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    BL = '\\x1b[1;34m' #GREEN\n",
    "    GR = '\\x1b[1;36m' #GREEN\n",
    "    YL = '\\x1b[1;33m' #YELLOW\n",
    "    RD = '\\x1b[1;31m' #RED\n",
    "    RESET = '\\033[0m' #RESET COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be2c7c-37e1-4bf9-80fc-d0554a14f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if impute_manual:\n",
    "    ln_ft = len(features)\n",
    "    ln_na = len(features.dropna())\n",
    "    print(f'Starting total row count: {bcolors.BL}{ln_ft}{bcolors.RESET}',\n",
    "          f'\\nPre-Impute NaN row count: {bcolors.RD}{ln_ft - ln_na}{bcolors.RESET}',\n",
    "          f'\\nPre-Impute NaN row %: {bcolors.RD}{((ln_ft - ln_na) / ln_ft)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\nPre-Impute NaN cell %: {bcolors.RD}{(features.isna().sum().sum() / num_cells)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\n\\nStep 1: Filling NaN values by month, year, and district group average')\n",
    "    features = (\n",
    "        features\n",
    "        .fillna(features\n",
    "                .groupby(['year', 'district'], as_index=False)\n",
    "                .transform('mean')\n",
    "               )\n",
    "    )\n",
    "    ln_ft = len(features)\n",
    "    ln_na = len(features.dropna())\n",
    "    print(f'Post step 1 NaN row count: {bcolors.YL}{ln_ft - ln_na}{bcolors.RESET}',\n",
    "          f'\\nPost step 1 NaN row %: {bcolors.YL}{((ln_ft - ln_na) / ln_ft)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\nPost step 1 NaN cell %: {bcolors.YL}{(features.isna().sum().sum() / num_cells)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\n\\nStep 2: Filling NaN values by month and district group average')\n",
    "    features = (\n",
    "        features\n",
    "        .fillna(features\n",
    "                .groupby(['district'], as_index=False)\n",
    "                .transform('mean')\n",
    "               )\n",
    "    )\n",
    "    ln_ft = len(features)\n",
    "    ln_na = len(features.dropna())\n",
    "    print(f'Post step 2 NaN row count: {bcolors.GR}{ln_ft - ln_na}{bcolors.RESET}',\n",
    "          f'\\nPost step 2 NaN row %: {bcolors.GR}{((ln_ft - ln_na) / ln_ft)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\nPost step 2 NaN cell %: {bcolors.GR}{(features.isna().sum().sum() / num_cells)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\n\\nStep 3: Drop remaining NaN values')\n",
    "    features = features.dropna(axis=0)\n",
    "    print(f'Ending total row count: {bcolors.BL}{len(features)}{bcolors.RESET}\\n')\n",
    "else:\n",
    "    features = features.set_index(['year', 'district'])\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputer.fit_transform(features)\n",
    "    features[:] = imputer.transform(features)\n",
    "    features = features.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dd396",
   "metadata": {},
   "source": [
    "### Save copy of completed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d421fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_copy = features.copy()\n",
    "features_copy['geometry'] = points.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7398ff",
   "metadata": {},
   "source": [
    "### Summarise to administrative boundary level\n",
    "Weighted by cropped area, or simple mean, depending on the selection at the top of this notebook for `weighted_avg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310666d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cols = features.columns[1:-2].values.tolist()\n",
    "features.columns[1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2fcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if weighted_avg:\n",
    "    features_summary = (\n",
    "        features\n",
    "        .groupby(['year', 'district'], as_index=False)\n",
    "        .apply(lambda x: pd.Series([sum(x[v] * x.crop_perc) / sum(x.crop_perc) for v in var_cols]))\n",
    "    )\n",
    "else:\n",
    "    features_summary = features.groupby(['district',\"year\"], as_index = False).mean()\n",
    "# features_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f51c4f-1afd-4d86-bbc4-594dc9e9d961",
   "metadata": {},
   "source": [
    "### Filter Summary Data to crop data range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e16707-44b2-484e-87be-d9324a0c565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary = features_summary[features_summary.year <= year_end_crops]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dc498",
   "metadata": {},
   "source": [
    "### Join crop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_df_x = crop_df[crop_df.year >= min(features_summary.year)]\n",
    "crop_df_x = crop_df_x[~crop_df_x.index.isin(['Mafinga', 'Ikelenge'])]\n",
    "crop_df_x.reset_index(inplace=True)\n",
    "# crop_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary = (\n",
    "    features_summary\n",
    "    .set_index([\"district\", \"year\"])\n",
    "    .join(other = crop_df_x.set_index([\"district\", \"year\"]))\n",
    "    .reset_index())\n",
    "# features_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b421ff-a0d3-46a6-aa1b-a2811e598fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_yield = max(features_summary.yield_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf30432-9f55-40fd-b0f9-e7fcc013be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_summary = features_summary[features_summary.yield_mt < max_yield]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3288b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_year = features_summary[features_summary.year.isin([\n",
    "    2013,\n",
    "    2014,\n",
    "    2015,\n",
    "    2016,\n",
    "    2017,\n",
    "    2018,\n",
    "])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea11764",
   "metadata": {},
   "source": [
    "### Define `x's` and `y's`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f3d06-6248-4c6b-bcc1-62a12b5ed0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if weighted_avg:\n",
    "    drop_cols = ['district', 'year', 'yield_mt']\n",
    "else:\n",
    "    drop_cols = ['district', 'year', 'yield_mt', \"crop_perc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc7bf3-b9a8-45bb-97cd-91642e39dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cols = model_year.columns[2:-2].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83567b5d-4c41-4d1f-b0c3-aa34f6eb5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_year['yield_mt'] = np.log10(model_year['yield_mt'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1762a21b-98c6-4f5c-b84a-668ee6fd8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = model_year[var_cols] - model_year.groupby(['district'])[var_cols].transform('mean')\n",
    "y_all = model_year['yield_mt'] - model_year.groupby(['district'])['yield_mt'].transform('mean')\n",
    "# y_all = np.log10(y_all + 1)\n",
    "# y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357123aa-6a22-457f-8383-4708e0531f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc3f10-72ee-4df4-874e-06baae021d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a4a39-9b2c-4156-bee4-f5bbe94b8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_all = model_year.drop(drop_cols, axis = 1)\n",
    "\n",
    "# y_all = features_summary.yield_mt\n",
    "# y_all = np.log10(model_year.yield_mt.to_numpy() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b916879-1f89-452a-b8db-0d7af4a4e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_year[model_year.year == 2016].iloc[: , :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b7ecf-b075-4e97-9f68-04ee0d38e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312a5f",
   "metadata": {},
   "source": [
    "### Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total N: \", len(x_all), \"\\n\", \n",
    "      \"Train N: \", len(x_train), \"\\n\",\n",
    "      \"Test  N: \", len(x_test), sep = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d84d0",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbadba3-9bef-43e2-b75f-8a5f9310f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf329e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = RepeatedKFold(n_splits = 5, n_repeats = 1, random_state = 42)\n",
    "# ridge_cv_random = RidgeCV(cv=cv, alphas=[0.001, 0.01, 1, 10])\n",
    "# ridge_cv_random = RidgeCV(cv=cv, alphas=np.logspace(-8, 8, base=10, num=17))\n",
    "# ridge_cv_random = RidgeCV(\n",
    "#     cv=5, \n",
    "#     alphas=np.logspace(-5, 5, base=10, num=11),\n",
    "#     scoring='r2',\n",
    "#     scoring='max_error',\n",
    "#     scoring='explained_variance'\n",
    "# )\n",
    "ridge_cv_random = RidgeCV(cv=5, alphas=np.logspace(-8, 8, base=10, num=17))\n",
    "ridge_cv_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9d48b-28dd-47ec-9098-970958bc9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Estimated regularization parameter {ridge_cv_random.alpha_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58e251",
   "metadata": {},
   "source": [
    "### Validation set $R^2$ performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation R2 performance {ridge_cv_random.best_score_:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ee3f9-8343-4ad6-86cb-4328d4ca557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# predicted = cross_val_predict(RidgeCV(cv=5, alphas=np.logspace(-8, 8, base=10, num=17)), x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d4a83-f041-4ad6-8868-8ce9b480aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(y_train, predicted, edgecolors=(0, 0, 0))\n",
    "# ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \"k--\", lw=4)\n",
    "# ax.set_xlabel(\"Measured\")\n",
    "# ax.set_ylabel(\"Predicted\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac1d1",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.maximum(ridge_cv_random.predict(x_train), 0)\n",
    "y_pred = ridge_cv_random.predict(x_train)\n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "# fig, ax = plt.figure()\n",
    "plt.scatter(y_pred, y_train, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title((f\"Model applied to train data n = {len(x_train)}, R$^2$ = {(r2_score(y_train, y_pred)):0.2f}\"),\n",
    "          fontsize=12, y=1.01)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# m, b = np.polyfit(y_pred, y_train, 1)\n",
    "# plt.plot(y_pred, m * y_pred + b, color=\"black\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_train_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R^2 = {r2_train:0.2f}\\nPearsons r = {pearsonr(y_pred, y_train)[0]:0.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550c544-4a28-4d34-841a-837223fa0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(y_pred, y_train)[0]  ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c01413-8e64-4ba8-b61e-5fd8c9d10c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_random.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff83102",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb42c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_pred = np.maximum(ridge_cv_random.predict(x_test), 0)\n",
    "y_pred = ridge_cv_random.predict(x_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title(f\"Model applied to test data n = {len(x_test)}, R$^2$ = {(r2_score(y_test, y_pred)):0.2f}\",\n",
    "          fontsize=12, y=1)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "m, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, m * y_pred + b, color=\"black\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_test_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Testing set R^2 = {r2_test:0.2f}\")\n",
    "print(f\"Testing set pearsons R = {pearsonr(y_pred, y_test)[0]:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db31373-5b4f-4f99-8710-c74854641844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_pred = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "y_pred = ridge_cv_random.predict(x_all)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.axline([-0.2, -0.2], [.4, .4], c = \"k\")\n",
    "plt.scatter(y_pred, y_all, alpha=.9, s=15)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Observed\", fontsize=15)\n",
    "plt.text(\n",
    "    -.2, .35, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_train:0.2f} - Train set\",\n",
    ")\n",
    "plt.text(\n",
    "    -.2, .325, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={ridge_cv_random.best_score_:0.2f} - Validation set\",\n",
    ")\n",
    "plt.text(\n",
    "    -.2, .3, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_test:0.2f} - Test set\",\n",
    ")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "plt.savefig(f'images/{feature_file_name}_all_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks_modeling",
   "language": "python",
   "name": "mosaiks_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
