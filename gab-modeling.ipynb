{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe56655",
   "metadata": {},
   "source": [
    "# Modeling Agricultural Variables\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4f19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import pyarrow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738cdc2-0f1c-4a6d-8756-9d4187cacaf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mild Preprocessing\n",
    "### 1. Load in the data\n",
    "\n",
    "First, we load in the feature data. This data was aggregated in the ___ notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5770bf79-e7b2-49e7-bf0a-e6e78d3db4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's read in the new concatenated features:\n",
    "features = pd.read_feather(\"/capstone/mosaiks/repos/modeling/data/sentinel_rgb_features_sea_save_2023_04_24.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf69ad2-c690-4b95-98eb-ce5212d59895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace 'longitude' and 'latitude' with the appropriate column names in your DataFrame\n",
    "geometry = gpd.points_from_xy(features.lon, features.lat)\n",
    "gdf = gpd.GeoDataFrame(features, geometry=geometry)\n",
    "\n",
    "# Step 4: Plot the data\n",
    "gdf.plot(markersize=0.000001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72181cf-1115-409e-968d-3318c38ab672",
   "metadata": {},
   "source": [
    "### Ground-Truth Data\n",
    "Next, we read in our ground truth data, which was processed in the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5a908f-73f2-4385-89e8-d7511904e59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Name list because gpd doesn't read in column names correctly\n",
    "names = [\"sea_unq\", \"year\", \"total_area_planted_ha\", \"total_area_harv_ha\", \"total_area_lost_ha\", \"total_harv_kg\", \"yield_kgha\", \"frac_area_harv\", \"frac_area_loss\", \"area_lost_fire\", \"maize\", \"groundnuts\", \"mixed_beans\",  \"popcorn\", \"sorghum\", \"soybeans\", \"sweet_potatoes\", \"bunding\", \"monocrop\", \"mixture\", \"frac_loss_drought\",  \"frac_loss_flood\", \"frac_loss_animal\", \"frac_loss_pests\", \"frac_loss_soil\", \"frac_loss_fert\", \"prop_till_plough\",  \"prop_till_ridge\", \"prop_notill\", \"prop_hand\", \"prop_mono\", \"prop_mix\", \"log_maize\",  \"log_sweetpotatoes\", \"log_groundnuts\", \"log_soybeans\", \"loss_ind\", \"drought_loss_ind\", \"flood_loss_ind\", \"animal_loss_ind\", \"pest_loss_ind\", \"geometry\"]\n",
    "\n",
    "\n",
    "\n",
    "# Read in the survey data\n",
    "country_sea = gpd.read_file('/capstone/mosaiks/repos/preprocessing/data/ground_data_spatial/updated_data.shp')\n",
    "country_sea.columns = names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4d161-30d1-47e5-95c3-aaf3b0873be4",
   "metadata": {},
   "source": [
    "We're going to make another object `sea_unq_join` which contains the spatial information and a unique key for each SEA. This will be handy later, when we need to join the features to the ground-truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5472f292-a66a-4d37-9e36-91454113402c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sea_unq                                           geometry\n",
      "0           1  POLYGON ((27.82327 -13.65772, 27.82294 -13.657...\n",
      "10          2  POLYGON ((27.99349 -13.46497, 27.99352 -13.464...\n",
      "20          3  POLYGON ((28.09909 -13.51864, 28.09867 -13.516...\n",
      "29          4  POLYGON ((28.31924 -13.42915, 28.31911 -13.426...\n",
      "38          5  POLYGON ((28.39982 -13.51544, 28.40012 -13.514...\n",
      "...       ...                                                ...\n",
      "3571      388  POLYGON ((25.07771 -14.63920, 25.07732 -14.638...\n",
      "3578      389  POLYGON ((22.74142 -14.00343, 22.73856 -14.002...\n",
      "3585      390  POLYGON ((23.08604 -14.20026, 23.08957 -14.202...\n",
      "3592      391  POLYGON ((24.36764 -16.62208, 24.36564 -16.621...\n",
      "3599      392  POLYGON ((23.23962 -16.31204, 23.23876 -16.312...\n",
      "\n",
      "[392 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter country_sea for unique values of 'seq_unq' and 'geometry'\n",
    "sea_unq_join = country_sea[['sea_unq', 'geometry']].drop_duplicates()\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(sea_unq_join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce99bc0-bd2d-4469-b57d-041af74c5500",
   "metadata": {},
   "source": [
    "### 2. Organize the features by growing season\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbc8fc-4355-428a-8867-e7b62ce335fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Organize the features by growing season\n",
    "# Carry months October, November, and December over to the following year's data\n",
    "# These months represent the start of the growing season for the following year's maize yield\n",
    "year_end = 2022\n",
    "\n",
    "features['year'] = np.where(\n",
    "    features['month'].isin([10, 11, 12]),\n",
    "    features['year'] + 1, \n",
    "    features['year'])\n",
    "\n",
    "features_gs = features[features['year'] <= year_end]\n",
    "\n",
    "features_gs.sort_values(['year', 'month'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f38a1f-5759-4e38-8fcb-5e0a74001d05",
   "metadata": {},
   "source": [
    "### 3. Convert the features into a geo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441255d-041c-4625-afa7-4679f13967fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a geodataframe of the new features\n",
    "features_new_gdf = gpd.GeoDataFrame(\n",
    "    features_gs, \n",
    "    geometry = gpd.points_from_xy(x = features_gs.lon, y = features_gs.lat), \n",
    "    crs='EPSG:4326'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8eebe4-b0fb-4d28-94d0-1e4e1003a3b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_new_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a8866-f763-4ed0-8df7-14b87323d703",
   "metadata": {},
   "source": [
    "## Pivot Wider by months\n",
    "\n",
    "Since we want each row to represent one location per year, we can use the .unstack() function to pivot wider all rows with the same lat/lon and year. This results in a dataframe with 12,000 columns (1,000 columns for each month). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2cbf1-0263-40e0-92a9-a48639bc708b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store the 'geometry' column separately before unstacking\n",
    "geometry_col = features_new_gdf[['lon', 'lat', 'geometry']].drop_duplicates(subset=['lon', 'lat'])\n",
    "\n",
    "# Perform the unstacking operation without the 'geometry' column\n",
    "features_gs_no_geometry = features_gs.drop(columns=['geometry'])\n",
    "features = features_gs_no_geometry.set_index(['lon', 'lat', 'year', 'month']).unstack()\n",
    "features.columns = features.columns.map(lambda x: '{}_{}'.format(*x))\n",
    "\n",
    "# Merge the 'geometry' column back into the features DataFrame\n",
    "features = features.reset_index().merge(geometry_col, on=['lon', 'lat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887e758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72857dd2-c8c8-4a31-9dbb-75646cb7fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unwanted 'index' and 'geometry' columns\n",
    "features = features.filter(regex='^(?!index_)')\n",
    "\n",
    "\n",
    "# Convert the 'features' DataFrame to a GeoDataFrame\n",
    "features_gdf = gpd.GeoDataFrame(features, geometry=features['geometry'], crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729729c2-3459-4375-8500-23b19fbd890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.iloc[:, 12000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d64dea-2fc5-4f15-9938-a161d01203bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Join features to ground data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5a91a-3370-4990-8227-f6a9b5eab405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets combine the sea data \n",
    "spatial_join = gpd.sjoin(features_gdf, sea_unq_join, how='right', predicate = 'within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbc0c5-d3fe-47be-854e-b37fb58f54cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b453c6-ba00-478a-bb99-2774ae6ee081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_join = spatial_join.merge(country_sea, on=['year', 'sea_unq'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc56303-0269-4134-98e7-cc14ea12f13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the redundant independent lon and lat columns because now that they are in a separate geometry column\n",
    "features_join = features_join.drop(['geometry_x'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a586310-57b0-4612-ba23-986b66385a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_join.iloc[:, 12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b876a19-3110-4171-9a2f-9531fcb145e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_join.iloc[:, 12003:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5d43e-b398-4fd6-9038-c07202e7be19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set some parameters \n",
    "# Number of features:\n",
    "num_features = 1000\n",
    "\n",
    "# Imputing\n",
    "impute_manual = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca644884",
   "metadata": {},
   "source": [
    "### Impute missing values\n",
    "\n",
    "Imputing \"manually\" by descending group levels imputes NA values in multiple \"cascading\" steps, decreasing the proportion of inputed values with each step. First, the NA values are imputed at by both `year` and `geometry`, which should yield imputed values that most closely match the feature values that would be present in the data if there was no clouds obscuring the satellite images. Next, the remaining NA values that could not be imputed by both `year` and `district` are imputed by only `district`. Lastly, the remaining NA vlaues that could not be imputed by both `year` and `district` or by just `district` are imputed by `year` only. This option gives the user more control and transparency over how the imputation is executed.\n",
    "\n",
    "Imputing using `scikit learn`'s simple imputer executes standard imputation, the details of which can be found in the `scikitlearn` documentation [here.](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "\n",
    "The imputation approach depends on the selection made at the top of this notebook for `impute_manual`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e1480-3e47-4666-8cae-06401be05fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the size of the features dataframe\n",
    "rows, cols = features_join.shape\n",
    "\n",
    "# compute the number of feature cells in the features dataframe\n",
    "num_cells = rows * cols\n",
    "num_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca7eda-15bb-4d0f-8706-f8665424aaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    BL = '\\x1b[1;34m' #GREEN\n",
    "    GR = '\\x1b[1;36m' #GREEN\n",
    "    YL = '\\x1b[1;33m' #YELLOW\n",
    "    RD = '\\x1b[1;31m' #RED\n",
    "    RESET = '\\033[0m' #RESET COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all infinity values with NaN\n",
    "features_join = features_join.replace([np.inf, -np.inf], np.nan)\n",
    "features_join = (\n",
    "    features_join\n",
    "    .fillna(features_join\n",
    "            .groupby(['lat', 'lon'], as_index=False)\n",
    "            .transform('median')\n",
    "            )\n",
    ")\n",
    "features_join = (\n",
    "    features_join\n",
    "    .fillna(features_join\n",
    "            .groupby(['sea_unq'], as_index=False)\n",
    "            .transform('median')\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be2c7c-37e1-4bf9-80fc-d0554a14f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Notes: Have to change the year, get an error rn. Also, check to make sure the number of cells is correct\n",
    "features_join = features_join.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "if impute_manual:\n",
    "    ln_ft = len(features_join)\n",
    "    ln_na = len(features_join.dropna())\n",
    "    print(f'Starting total row count: {bcolors.BL}{ln_ft}{bcolors.RESET}',\n",
    "          f'\\nPre-Impute NaN row count: {bcolors.RD}{ln_ft - ln_na}{bcolors.RESET}',\n",
    "          f'\\nPre-Impute NaN row %: {bcolors.RD}{((ln_ft - ln_na) / ln_ft)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\nPre-Impute NaN cell %: {bcolors.RD}{(features_join.isna().sum().sum() / num_cells)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\n\\nStep 1: Filling NaN values by month, year, and district group average')\n",
    "    features_join = (\n",
    "        features_join\n",
    "        .fillna(features_join\n",
    "                .groupby(['year', 'sea_unq'], as_index=False) \n",
    "                .transform('mean')\n",
    "               )\n",
    "    )\n",
    "    ln_ft = len(features_join)\n",
    "    ln_na = len(features_join.dropna())\n",
    "    print(f'Post step 1 NaN row count: {bcolors.YL}{ln_ft - ln_na}{bcolors.RESET}',\n",
    "          f'\\nPost step 1 NaN row %: {bcolors.YL}{((ln_ft - ln_na) / ln_ft)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\nPost step 1 NaN cell %: {bcolors.YL}{(features_join.isna().sum().sum() / num_cells)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\n\\nStep 2: Filling NaN values by month and district across group average')\n",
    "    features_join = (\n",
    "        features_join\n",
    "        .fillna(features_join\n",
    "                .groupby(['sea_unq'], as_index=False)\n",
    "                .transform('mean')\n",
    "               )\n",
    "    )\n",
    "    ln_ft = len(features_join)\n",
    "    ln_na = len(features_join.dropna())\n",
    "    print(f'Post step 2 NaN row count: {bcolors.GR}{ln_ft - ln_na}{bcolors.RESET}',\n",
    "          f'\\nPost step 2 NaN row %: {bcolors.GR}{((ln_ft - ln_na) / ln_ft)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\nPost step 2 NaN cell %: {bcolors.GR}{(features_join.isna().sum().sum() / num_cells)*100:.02f}{bcolors.RESET}',\n",
    "          f'\\n\\nStep 3: Drop remaining NaN values\\n')\n",
    "    features_join = features_join.dropna(axis=0)\n",
    "    print(f'Ending total row count: {bcolors.BL}{len(features_join)}{bcolors.RESET}')\n",
    "    \n",
    "else:\n",
    "    # Store the geometry column separately\n",
    "    geometry_col = features_join['geometry_y']\n",
    "    # Remove the geometry column from the DataFrame\n",
    "    features_join = features_join.drop(columns=['geometry_y'])\n",
    "    features_join = features_join.set_index(['year', 'sea_unq'])\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputer.fit_transform(features_join)\n",
    "    features_join[:] = imputer.transform(features_join)\n",
    "    features_join = features_join.reset_index()\n",
    "    # Add the geometry column back to the DataFrame\n",
    "    features_join['geometry'] = geometry_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_join = features_join[features_join['year'] != 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fded92-78f8-4d74-bea8-11fb469eeaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove years 2019 and 2020 from features join data \n",
    "print(features_join['year'].unique())\n",
    "\n",
    "\n",
    "features_join = features_join.drop(['lat', 'lon'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dd396",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save copy of processed features before sumarizing training features to district level\n",
    "\n",
    "Duplicate the features dataframe at this stage so we can retain a copy of features at point resolution for all years available, which is `2013/2014/2016-2021`.\n",
    "\n",
    "    - The start year is `2016` if the satellite selected is Sentinel 2 (due to the fact that Sentinel 2 launched in June of `2015`)\n",
    "    - The start year is `2013` if the satellite selected is Landsat 8 and the month range selected was anything besides all months (due to the fact that Landsat 8 launched in February of `2013`)\n",
    "    - The start year is `2014` if the satellite selected is Landsat 8 and the month range selected was all months\n",
    "    \n",
    "This duplicated dataframe we create in the following code is called `features_all_years`. The purpose for this dataframe comes into play after the model is trained; we will be able to plug in point-resolution features from _any and all_ years from this dataframe into the trained model and observe how the model predicts crop years across space and time. It would be interesting to plot these features for each year sequentially to show how the crop prediction landscape changes by year. These point-resolution features increase the spatial resolution of the ground-truth crop data we have for the years through 2018, because our ground-truth crop data is at a the coarser  district-resolution. Furthermore, these point-resolution features are the _only_ crop data we have for the years 2020-2021. The reason we lack data from 2019 is because the Zanbia Sattistics Agency has not yet released their Crop Forecast Survey data for that year. The reason we do not have data for 2020-2021 is because Covid-19 prevented any Crop Forecast Surveys from being conducted. \n",
    "\n",
    "\n",
    "After we create the dataframe `features_all_years`, we are free to further process the original features dataframe, `features_join`, in order to train the model with these features and their paired ground-truth crop yields. Processing this dataframe further requires us to subset the years to the start year through the years for which we have crop data: `2013/2014/2016-2019`. This dataframe is called `features_through_2019`. The reason we subset this dataframe is because we are training the model using _supervised_ machine learning, which means we are feeding it only features that have ground-truth crop data accosicated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d421fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years = features_join.copy()\n",
    "\n",
    "# assign the geometry column to features_2014_2021 so it can serve 2 purposes:\n",
    "# 1. plotting features sequentially by year\n",
    "# 2. the entire dataframe can be fed into the model after the model is trained on only the summarized features for 2014-2018 and the associated crop data\n",
    "# moving forward in the immediate sections, summarize the `features` dataframe to district level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7398ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summarise to administrative boundary level\n",
    "Weighted by cropped area, or simple mean, depending on the selection at the top of this notebook for `weighted_avg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the order of the columns in the dataframe that will be summarized and then fed into the ridge regression in order to train the model\n",
    "# we care about the order of columns specifically because in the following steps we assign only the feature columns to an object, so we need to know which 3 columns to omit by indexing\n",
    "features_join.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5bb4b3-eae0-4e0e-98ee-84d61b8358a1",
   "metadata": {},
   "source": [
    "The output above show that the 3 columns that are _not_ features are the first 2 columns `year` and `district`, and the last column, `crop_perc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbc894-8004-4fa3-b02c-432e1acc84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape to the dataframe as a sanity check\n",
    "features_join.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95446b-8ade-411b-9b42-97bb84fc01cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_join.iloc[:, 12002]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f4620-f31d-4e85-afc2-5a30b942754a",
   "metadata": {},
   "source": [
    "The output above shows the number of rows and columns in the dataframe, respectively. Recall that the number of rows represents the number of points for which we have features, and the number of columns is all features for all months selected plus the columns `year`, `district`, and `crop_perc`. There are 13866 rows, meaning that is the amount of training points we have to feed into the model _before they are summarized to district level_, so this number will shrink after we summarize to district level. There are 12003 columns, which will not change after we summarize the features to district level. The number of columns that we include in the features object in the next chunk will be this number minus the 3 non-feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310666d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object that contains only feature columns, rather than all columns that would include `district`, `year`, and `crop_perc`\n",
    "# python index starts at 0, so here we specify to retain columns starting at 3 through every column besides the last column\n",
    "# the columns we omit stay in the dataframe, because we assign the selected columns to an object, but the omitted columns are not included in the calculation in the next chunk\n",
    "var_cols = features_join.columns[3:12003].values.tolist()\n",
    "\n",
    "# call the object `var_cols` to check that it only includes feature columns, but do not view it in list format because it is more readable not as a list \n",
    "features_join.columns[3:12003]\n",
    "# these are all the feature columns that will be fed into the `weighted_avg` calculation in the next chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2fcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Group by 'year' and 'sea_unq' and calculate the mean for the specified columns\n",
    "grouped_features = features_join.groupby(['year', 'sea_unq']).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5f1ce-57d8-46e4-bec3-c0bafe0d305e",
   "metadata": {},
   "source": [
    "Now that the features have been summarized to district and year, there are fewer rows. The dataframe we were working with before this step,  `features_through_2018`, had 13866 rows that represented points. Now we have 216 rows, as shown by the following output. Notice we still have all 12003 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6e828-dd90-4ca8-b3f6-1c09096711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_features.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3288b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea11764",
   "metadata": {},
   "source": [
    "### Define `x`'s and `y`'s that will be a part of training the model\n",
    "\n",
    "Since our independent variable is the features, these are the `x`'s. Our dependent variable is the crop yield in metric tonnes per hectare planted, so that will be the `y`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variables (y)\n",
    "X = grouped_features.iloc[:, 1:12000]\n",
    "y = grouped_features['ar_____']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ccecfe-5e5c-4895-8fdb-d0d165364900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312a5f",
   "metadata": {},
   "source": [
    "### Split into train and test sets\n",
    "\n",
    "This step is executed right before training the model so we can train on 80% of the data and preserve 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total points: \", len(X), \"\\n\", \n",
    "      \"Number of training points: \", len(X_train), \"\\n\",\n",
    "      \"Number of testing points: \", len(X_test), sep = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d84d0",
   "metadata": {},
   "source": [
    "### Train model using cross-validated ridge regression\n",
    "\n",
    "Please see the documentation for the function that executes this regression [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13675964-2c33-4e52-874a-9187d2d019e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ridge_cv_random = RidgeCV(cv = 5, alphas = np.linspace(2, 10, num = 20))\n",
    "# ridge_cv_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ca6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_random = RidgeCV(cv = 5, alphas = np.logspace(-8, 8, base = 10, num = 17))\n",
    "ridge_cv_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964fa24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Estimated regularization parameter: {ridge_cv_random.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation R2 performance: {ridge_cv_random.best_score_:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aeb219-a562-4bf6-a8db-95b39753593b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = ridge_cv_random.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "r=r2_score(y_test, y_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9d48b-28dd-47ec-9098-970958bc9b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store the predictions, RMSEs, and R-squared values\n",
    "predictions = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# Loop through the target variables (columns)\n",
    "for i in range(y_test.shape[1]):\n",
    "    # Extract the true values and predictions for the current target variable\n",
    "    y_test_i = y_test.iloc[:, i]\n",
    "    y_pred_i = y_pred[:, i]\n",
    "    \n",
    "    # Compute the RMSE and R-squared\n",
    "    rmse_i = np.sqrt(mean_squared_error(y_test_i, y_pred_i))\n",
    "    r2_i = r2_score(y_test_i, y_pred_i)\n",
    "    \n",
    "    # Append the results to the corresponding lists\n",
    "    predictions.append(y_pred_i)\n",
    "    rmse_list.append(rmse_i)\n",
    "    r2_list.append(r2_i)\n",
    "\n",
    "# Print the RMSE and R-squared values for each target variable\n",
    "\n",
    "for i, (column_name, rmse_i, r2_i) in enumerate(zip(y_test.columns, rmse_list, r2_list), start=1):\n",
    "    print(f\"{column_name}: R-squared = {r2_i:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58e251",
   "metadata": {},
   "source": [
    "### Validation set $R^2$ performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation R2 performance: {ridge_cv_random.best_score_:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac1d1",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(X_train), 0)\n",
    "print(y_pred)\n",
    "r2_train = r2_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R^2 = {r2_train:0.2f}\\nPearsons r = {pearsonr(y_pred, y_train)[0]:0.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550c544-4a28-4d34-841a-837223fa0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson r^2\n",
    "pearsonr(y_pred, y_train)[0] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c01413-8e64-4ba8-b61e-5fd8c9d10c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to calculate Training R^2\n",
    "ridge_cv_random.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff83102",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb42c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_test), 0)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title(f\"Model applied to test data n = {len(x_test)}, R$^2$ = {r2_test:0.2f}\",\n",
    "          fontsize=12, y=1)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_test_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Testing set R^2 = {r2_test:0.2f}\")\n",
    "print(f\"Testing set pearsons R = {pearsonr(y_pred, y_test)[0]:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef4215-081f-4537-aade-bf7c3e5d3d93",
   "metadata": {},
   "source": [
    "Summary of both train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78675318-1a34-4c3d-90f8-e738abd6c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "plt.scatter(y_pred, y_all, alpha=.9, s=15)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Observed\", fontsize=15)\n",
    "plt.text(\n",
    "    0, .8, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_train:0.2f} - Train set\",\n",
    ")\n",
    "plt.text(\n",
    "    0, .75, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={ridge_cv_random.best_score_:0.2f} - Validation set\",\n",
    ")\n",
    "plt.text(\n",
    "    0, .7, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_test:0.2f} - Test set\",\n",
    ")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_all_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29cb5b",
   "metadata": {},
   "source": [
    "### Use the trained model to predict crop yields over all years from 1km grid-cell resolution features \n",
    "\n",
    "Recall that after we executed imputation on all feature years in the dataframe `features`, we copied the dataframe and named it `features_all_years`. Now we can plug that into the model to visualize how our model performs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360ddd6-1c76-4aa0-90cf-3b6ff35b1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall the object we created earlier, before we split the features by year into those that would train the model \n",
    "# and those that would be fed into the trained model to predict crop yields\n",
    "# in years for which we do not have crop data\n",
    "features_all_years.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87a870-2e2b-4c03-b65b-d7431fa82f73",
   "metadata": {},
   "source": [
    "In the following chunk, we drop certain columns from `features_all_years` because we only need to feed the feature data into the model to generate predictions. Using the argument `axis = 1`, we specify that we are dropping columns rather than rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = features_all_years.drop([\n",
    "    'year', \n",
    "    'geometry',\n",
    "    'district',\n",
    "    'crop_perc'\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1331c-9e70-4deb-83a1-ae87cfc7e46b",
   "metadata": {},
   "source": [
    "In the following chunk, we execute the model on the features from the dataframe `features_all_years`. The crop yield predictions for each row populate a new column in the dataframe.\n",
    "\n",
    "The model is run inside the `np.maximum()` function because if we run it without being wrapped inside function, some crop predictions are negative values, but we need them all to be positive because conceptually crop yields cannot be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2e993-6581-4a67-ab60-508479ad53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years['yield_prediction'] = np.maximum(ridge_cv_random.predict(x_all), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4758b-e84a-47c5-a5a5-561d6fbe6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the dataframe with the new column of predictions\n",
    "features_all_years.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f250da4-4a71-483d-bca9-248b8ecd6901",
   "metadata": {},
   "source": [
    "The dataframe is already a geodataframe, so we do not have to convert it to one before mapping predictions. However, we do need to replace all the zero value crop percentage areas with `NA`. We do this by applying the `mask()` function. This function is similar to an if-else statement. If the value of the `crop_perc` is equal to 0, that value is replaced by the value of the second argument, which is `NA`. If the value of `crop_prec` is _not_ equal to zero, we retain the current value. The argument `inplace = True` executes this replacement in the same cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0ee44-575a-45b8-ae14-b44ce3290ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years['yield_prediction'].mask(features_all_years['crop_perc']==0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82712032-c523-4569-9c2a-26f9dea91177",
   "metadata": {},
   "source": [
    "Recall that this dataframe has a geometry column, with latitude and longitude together. In order to map the predicted features, we separate this geometry column into separate `lon` and `lat` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b20d1-e9f8-43b8-888f-32df0f261592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the longitude and latitude from the geometry column, and make then into independent columns\n",
    "features_all_years['lon'], features_all_years['lat'] = features_all_years.geometry.x, features_all_years.geometry.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb0d10-ec00-4063-a106-1b73991b9df8",
   "metadata": {},
   "source": [
    "Plot the predicted features for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4364cf-5eaf-4cb4-8c77-6bd38de288ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, y, c, **kwargs):\n",
    "    plt.scatter(x, y, c=c, s = 1.25)\n",
    "sns.color_palette(\"viridis\", as_cmap=True)\n",
    "g = sns.FacetGrid(\n",
    "    features_all_years, \n",
    "    col=\"year\", \n",
    "    col_wrap = 4, \n",
    "    height=5, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(scatter, \"lon\", \"lat\", \"yield_prediction\")\n",
    "g.set_axis_labels(r\"Yield Prediction\")\n",
    "# save the figure and name the file so that it represents the model parameters that created the predictions\n",
    "# plt.savefig(f'images/{feature_file_name}_all_predictions.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3917b-9fea-429f-9416-23851b20229e",
   "metadata": {},
   "source": [
    "Plot the model's predicted features summarized to district level. In this visualization, we choose a specific year to examine rather than visualizing all years in one figure. Visualizing the the features summarized to district level is interesting because the crop data resolution provided by Zambia Statistics Agency is at the district level, and therefore it is easier to compare our model results to those ground-truth values when they are summarized to district level as well. Furthermore, our model's crop predictions for the years 2020 and 2021 might be more valuable when summarized to district level if Zambian governments, policy-makers, farmers, and researchers wish to use this data to determine crop imports, exports, and storage according to district summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dceaaf7-84d7-49b4-a2da-e0086c67c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years_summary = (\n",
    "    features_all_years\n",
    "    .groupby(['district',\"year\"], as_index = False)['yield_prediction']\n",
    "    .mean()\n",
    "    .set_index('district')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59be6-5dd0-49f2-bfcc-eb2a2ebea5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join Zambia's shapefile to the summarized features to map the districts\n",
    "# reset the index so it is a properly formatted dataframe\n",
    "features_all_years_summary = features_all_years_summary.join(country_shp).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e5b61-80c4-4b22-a0fa-5a2dbd415517",
   "metadata": {},
   "source": [
    "Now that the geometries have been converted to districts from points, the geomatries are now polygons. There is still a row for each district for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f98fce-e33f-49dc-a17c-c9d52215523a",
   "metadata": {},
   "source": [
    "In order to change the year visualized, simply change the year in the following code and re-run the chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084cc6b-b854-46f4-b2e2-02ba71482002",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years_summary[features_all_years_summary.year == 2020].plot(column = \"yield_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acaeba-bf52-49c3-89e9-00dd307b57e6",
   "metadata": {},
   "source": [
    "Plot a boxplot for each year to visualize the range and quantile distribution of each year's crop predictions, summarized to district level. This enables us to identify years with exceptional disparities between the predicted yields by district. It also allows us to identify years that have many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5eff-a4c8-4a54-85f2-52a1fcf8e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=\"year\", y=\"yield_prediction\", data = features_all_years_summary)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.ylabel(\"Predicted Yield\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910fe1b-bb79-497a-952a-0c7d3a3e95ee",
   "metadata": {},
   "source": [
    "Visualize the total crop yield predictions by year. This bar chart shows the sum of all the district crop yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427592b4-686f-4ab1-b781-5f0194dbe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"year\", y=\"yield_prediction\", data = features_all_years_summary, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb543c8f-3e58-4075-b3c2-95804d3c6e7a",
   "metadata": {},
   "source": [
    "## Yield and Residual Plots\n",
    "\n",
    "Create a dataframe of residuals called `residuals_df` from the `features_summary` dataframe. Note that we are _not_ using the predicted crop yields for _all_ years for these residuals, but rather the ground-truth crop yields for just the years through 2018.\n",
    "\n",
    "The residuals give us an idea of the amount of uncertianty that is present in our model. By demeaning the residuals over space, we are able to remove the uncertainty over space and better determine our model performance over time and our uncertainty over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4918a9-c0c4-4a0d-bb32-3ff240200571",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = features_summary.drop(drop_cols, axis = 1)\n",
    "\n",
    "# create empty dataframe to then populate with columns\n",
    "residual_df = pd.DataFrame()\n",
    "\n",
    "residual_df[\"yield_mt\"] = features_summary.yield_mt.to_numpy()\n",
    "residual_df[\"log_yield\"] = np.log10(features_summary.yield_mt.to_numpy() + 1)\n",
    "residual_df[\"prediction\"] = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "residual_df[\"residual\"] = residual_df[\"log_yield\"] - residual_df[\"prediction\"]\n",
    "residual_df[\"year\"] = features_summary.year\n",
    "residual_df[\"district\"] = features_summary.district\n",
    "# join the district geometries\n",
    "residual_df = residual_df.join(country_shp, how = \"left\", on = \"district\")\n",
    "\n",
    "# demean by location so we can analyze the data over time\n",
    "residual_df[\"district_yield_mean\"] = residual_df.groupby('district')['log_yield'].transform('mean')\n",
    "residual_df[\"district_prediction_mean\"] = residual_df.groupby('district')['prediction'].transform('mean')\n",
    "residual_df[\"demean_yield\"] = residual_df[\"log_yield\"] - residual_df[\"district_yield_mean\"]\n",
    "residual_df[\"demean_prediction\"] = residual_df[\"prediction\"] - residual_df[\"district_prediction_mean\"]\n",
    "residual_gdf = geopandas.GeoDataFrame(residual_df)\n",
    "\n",
    "residual_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a2560-4eca-4061-897f-4bb7e2f7c708",
   "metadata": {},
   "source": [
    "Visualize the residuals for the ground truth crop yields through 2018 with a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676a675-bd63-4202-b647-85f0a4fb6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x=\"year\", y=\"log_yield\", data=residual_df)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.ylabel(\"Log Yield\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5edb9d-5840-4847-8f04-80f3de8ef0e1",
   "metadata": {},
   "source": [
    "Visualize the residuals as a sum by year with a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ffa4d-6c2d-4f16-b10d-7ba68bad0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.barplot(x=\"year\", y=\"log_yield\", data=residual_df, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0e82a-7842-4ffe-aa54-0998a766d162",
   "metadata": {},
   "source": [
    "Visualize the crop yield residuals by year as a histogram to determine how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79b57f-1fcc-4364-ba15-db3eed9e7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"yield_mt\", bins = 20)\n",
    "g.set_axis_labels(\"Yield (MT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd3e09-071a-4bb3-b706-9843ef4e58cc",
   "metadata": {},
   "source": [
    "Visualize the log-transformed crop yield residuals by year as a histogram to compare how they are distributed after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51204a02-7ac4-49bc-b4a6-d4d89f18b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"log_yield\", bins = 20)\n",
    "g.set_axis_labels(r\"$\\log_{10}(1 + Crop Yield)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1529f-abd6-4dde-9af2-7128cfd908ce",
   "metadata": {},
   "source": [
    "#### Crop prediction histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611311c-5df0-4cbf-b3ac-37931e00acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"prediction\", bins = 20)\n",
    "g.set_axis_labels(r\"Crop yield predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7448e-ad5f-488d-bde5-dab420c74859",
   "metadata": {},
   "source": [
    "#### Residual histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0628f0-fce2-47ff-b96a-8a4deec322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"residual\", bins = 20)\n",
    "g.set_axis_labels(r\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5d92d-0165-409b-aa92-e8224fce2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_gdf.residual.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88730cab-d02a-4df4-9d05-bbbf6b42eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_gdf.residual.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbac5aa-4029-43e2-9d94-dbaa930aa87b",
   "metadata": {},
   "source": [
    "#### Log crop yield vs residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec42e2-81d5-43f4-ab32-926f5f0ffc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.scatterplot, \"log_yield\", \"residual\")\n",
    "g.set_axis_labels(r\"$\\log_{10}(1 + Crop Yield)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063416fe-51cb-4505-a5c1-59864bf277b3",
   "metadata": {},
   "source": [
    "#### District residuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f7002-7619-4fc4-bcb8-98f1317cd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if satellite == 'landsat-8-c2-l2':\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
    "    ax1 = (residual_gdf[residual_gdf.year == 2014]\n",
    "           .plot(ax = ax1, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "           .set_title(\"2014 Residuals\"))\n",
    "    ax2 = (residual_gdf[residual_gdf.year == 2015]\n",
    "           .plot(ax = ax2, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "           .set_title(\"2015 Residuals\"))\n",
    "else:\n",
    "    pass\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "ax1 = (residual_gdf[residual_gdf.year == 2016]\n",
    "       .plot(ax = ax1, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2016 Residuals\"))\n",
    "ax2 = (residual_gdf[residual_gdf.year == 2017]\n",
    "       .plot(ax = ax2, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2017 Residuals\"))\n",
    "ax3 = (residual_gdf[residual_gdf.year == 2018]\n",
    "       .plot(ax = ax3, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2018 Residuals\"))\n",
    "\n",
    "caption = \"A positive value is an underestimated prediction (the prediction is lower than the actual yield), a negative value is an over estimated prediction\"\n",
    "plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06eb6d-6b28-4493-982f-c2bdc6e18517",
   "metadata": {},
   "source": [
    "#### Difference from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e53cc-050b-4718-8882-410d02c5aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.scatterplot, \"demean_yield\", \"demean_prediction\")\n",
    "g.set_axis_labels('Difference from Yield Mean', 'Difference from Prediction Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c993e12-982a-42e9-8c35-28770ab2b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (6, 5))\n",
    "ax.axline([-.2, -.2], [.2, .2], c = \"k\")\n",
    "plt.scatter(residual_gdf.demean_yield, residual_gdf.demean_prediction)\n",
    "plt.title(\"Demeaned truth and predictions by district\")\n",
    "plt.xlabel('Difference from Yield Mean')\n",
    "plt.ylabel('Difference from Predictions Mean')\n",
    "r_squared = r2_score(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "plt.text(\n",
    "    -0.2,\n",
    "    .18,\n",
    "    s=f\"Demeaned R$^2$ = {r_squared:0.2f}\",\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.savefig(f'images/{feature_file_name}_demean.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f9228-34b2-4f04-b4b0-d47e78542e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in range(year_start+1, 2018):\n",
    "    r_squared = r2_score(residual_gdf[residual_gdf.year == yr][\"demean_yield\"], residual_gdf[residual_gdf.year == yr][\"demean_prediction\"])\n",
    "    pearson_r = pearsonr(residual_gdf[residual_gdf.year == yr][\"demean_yield\"], residual_gdf[residual_gdf.year == yr][\"demean_prediction\"])\n",
    "    \n",
    "    print(yr, f\"    R^2: {r_squared:.2f}\\n\",\n",
    "          f\"Pearson's r: {pearson_r[0]:.2f}\\n\", \n",
    "          sep = \"\")\n",
    "    \n",
    "r_squared = r2_score(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "pearson_r = pearsonr(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "print(f\"All     R^2: {r_squared:.2f}\\n\",\n",
    "      f\"Pearson's r: {pearson_r[0]:.2f}\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bd1d1-4490-4801-a729-331c00e0a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = round(pearson_r[0] ** 2, 2)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e907866-1c8b-41dc-a346-01c0a53ee3fb",
   "metadata": {},
   "source": [
    "#### Join residuals to the features for _all_ years to visualize the residuals of the features before they were summarized to district level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0e606-93a8-477f-b15d-b9a98d2a84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = (\n",
    "    features_all_years_summary\n",
    "    .set_index(['district', 'year'])\n",
    "    .join(residual_df\n",
    "          .drop('geometry', axis = 1)\n",
    "          .set_index(['district', 'year'])\n",
    "         )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "complete_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f045cfe-8479-41c7-bd04-9247843e4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "tidy = complete_df.melt(id_vars='year').rename(columns=str.title)\n",
    "tidy = tidy[tidy.Variable.isin(['yield_prediction', 'log_yield'])]\n",
    "sns.barplot(x='Year', y='Value', hue='Variable', data=tidy, ax=ax1, ci = None)\n",
    "sns.despine(fig)\n",
    "\n",
    "h, l = ax1.get_legend_handles_labels()\n",
    "ax1.legend(h, ['Predicted Yield', 'Observed Yield'],loc='lower left')\n",
    "\n",
    "plt.savefig(f'images/{feature_file_name}_yield_pred.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149c18b-e563-4575-9c13-db636db64af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"year\", y=\"yield_prediction\", data=complete_df, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476b4e-d3b5-4f79-8d2d-651d6416900a",
   "metadata": {},
   "source": [
    "### Congratulations on completing this analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks-modeling",
   "language": "python",
   "name": "mosaiks-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
