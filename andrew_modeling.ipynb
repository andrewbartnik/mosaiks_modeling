{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe56655",
   "metadata": {},
   "source": [
    "# Modeling Agricultural Variables\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4f19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import pyarrow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f593b6f-5740-41de-b785-3a4555428899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/preprocessing/data/grouped_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe3e8ca-f209-4c76-a209-1c49d83c81a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.157999e-06</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>6.299240e-05</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>0.939709</td>\n",
       "      <td>0.049106</td>\n",
       "      <td>0.039969</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.071531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008277e-03</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.071531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.590917e-05</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.071531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.113844e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.071531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5       0_6       0_7  \\\n",
       "0  0.000000  0.000863  0.000783  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000069  0.000863  0.000783  0.000000  0.000002  0.000014  0.000047   \n",
       "2  0.001141  0.000863  0.000783  0.000329  0.000000  0.000000  0.000000   \n",
       "3  0.001131  0.000863  0.000783  0.000006  0.000004  0.000010  0.000014   \n",
       "4  0.001131  0.000863  0.000783  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            0_8       0_9      0_10  ...     999_3     999_4     999_5  \\\n",
       "0  6.157999e-06  0.000207  0.001568  ...  0.060421  1.000000  0.274676   \n",
       "1  6.299240e-05  0.000168  0.001568  ...  0.060421  0.939709  0.049106   \n",
       "2  1.008277e-03  0.001360  0.002211  ...  0.060421  0.006789  1.000000   \n",
       "3  2.590917e-05  0.000110  0.001568  ...  0.060421  0.005561  0.006391   \n",
       "4  3.113844e-07  0.000012  0.001568  ...  0.060421  0.005570  0.006739   \n",
       "\n",
       "      999_6     999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0  1.000000  0.115388  0.002708  0.001319  0.002867  0.003866  1.000000  \n",
       "1  0.039969  0.004752  0.002671  0.002439  0.002867  0.003866  0.071531  \n",
       "2  1.000000  1.000000  0.000517  0.000343  0.000396  0.003866  0.071531  \n",
       "3  0.004212  0.003235  0.001937  0.001683  0.002867  0.003866  0.071531  \n",
       "4  0.003991  0.002857  0.001979  0.001435  0.002867  0.003866  0.071531  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = grouped_features.iloc[:,2:12002]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0640f9c-6682-4d85-866c-f7d2be3135cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>total_harv_kg</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>area_lost_fire</th>\n",
       "      <th>maize</th>\n",
       "      <th>groundnuts</th>\n",
       "      <th>mixed_beans</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058626</td>\n",
       "      <td>6.364023</td>\n",
       "      <td>5.935403</td>\n",
       "      <td>6.565149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>24.045802</td>\n",
       "      <td>0.946565</td>\n",
       "      <td>0.053435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.045802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.179960</td>\n",
       "      <td>6.364023</td>\n",
       "      <td>5.935403</td>\n",
       "      <td>6.565149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>8730.0</td>\n",
       "      <td>8.592520</td>\n",
       "      <td>0.597441</td>\n",
       "      <td>0.402559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>3.387211</td>\n",
       "      <td>0.689155</td>\n",
       "      <td>5.935403</td>\n",
       "      <td>6.565149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>462.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>12.162577</td>\n",
       "      <td>0.708589</td>\n",
       "      <td>0.291411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.938398</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>2.703935</td>\n",
       "      <td>6.364023</td>\n",
       "      <td>-1.408767</td>\n",
       "      <td>6.565149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>19975.0</td>\n",
       "      <td>36.651376</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.048593</td>\n",
       "      <td>28.629032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714757</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.354421</td>\n",
       "      <td>6.565149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_area_harv_ha  total_area_lost_ha  total_harv_kg  yield_kgha  \\\n",
       "0                71.0                 5.0         4400.0   57.894737   \n",
       "1               124.0                 7.0         3150.0   24.045802   \n",
       "2               607.0               409.0         8730.0    8.592520   \n",
       "3               462.0               190.0         7930.0   12.162577   \n",
       "4               410.0               135.0        19975.0   36.651376   \n",
       "\n",
       "   frac_area_harv  frac_area_loss  area_lost_fire      maize  groundnuts  \\\n",
       "0        0.934211        0.065789             0.0  57.894737    0.000000   \n",
       "1        0.946565        0.053435             0.0  24.045802    0.000000   \n",
       "2        0.597441        0.402559             0.0  29.583333    0.000000   \n",
       "3        0.708589        0.291411             0.0  14.938398    0.244444   \n",
       "4        0.752294        0.247706             0.0  41.048593   28.629032   \n",
       "\n",
       "   mixed_beans  ...  prop_mix  log_maize  log_sweetpotatoes  log_groundnuts  \\\n",
       "0     0.000000  ...  0.000000   4.058626           6.364023        5.935403   \n",
       "1     0.000000  ...  0.000000   3.179960           6.364023        5.935403   \n",
       "2     0.434783  ...  0.181102   3.387211           0.689155        5.935403   \n",
       "3     5.366667  ...  0.069018   2.703935           6.364023       -1.408767   \n",
       "4     0.000000  ...  0.000000   3.714757           2.525729        3.354421   \n",
       "\n",
       "   log_soybeans  loss_ind  drought_loss_ind  flood_loss_ind  animal_loss_ind  \\\n",
       "0      6.565149       0.0               0.0             0.0              0.0   \n",
       "1      6.565149       0.0               0.0             0.0              0.0   \n",
       "2      6.565149       1.0               1.0             0.0              0.0   \n",
       "3      6.565149       1.0               0.0             0.0              0.0   \n",
       "4      6.565149       1.0               0.0             0.0              0.0   \n",
       "\n",
       "   pest_loss_ind  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = grouped_features.iloc[:,12003:]\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3288b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea11764",
   "metadata": {},
   "source": [
    "### Define `x`'s and `y`'s that will be a part of training the model\n",
    "\n",
    "Since our independent variable is the features, these are the `x`'s. Our dependent variable is the crop yield in metric tonnes per hectare planted, so that will be the `y`'s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312a5f",
   "metadata": {},
   "source": [
    "### Split into train and test sets\n",
    "\n",
    "This step is executed right before training the model so we can train on 80% of the data and preserve 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ea5f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(target_columns):\n",
    "    grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/preprocessing/data/grouped_features.csv\")\n",
    "\n",
    "    features = grouped_features.iloc[:, 2:12002]\n",
    "    outcomes = grouped_features.iloc[:, 12003:]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train_full, y_test_full = train_test_split(features, outcomes, test_size=0.2, random_state=42)\n",
    "\n",
    "    for target_column in target_columns:\n",
    "        # Select the target variable\n",
    "        y_train = y_train_full[target_column]\n",
    "        y_test = y_test_full[target_column]\n",
    "\n",
    "        # Train the model\n",
    "        ridge_cv = RidgeCV(cv=5, alphas=np.logspace(-8, 8, base=10, num=17))\n",
    "        ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = ridge_cv.predict(X_test)\n",
    "        \n",
    "        # Calculate Pearson's correlation coefficient\n",
    "        pearson_coeff, _ = pearsonr(y_test, y_pred)\n",
    "\n",
    "        print(f\"Target variable: {target_column}\")\n",
    "        print(f\"Estimated regularization parameter: {ridge_cv.alpha_}\")\n",
    "        print(f\"Validation R2 performance: {ridge_cv.best_score_:0.2f}\")\n",
    "        print(f\"Pearson's correlation coefficient: {pearson_coeff:0.2f}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d84d0",
   "metadata": {},
   "source": [
    "### Train model using cross-validated ridge regression\n",
    "\n",
    "Please see the documentation for the function that executes this regression [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13675964-2c33-4e52-874a-9187d2d019e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: total_area_harv_ha\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.37\n",
      "Pearson's correlation coefficient: 0.70\n",
      "\n",
      "Target variable: total_area_lost_ha\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.42\n",
      "Pearson's correlation coefficient: 0.74\n",
      "\n",
      "Target variable: total_harv_kg\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.41\n",
      "Pearson's correlation coefficient: 0.55\n",
      "\n",
      "Target variable: yield_kgha\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.49\n",
      "Pearson's correlation coefficient: 0.73\n",
      "\n",
      "Target variable: frac_area_harv\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.36\n",
      "Pearson's correlation coefficient: 0.67\n",
      "\n",
      "Target variable: frac_area_loss\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.36\n",
      "Pearson's correlation coefficient: 0.67\n",
      "\n",
      "Target variable: area_lost_fire\n",
      "Estimated regularization parameter: 1000000.0\n",
      "Validation R2 performance: -0.01\n",
      "Pearson's correlation coefficient: -0.12\n",
      "\n",
      "Target variable: maize\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.48\n",
      "Pearson's correlation coefficient: 0.73\n",
      "\n",
      "Target variable: groundnuts\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.21\n",
      "Pearson's correlation coefficient: 0.49\n",
      "\n",
      "Target variable: mixed_beans\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.18\n",
      "Pearson's correlation coefficient: 0.50\n",
      "\n",
      "Target variable: popcorn\n",
      "Estimated regularization parameter: 100.0\n",
      "Validation R2 performance: 0.06\n",
      "Pearson's correlation coefficient: 0.27\n",
      "\n",
      "Target variable: sorghum\n",
      "Estimated regularization parameter: 100.0\n",
      "Validation R2 performance: 0.04\n",
      "Pearson's correlation coefficient: 0.28\n",
      "\n",
      "Target variable: soybeans\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.24\n",
      "Pearson's correlation coefficient: 0.55\n",
      "\n",
      "Target variable: sweet_potatoes\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.19\n",
      "Pearson's correlation coefficient: 0.48\n",
      "\n",
      "Target variable: bunding\n",
      "Estimated regularization parameter: 1000000.0\n",
      "Validation R2 performance: -0.14\n",
      "Pearson's correlation coefficient: 0.07\n",
      "\n",
      "Target variable: monocrop\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.43\n",
      "Pearson's correlation coefficient: 0.60\n",
      "\n",
      "Target variable: mixture\n",
      "Estimated regularization parameter: 100.0\n",
      "Validation R2 performance: 0.01\n",
      "Pearson's correlation coefficient: 0.24\n",
      "\n",
      "Target variable: frac_loss_drought\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.35\n",
      "Pearson's correlation coefficient: 0.75\n",
      "\n",
      "Target variable: frac_loss_flood\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.04\n",
      "Pearson's correlation coefficient: 0.06\n",
      "\n",
      "Target variable: frac_loss_animal\n",
      "Estimated regularization parameter: 10000.0\n",
      "Validation R2 performance: 0.01\n",
      "Pearson's correlation coefficient: 0.14\n",
      "\n",
      "Target variable: frac_loss_pests\n",
      "Estimated regularization parameter: 1000.0\n",
      "Validation R2 performance: -0.00\n",
      "Pearson's correlation coefficient: 0.18\n",
      "\n",
      "Target variable: frac_loss_soil\n",
      "Estimated regularization parameter: 1000.0\n",
      "Validation R2 performance: -0.00\n",
      "Pearson's correlation coefficient: 0.15\n",
      "\n",
      "Target variable: frac_loss_fert\n",
      "Estimated regularization parameter: 100.0\n",
      "Validation R2 performance: 0.02\n",
      "Pearson's correlation coefficient: 0.20\n",
      "\n",
      "Target variable: prop_till_plough\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.68\n",
      "Pearson's correlation coefficient: 0.80\n",
      "\n",
      "Target variable: prop_till_ridge\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.49\n",
      "Pearson's correlation coefficient: 0.74\n",
      "\n",
      "Target variable: prop_notill\n",
      "Estimated regularization parameter: 100000000.0\n",
      "Validation R2 performance: -0.03\n",
      "Pearson's correlation coefficient: -0.01\n",
      "\n",
      "Target variable: prop_hand\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.17\n",
      "Pearson's correlation coefficient: 0.46\n",
      "\n",
      "Target variable: prop_mono\n",
      "Estimated regularization parameter: 0.09999999999999999\n",
      "Validation R2 performance: 0.58\n",
      "Pearson's correlation coefficient: 0.82\n",
      "\n",
      "Target variable: prop_mix\n",
      "Estimated regularization parameter: 1000.0\n",
      "Validation R2 performance: -0.01\n",
      "Pearson's correlation coefficient: 0.24\n",
      "\n",
      "Target variable: log_maize\n",
      "Estimated regularization parameter: 0.09999999999999999\n",
      "Validation R2 performance: 0.53\n",
      "Pearson's correlation coefficient: 0.81\n",
      "\n",
      "Target variable: log_sweetpotatoes\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.28\n",
      "Pearson's correlation coefficient: 0.69\n",
      "\n",
      "Target variable: log_groundnuts\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.37\n",
      "Pearson's correlation coefficient: 0.70\n",
      "\n",
      "Target variable: log_soybeans\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.14\n",
      "Pearson's correlation coefficient: 0.44\n",
      "\n",
      "Target variable: loss_ind\n",
      "Estimated regularization parameter: 1.0\n",
      "Validation R2 performance: 0.23\n",
      "Pearson's correlation coefficient: 0.49\n",
      "\n",
      "Target variable: drought_loss_ind\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.41\n",
      "Pearson's correlation coefficient: 0.68\n",
      "\n",
      "Target variable: flood_loss_ind\n",
      "Estimated regularization parameter: 10.0\n",
      "Validation R2 performance: 0.02\n",
      "Pearson's correlation coefficient: 0.12\n",
      "\n",
      "Target variable: animal_loss_ind\n",
      "Estimated regularization parameter: 100000.0\n",
      "Validation R2 performance: -0.01\n",
      "Pearson's correlation coefficient: 0.09\n",
      "\n",
      "Target variable: pest_loss_ind\n",
      "Estimated regularization parameter: 1000.0\n",
      "Validation R2 performance: -0.01\n",
      "Pearson's correlation coefficient: 0.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_columns = outcomes.columns\n",
    "train_and_evaluate_models(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cd84af-08a7-4d1e-90c2-200446c64927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models_blocksample(target_columns, hold_out_sea_unq):\n",
    "    grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/preprocessing/data/grouped_features.csv\")\n",
    "\n",
    "    features = grouped_features.iloc[:, 2:12002]\n",
    "    outcomes = grouped_features.iloc[:, 12003:]\n",
    "\n",
    "    # Perform block sampling based on sea_unq values\n",
    "    X_train, X_test, y_train_full, y_test_full = block_split(grouped_features, features, outcomes, hold_out_sea_unq)\n",
    "\n",
    "    for target_column in target_columns:\n",
    "        # Select the target variable\n",
    "        y_train = y_train_full[target_column]\n",
    "        y_test = y_test_full[target_column]\n",
    "\n",
    "        # Train the model\n",
    "        ridge_cv = RidgeCV(cv=5, alphas=np.logspace(-8, 8, base=10, num=17))\n",
    "        ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = ridge_cv.predict(X_test)\n",
    "\n",
    "        # Calculate Pearson's correlation coefficient\n",
    "        pearson_coeff, _ = pearsonr(y_test, y_pred)\n",
    "\n",
    "        print(f\"Target variable: {target_column}\")\n",
    "        print(f\"Estimated regularization parameter: {ridge_cv.alpha_}\")\n",
    "        print(f\"Validation R2 performance: {ridge_cv.best_score_:0.2f}\")\n",
    "        print(f\"Pearson's correlation coefficient: {pearson_coeff:0.2f}\")\n",
    "        print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced006f5-e986-42ae-a701-9320ac74e893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: log_maize\n",
      "Estimated regularization parameter: 100000.0\n",
      "Validation R2 performance: -16.26\n",
      "Pearson's correlation coefficient: 0.43\n",
      "\n",
      "Target variable: frac_area_loss\n",
      "Estimated regularization parameter: 100000000.0\n",
      "Validation R2 performance: -1.58\n",
      "Pearson's correlation coefficient: -0.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "hold_out_sea_unq = list([45, 52])  \n",
    "target_columns = ['log_maize', 'frac_area_loss', 'drought_loss_ind']\n",
    "train_and_evaluate_models_blocksample(target_columns, hold_out_sea_unq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac1d1",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_train), 0)\n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1)\n",
    "plt.scatter(y_pred, y_train, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15, x = .3)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title((f\"Model applied to train data n = {len(x_train)}, R$^2$ = {r2_train:0.2f}\"),\n",
    "          fontsize=12, y=1.01)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "ax.axline([0, 0], [1, 1], c = \"k\")\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_train_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "# the model is plotted with a black 45 degree line that serves as a reference of what a perfect correlation would look like\n",
    "# deviation of the line indicates that there is not a perfect correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R^2 = {r2_train:0.2f}\\nPearsons r = {pearsonr(y_pred, y_train)[0]:0.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550c544-4a28-4d34-841a-837223fa0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson r^2\n",
    "pearsonr(y_pred, y_train)[0] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c01413-8e64-4ba8-b61e-5fd8c9d10c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to calculate Training R^2\n",
    "ridge_cv_random.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff83102",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb42c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_test), 0)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title(f\"Model applied to test data n = {len(x_test)}, R$^2$ = {r2_test:0.2f}\",\n",
    "          fontsize=12, y=1)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_test_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Testing set R^2 = {r2_test:0.2f}\")\n",
    "print(f\"Testing set pearsons R = {pearsonr(y_pred, y_test)[0]:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef4215-081f-4537-aade-bf7c3e5d3d93",
   "metadata": {},
   "source": [
    "Summary of both train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78675318-1a34-4c3d-90f8-e738abd6c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "plt.scatter(y_pred, y_all, alpha=.9, s=15)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Observed\", fontsize=15)\n",
    "plt.text(\n",
    "    0, .8, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_train:0.2f} - Train set\",\n",
    ")\n",
    "plt.text(\n",
    "    0, .75, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={ridge_cv_random.best_score_:0.2f} - Validation set\",\n",
    ")\n",
    "plt.text(\n",
    "    0, .7, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_test:0.2f} - Test set\",\n",
    ")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_all_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29cb5b",
   "metadata": {},
   "source": [
    "### Use the trained model to predict crop yields over all years from 1km grid-cell resolution features \n",
    "\n",
    "Recall that after we executed imputation on all feature years in the dataframe `features`, we copied the dataframe and named it `features_all_years`. Now we can plug that into the model to visualize how our model performs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360ddd6-1c76-4aa0-90cf-3b6ff35b1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall the object we created earlier, before we split the features by year into those that would train the model \n",
    "# and those that would be fed into the trained model to predict crop yields\n",
    "# in years for which we do not have crop data\n",
    "features_all_years.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87a870-2e2b-4c03-b65b-d7431fa82f73",
   "metadata": {},
   "source": [
    "In the following chunk, we drop certain columns from `features_all_years` because we only need to feed the feature data into the model to generate predictions. Using the argument `axis = 1`, we specify that we are dropping columns rather than rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = features_all_years.drop([\n",
    "    'year', \n",
    "    'geometry',\n",
    "    'district',\n",
    "    'crop_perc'\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1331c-9e70-4deb-83a1-ae87cfc7e46b",
   "metadata": {},
   "source": [
    "In the following chunk, we execute the model on the features from the dataframe `features_all_years`. The crop yield predictions for each row populate a new column in the dataframe.\n",
    "\n",
    "The model is run inside the `np.maximum()` function because if we run it without being wrapped inside function, some crop predictions are negative values, but we need them all to be positive because conceptually crop yields cannot be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2e993-6581-4a67-ab60-508479ad53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years['yield_prediction'] = np.maximum(ridge_cv_random.predict(x_all), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4758b-e84a-47c5-a5a5-561d6fbe6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the dataframe with the new column of predictions\n",
    "features_all_years.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f250da4-4a71-483d-bca9-248b8ecd6901",
   "metadata": {},
   "source": [
    "The dataframe is already a geodataframe, so we do not have to convert it to one before mapping predictions. However, we do need to replace all the zero value crop percentage areas with `NA`. We do this by applying the `mask()` function. This function is similar to an if-else statement. If the value of the `crop_perc` is equal to 0, that value is replaced by the value of the second argument, which is `NA`. If the value of `crop_prec` is _not_ equal to zero, we retain the current value. The argument `inplace = True` executes this replacement in the same cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0ee44-575a-45b8-ae14-b44ce3290ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years['yield_prediction'].mask(features_all_years['crop_perc']==0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82712032-c523-4569-9c2a-26f9dea91177",
   "metadata": {},
   "source": [
    "Recall that this dataframe has a geometry column, with latitude and longitude together. In order to map the predicted features, we separate this geometry column into separate `lon` and `lat` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b20d1-e9f8-43b8-888f-32df0f261592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the longitude and latitude from the geometry column, and make then into independent columns\n",
    "features_all_years['lon'], features_all_years['lat'] = features_all_years.geometry.x, features_all_years.geometry.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb0d10-ec00-4063-a106-1b73991b9df8",
   "metadata": {},
   "source": [
    "Plot the predicted features for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4364cf-5eaf-4cb4-8c77-6bd38de288ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, y, c, **kwargs):\n",
    "    plt.scatter(x, y, c=c, s = 1.25)\n",
    "sns.color_palette(\"viridis\", as_cmap=True)\n",
    "g = sns.FacetGrid(\n",
    "    features_all_years, \n",
    "    col=\"year\", \n",
    "    col_wrap = 4, \n",
    "    height=5, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(scatter, \"lon\", \"lat\", \"yield_prediction\")\n",
    "g.set_axis_labels(r\"Yield Prediction\")\n",
    "# save the figure and name the file so that it represents the model parameters that created the predictions\n",
    "# plt.savefig(f'images/{feature_file_name}_all_predictions.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3917b-9fea-429f-9416-23851b20229e",
   "metadata": {},
   "source": [
    "Plot the model's predicted features summarized to district level. In this visualization, we choose a specific year to examine rather than visualizing all years in one figure. Visualizing the the features summarized to district level is interesting because the crop data resolution provided by Zambia Statistics Agency is at the district level, and therefore it is easier to compare our model results to those ground-truth values when they are summarized to district level as well. Furthermore, our model's crop predictions for the years 2020 and 2021 might be more valuable when summarized to district level if Zambian governments, policy-makers, farmers, and researchers wish to use this data to determine crop imports, exports, and storage according to district summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dceaaf7-84d7-49b4-a2da-e0086c67c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years_summary = (\n",
    "    features_all_years\n",
    "    .groupby(['district',\"year\"], as_index = False)['yield_prediction']\n",
    "    .mean()\n",
    "    .set_index('district')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59be6-5dd0-49f2-bfcc-eb2a2ebea5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join Zambia's shapefile to the summarized features to map the districts\n",
    "# reset the index so it is a properly formatted dataframe\n",
    "features_all_years_summary = features_all_years_summary.join(country_shp).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e5b61-80c4-4b22-a0fa-5a2dbd415517",
   "metadata": {},
   "source": [
    "Now that the geometries have been converted to districts from points, the geomatries are now polygons. There is still a row for each district for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f98fce-e33f-49dc-a17c-c9d52215523a",
   "metadata": {},
   "source": [
    "In order to change the year visualized, simply change the year in the following code and re-run the chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084cc6b-b854-46f4-b2e2-02ba71482002",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years_summary[features_all_years_summary.year == 2020].plot(column = \"yield_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acaeba-bf52-49c3-89e9-00dd307b57e6",
   "metadata": {},
   "source": [
    "Plot a boxplot for each year to visualize the range and quantile distribution of each year's crop predictions, summarized to district level. This enables us to identify years with exceptional disparities between the predicted yields by district. It also allows us to identify years that have many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5eff-a4c8-4a54-85f2-52a1fcf8e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=\"year\", y=\"yield_prediction\", data = features_all_years_summary)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.ylabel(\"Predicted Yield\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910fe1b-bb79-497a-952a-0c7d3a3e95ee",
   "metadata": {},
   "source": [
    "Visualize the total crop yield predictions by year. This bar chart shows the sum of all the district crop yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427592b4-686f-4ab1-b781-5f0194dbe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"year\", y=\"yield_prediction\", data = features_all_years_summary, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb543c8f-3e58-4075-b3c2-95804d3c6e7a",
   "metadata": {},
   "source": [
    "## Yield and Residual Plots\n",
    "\n",
    "Create a dataframe of residuals called `residuals_df` from the `features_summary` dataframe. Note that we are _not_ using the predicted crop yields for _all_ years for these residuals, but rather the ground-truth crop yields for just the years through 2018.\n",
    "\n",
    "The residuals give us an idea of the amount of uncertianty that is present in our model. By demeaning the residuals over space, we are able to remove the uncertainty over space and better determine our model performance over time and our uncertainty over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4918a9-c0c4-4a0d-bb32-3ff240200571",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = features_summary.drop(drop_cols, axis = 1)\n",
    "\n",
    "# create empty dataframe to then populate with columns\n",
    "residual_df = pd.DataFrame()\n",
    "\n",
    "residual_df[\"yield_mt\"] = features_summary.yield_mt.to_numpy()\n",
    "residual_df[\"log_yield\"] = np.log10(features_summary.yield_mt.to_numpy() + 1)\n",
    "residual_df[\"prediction\"] = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "residual_df[\"residual\"] = residual_df[\"log_yield\"] - residual_df[\"prediction\"]\n",
    "residual_df[\"year\"] = features_summary.year\n",
    "residual_df[\"district\"] = features_summary.district\n",
    "# join the district geometries\n",
    "residual_df = residual_df.join(country_shp, how = \"left\", on = \"district\")\n",
    "\n",
    "# demean by location so we can analyze the data over time\n",
    "residual_df[\"district_yield_mean\"] = residual_df.groupby('district')['log_yield'].transform('mean')\n",
    "residual_df[\"district_prediction_mean\"] = residual_df.groupby('district')['prediction'].transform('mean')\n",
    "residual_df[\"demean_yield\"] = residual_df[\"log_yield\"] - residual_df[\"district_yield_mean\"]\n",
    "residual_df[\"demean_prediction\"] = residual_df[\"prediction\"] - residual_df[\"district_prediction_mean\"]\n",
    "residual_gdf = geopandas.GeoDataFrame(residual_df)\n",
    "\n",
    "residual_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a2560-4eca-4061-897f-4bb7e2f7c708",
   "metadata": {},
   "source": [
    "Visualize the residuals for the ground truth crop yields through 2018 with a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676a675-bd63-4202-b647-85f0a4fb6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x=\"year\", y=\"log_yield\", data=residual_df)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.ylabel(\"Log Yield\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5edb9d-5840-4847-8f04-80f3de8ef0e1",
   "metadata": {},
   "source": [
    "Visualize the residuals as a sum by year with a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ffa4d-6c2d-4f16-b10d-7ba68bad0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.barplot(x=\"year\", y=\"log_yield\", data=residual_df, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0e82a-7842-4ffe-aa54-0998a766d162",
   "metadata": {},
   "source": [
    "Visualize the crop yield residuals by year as a histogram to determine how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79b57f-1fcc-4364-ba15-db3eed9e7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"yield_mt\", bins = 20)\n",
    "g.set_axis_labels(\"Yield (MT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd3e09-071a-4bb3-b706-9843ef4e58cc",
   "metadata": {},
   "source": [
    "Visualize the log-transformed crop yield residuals by year as a histogram to compare how they are distributed after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51204a02-7ac4-49bc-b4a6-d4d89f18b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"log_yield\", bins = 20)\n",
    "g.set_axis_labels(r\"$\\log_{10}(1 + Crop Yield)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1529f-abd6-4dde-9af2-7128cfd908ce",
   "metadata": {},
   "source": [
    "#### Crop prediction histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611311c-5df0-4cbf-b3ac-37931e00acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"prediction\", bins = 20)\n",
    "g.set_axis_labels(r\"Crop yield predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7448e-ad5f-488d-bde5-dab420c74859",
   "metadata": {},
   "source": [
    "#### Residual histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0628f0-fce2-47ff-b96a-8a4deec322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"residual\", bins = 20)\n",
    "g.set_axis_labels(r\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5d92d-0165-409b-aa92-e8224fce2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_gdf.residual.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88730cab-d02a-4df4-9d05-bbbf6b42eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_gdf.residual.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbac5aa-4029-43e2-9d94-dbaa930aa87b",
   "metadata": {},
   "source": [
    "#### Log crop yield vs residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec42e2-81d5-43f4-ab32-926f5f0ffc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.scatterplot, \"log_yield\", \"residual\")\n",
    "g.set_axis_labels(r\"$\\log_{10}(1 + Crop Yield)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063416fe-51cb-4505-a5c1-59864bf277b3",
   "metadata": {},
   "source": [
    "#### District residuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f7002-7619-4fc4-bcb8-98f1317cd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if satellite == 'landsat-8-c2-l2':\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
    "    ax1 = (residual_gdf[residual_gdf.year == 2014]\n",
    "           .plot(ax = ax1, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "           .set_title(\"2014 Residuals\"))\n",
    "    ax2 = (residual_gdf[residual_gdf.year == 2015]\n",
    "           .plot(ax = ax2, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "           .set_title(\"2015 Residuals\"))\n",
    "else:\n",
    "    pass\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "ax1 = (residual_gdf[residual_gdf.year == 2016]\n",
    "       .plot(ax = ax1, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2016 Residuals\"))\n",
    "ax2 = (residual_gdf[residual_gdf.year == 2017]\n",
    "       .plot(ax = ax2, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2017 Residuals\"))\n",
    "ax3 = (residual_gdf[residual_gdf.year == 2018]\n",
    "       .plot(ax = ax3, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2018 Residuals\"))\n",
    "\n",
    "caption = \"A positive value is an underestimated prediction (the prediction is lower than the actual yield), a negative value is an over estimated prediction\"\n",
    "plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06eb6d-6b28-4493-982f-c2bdc6e18517",
   "metadata": {},
   "source": [
    "#### Difference from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e53cc-050b-4718-8882-410d02c5aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.scatterplot, \"demean_yield\", \"demean_prediction\")\n",
    "g.set_axis_labels('Difference from Yield Mean', 'Difference from Prediction Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c993e12-982a-42e9-8c35-28770ab2b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (6, 5))\n",
    "ax.axline([-.2, -.2], [.2, .2], c = \"k\")\n",
    "plt.scatter(residual_gdf.demean_yield, residual_gdf.demean_prediction)\n",
    "plt.title(\"Demeaned truth and predictions by district\")\n",
    "plt.xlabel('Difference from Yield Mean')\n",
    "plt.ylabel('Difference from Predictions Mean')\n",
    "r_squared = r2_score(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "plt.text(\n",
    "    -0.2,\n",
    "    .18,\n",
    "    s=f\"Demeaned R$^2$ = {r_squared:0.2f}\",\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.savefig(f'images/{feature_file_name}_demean.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f9228-34b2-4f04-b4b0-d47e78542e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in range(year_start+1, 2018):\n",
    "    r_squared = r2_score(residual_gdf[residual_gdf.year == yr][\"demean_yield\"], residual_gdf[residual_gdf.year == yr][\"demean_prediction\"])\n",
    "    pearson_r = pearsonr(residual_gdf[residual_gdf.year == yr][\"demean_yield\"], residual_gdf[residual_gdf.year == yr][\"demean_prediction\"])\n",
    "    \n",
    "    print(yr, f\"    R^2: {r_squared:.2f}\\n\",\n",
    "          f\"Pearson's r: {pearson_r[0]:.2f}\\n\", \n",
    "          sep = \"\")\n",
    "    \n",
    "r_squared = r2_score(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "pearson_r = pearsonr(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "print(f\"All     R^2: {r_squared:.2f}\\n\",\n",
    "      f\"Pearson's r: {pearson_r[0]:.2f}\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bd1d1-4490-4801-a729-331c00e0a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = round(pearson_r[0] ** 2, 2)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e907866-1c8b-41dc-a346-01c0a53ee3fb",
   "metadata": {},
   "source": [
    "#### Join residuals to the features for _all_ years to visualize the residuals of the features before they were summarized to district level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0e606-93a8-477f-b15d-b9a98d2a84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = (\n",
    "    features_all_years_summary\n",
    "    .set_index(['district', 'year'])\n",
    "    .join(residual_df\n",
    "          .drop('geometry', axis = 1)\n",
    "          .set_index(['district', 'year'])\n",
    "         )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "complete_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f045cfe-8479-41c7-bd04-9247843e4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "tidy = complete_df.melt(id_vars='year').rename(columns=str.title)\n",
    "tidy = tidy[tidy.Variable.isin(['yield_prediction', 'log_yield'])]\n",
    "sns.barplot(x='Year', y='Value', hue='Variable', data=tidy, ax=ax1, ci = None)\n",
    "sns.despine(fig)\n",
    "\n",
    "h, l = ax1.get_legend_handles_labels()\n",
    "ax1.legend(h, ['Predicted Yield', 'Observed Yield'],loc='lower left')\n",
    "\n",
    "plt.savefig(f'images/{feature_file_name}_yield_pred.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149c18b-e563-4575-9c13-db636db64af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"year\", y=\"yield_prediction\", data=complete_df, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476b4e-d3b5-4f79-8d2d-651d6416900a",
   "metadata": {},
   "source": [
    "### Congratulations on completing this analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks-modeling",
   "language": "python",
   "name": "mosaiks-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
