{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe56655",
   "metadata": {},
   "source": [
    "# Modeling Agricultural Variables\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b4f19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyarrow\n",
    "\n",
    "from IPython.display import display\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.axes import Axes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, r2_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import check_random_state, resample\n",
    "\n",
    "\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0591f-583f-4945-b1d2-0323ae715531",
   "metadata": {},
   "source": [
    "## Read in Data\n",
    "\n",
    "We first read in the aggregated features and ground-truth data joined in  feature_preprocessing.ipynb. We separate this aggregated file into two distinct dataframes, *features* and *outcomes*, where features contain aggregated features and outcomes contain our ground-truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f593b6f-5740-41de-b785-3a4555428899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_averaged_features_manual_impute_bfill_modeltrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50344858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sea_unq</th>\n",
       "      <th>index_left</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46302.000000</td>\n",
       "      <td>27.807993</td>\n",
       "      <td>-13.659357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058626</td>\n",
       "      <td>5.269229</td>\n",
       "      <td>7.640386</td>\n",
       "      <td>6.977090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>7</td>\n",
       "      <td>51611.666667</td>\n",
       "      <td>28.634660</td>\n",
       "      <td>-13.772690</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>3.387211</td>\n",
       "      <td>0.689155</td>\n",
       "      <td>7.707512</td>\n",
       "      <td>7.113191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>9</td>\n",
       "      <td>44806.714286</td>\n",
       "      <td>27.406446</td>\n",
       "      <td>-12.905428</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>2.703935</td>\n",
       "      <td>8.486127</td>\n",
       "      <td>-1.408767</td>\n",
       "      <td>7.141370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>10</td>\n",
       "      <td>44644.411765</td>\n",
       "      <td>27.381719</td>\n",
       "      <td>-12.962298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714757</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.354421</td>\n",
       "      <td>6.929734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>12</td>\n",
       "      <td>47769.000000</td>\n",
       "      <td>28.014660</td>\n",
       "      <td>-12.889357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786884</td>\n",
       "      <td>8.509161</td>\n",
       "      <td>2.852125</td>\n",
       "      <td>0.798508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12044 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  sea_unq    index_left        lon        lat       0_1       0_2  \\\n",
       "0  2016.0        1  46302.000000  27.807993 -13.659357  0.000000  0.000000   \n",
       "1  2016.0        7  51611.666667  28.634660 -13.772690  0.001141  0.000329   \n",
       "2  2016.0        9  44806.714286  27.406446 -12.905428  0.000006  0.000006   \n",
       "3  2016.0       10  44644.411765  27.381719 -12.962298  0.000000  0.000000   \n",
       "4  2016.0       12  47769.000000  28.014660 -12.889357  0.000000  0.000000   \n",
       "\n",
       "        0_3       0_4       0_5  ...  prop_mix  log_maize  log_sweetpotatoes  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000   4.058626           5.269229   \n",
       "1  0.000329  0.000329  0.000000  ...  0.181102   3.387211           0.689155   \n",
       "2  0.000006  0.000006  0.000004  ...  0.069018   2.703935           8.486127   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000   3.714757           2.525729   \n",
       "4  0.000000  0.000000  0.000000  ...  0.000000   2.786884           8.509161   \n",
       "\n",
       "   log_groundnuts  log_soybeans  loss_ind  drought_loss_ind  flood_loss_ind  \\\n",
       "0        7.640386      6.977090       0.0               0.0             0.0   \n",
       "1        7.707512      7.113191       1.0               1.0             0.0   \n",
       "2       -1.408767      7.141370       1.0               0.0             0.0   \n",
       "3        3.354421      6.929734       1.0               0.0             0.0   \n",
       "4        2.852125      0.798508       1.0               0.0             0.0   \n",
       "\n",
       "   animal_loss_ind  pest_loss_ind  \n",
       "0              0.0            0.0  \n",
       "1              0.0            0.0  \n",
       "2              0.0            0.0  \n",
       "3              0.0            0.0  \n",
       "4              0.0            0.0  \n",
       "\n",
       "[5 rows x 12044 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe3e8ca-f209-4c76-a209-1c49d83c81a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.157999e-06</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008277e-03</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.590917e-05</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.005251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.113844e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.007540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.700000e-06</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.018616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5      0_6       0_7  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.001141  0.000329  0.000329  0.000329  0.000000  0.00000  0.000000   \n",
       "2  0.000006  0.000006  0.000006  0.000006  0.000004  0.00001  0.000014   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "            0_8       0_9      0_10  ...     999_3     999_4     999_5  \\\n",
       "0  6.157999e-06  0.000207  0.000000  ...  1.000000  1.000000  0.274676   \n",
       "1  1.008277e-03  0.001360  0.002211  ...  0.006789  0.006789  1.000000   \n",
       "2  2.590917e-05  0.000110  0.000109  ...  0.005561  0.005561  0.006391   \n",
       "3  3.113844e-07  0.000012  0.000000  ...  0.005570  0.005570  0.006739   \n",
       "4  9.700000e-06  0.000186  0.000166  ...  1.000000  1.000000  1.000000   \n",
       "\n",
       "      999_6     999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0  1.000000  0.115388  0.002708  0.001319  1.000000  1.000000  1.000000  \n",
       "1  1.000000  1.000000  0.000517  0.000343  0.000396  0.000327  0.004724  \n",
       "2  0.004212  0.003235  0.001937  0.001683  0.001970  0.002340  0.005251  \n",
       "3  0.003991  0.002857  0.001979  0.001435  0.001284  0.001814  0.007540  \n",
       "4  1.000000  0.002690  0.001603  0.000820  0.001269  0.001692  0.018616  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = grouped_features.iloc[:,5:12005]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0640f9c-6682-4d85-866c-f7d2be3135cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_area_harv_ha', 'total_area_lost_ha', 'total_harv_kg',\n",
      "       'yield_kgha', 'frac_area_harv', 'frac_area_loss', 'area_lost_fire',\n",
      "       'maize', 'groundnuts', 'mixed_beans', 'popcorn', 'sorghum', 'soybeans',\n",
      "       'sweet_potatoes', 'bunding', 'monocrop', 'mixture', 'frac_loss_drought',\n",
      "       'frac_loss_flood', 'frac_loss_animal', 'frac_loss_pests',\n",
      "       'frac_loss_soil', 'frac_loss_fert', 'prop_till_plough',\n",
      "       'prop_till_ridge', 'prop_notill', 'prop_hand', 'prop_mono', 'prop_mix',\n",
      "       'log_maize', 'log_sweetpotatoes', 'log_groundnuts', 'log_soybeans',\n",
      "       'loss_ind', 'drought_loss_ind', 'flood_loss_ind', 'animal_loss_ind',\n",
      "       'pest_loss_ind'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "outcomes = grouped_features.iloc[:,12006:]\n",
    "\n",
    "outcomes[\"loss_ind\"].astype('category')\n",
    "outcomes[\"drought_loss_ind\"].astype('category')\n",
    "outcomes['pest_loss_ind'].astype('category')\n",
    "outcomes['animal_loss_ind'].astype('category')\n",
    "outcomes['flood_loss_ind'].astype('category')\n",
    "outcomes.head()\n",
    "\n",
    "print(outcomes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3288b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "We define a model to predict each of our outcome variables on our features for each survey enumeration area (SEA)/year. The `train_and_evaluate_models` function trains and evaluates Ridge Linear Regression models for each target variable specified in the `target_columns` parameter. It handles both categorical and continuous target variables.\n",
    "\n",
    "The function works as follows:\n",
    "\n",
    "1. Read the grouped features and outcomes from a CSV file.\n",
    "2. For each target variable in `target_columns`, select the corresponding target variable data.\n",
    "3. Use `train_test_split` to split the data into training and testing sets.\n",
    "5. Train a Ridge Linear Regression model using RidgeCV with 5-fold cross-validation and a range of alpha values.\n",
    "6. If the target variable is categorical, calculate and print the false positive rate and AUC-ROC. If the target variable is continuous, calculate and print the estimated regularization parameter, training R2 performance, validation R2 performance, and Pearson's correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4870dc-25d2-4eab-8bae-f752633f0150",
   "metadata": {},
   "source": [
    "### Helper Function for Confusion Matrix for Categorical Variables\n",
    "`calculate_confusion_matrix`:\n",
    "This function calculates the confusion matrix for binary classification problems based on the given true labels (`y_true`), predicted values (`y_pred`), and a decision boundary (`decision_boundary`). The decision boundary is used to threshold the predicted values to obtain binary predictions.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "`y_true`: The true labels of the target variable (a pandas Series or numpy array).\n",
    "\n",
    "`y_pred`: The predicted values of the target variable (a numpy array).\n",
    "\n",
    "`decision_boundary`: A float value that serves as the threshold for classifying the predicted values into two classes (0 or 1).\n",
    "\n",
    "\n",
    "The function performs the following steps:\n",
    "1. It adjusts the predicted values by setting them to 1 if they are greater than or equal to the decision boundary, and 0 otherwise.\n",
    "2. It calculates the confusion matrix using the true labels and adjusted predicted values.\n",
    "3. Depending on the shape of the confusion matrix, it extracts the true negatives (tn), false positives (fp), false negatives (fn), and true positives (tp).\n",
    "4. If the shape of the confusion matrix is not (1, 1) or (2, 2), it raises an error.\n",
    "\n",
    "Output: The function returns the values of tn, fp, fn, and tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ac3bf3-e040-420d-8290-7c1aa96c7f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(y_true, y_pred, decision_boundary):\n",
    "    y_pred_adj = np.where(y_pred >= decision_boundary, 1, 0)\n",
    "    cm = confusion_matrix(y_true, y_pred_adj)\n",
    "    if cm.shape == (1, 1):\n",
    "        if y_true.iloc[0] == 0:\n",
    "            tn, fp, fn, tp = cm[0, 0], 0, 0, 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
    "    elif cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        print(\"Unexpected confusion matrix:\")\n",
    "        print(cm)\n",
    "        raise ValueError('Unexpected confusion matrix shape.')\n",
    "    return tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f762185-2e35-48c4-b203-cd5b5c7cd7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomly_select_seas(n, grouped_features):\n",
    "    unique_seas = grouped_features['sea_unq'].unique()\n",
    "    selected_seas = np.random.choice(unique_seas, n, replace=False)\n",
    "    return selected_seas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc11038",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103c6d0b-6ef4-45cf-a477-748618b6d4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the arguments as a dictionary\n",
    "args = {\n",
    "    'target_columns': ['total_area_harv_ha', 'total_area_lost_ha', 'total_harv_kg',\n",
    "       'yield_kgha', 'frac_area_harv', 'frac_area_loss', 'area_lost_fire',\n",
    "       'maize', 'groundnuts', 'mixed_beans', 'popcorn', 'sorghum', 'soybeans',\n",
    "       'sweet_potatoes', 'bunding', 'monocrop', 'mixture', 'frac_loss_drought',\n",
    "       'frac_loss_flood', 'frac_loss_animal', 'frac_loss_pests',\n",
    "       'frac_loss_soil', 'frac_loss_fert', 'prop_till_plough',\n",
    "       'prop_till_ridge', 'prop_notill', 'prop_hand', 'prop_mono', 'prop_mix',\n",
    "       'log_maize', 'log_sweetpotatoes', 'log_groundnuts', 'log_soybeans',\n",
    "       'loss_ind', 'drought_loss_ind', 'flood_loss_ind', 'animal_loss_ind',\n",
    "       'pest_loss_ind'],\n",
    "    'test_size': 0.1,\n",
    "    'categorical_columns':['loss_ind','drought_loss_ind', 'flood_loss_ind','animal_loss_ind','pest_loss_ind'],\n",
    "    'decision_boundaries': [0.3,0.5,0.7],\n",
    "    'sea_ids': grouped_features['sea_unq'],\n",
    "    'validation_size' : 0.1,\n",
    "    'random_state': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c626605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(args):\n",
    "    # Extracting input parameters\n",
    "    target_columns = args['target_columns']\n",
    "    test_size = args.get('test_size', 0.1)\n",
    "    categorical_columns = args['categorical_columns']\n",
    "    decision_boundaries = args['decision_boundaries']\n",
    "    sea_ids = args['sea_ids']\n",
    "    validation_size = args.get('validation_size', 0.1)\n",
    "    random_state = args.get('random_state', False)\n",
    "    \n",
    "    # Read the grouped features from a CSV file\n",
    "    grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_averaged_features_manual_impute_bfill_modeltrain.csv\")\n",
    "\n",
    "    # Extract the relevant features, outcomes, and year columns\n",
    "    features = grouped_features.iloc[:, 5:12005]\n",
    "    outcomes = grouped_features.iloc[:, 12006:]\n",
    "    year = grouped_features.iloc[:, 0]\n",
    "    \n",
    "    # Initialize data structures to store metrics and results\n",
    "    metrics_df = pd.DataFrame(columns=['target_column', 'train_score', 'val_score', 'pearson_coeff'])\n",
    "    models = {}\n",
    "    X_trains = {}\n",
    "    X_tests = {}\n",
    "    y_trains = pd.DataFrame()\n",
    "    y_tests = pd.DataFrame()\n",
    "    y_year = pd.DataFrame()\n",
    "    \n",
    "    # Print the model parameters\n",
    "    print(f\"\\nRunning model with the following parameters:\")\n",
    "    print(f\"Target columns: {target_columns}\")\n",
    "    print(f\"Test size: {test_size}\", f\"Validation size: {validation_size}\")\n",
    "    print(f\"Random State: {random_state}\")\n",
    "\n",
    "    # Iterate over each target column\n",
    "    for target_column in target_columns:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, outcomes[target_column], test_size=test_size, random_state = random_state)\n",
    "        \n",
    "        # Split the training data again to create a validation set\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size, random_state = random_state)\n",
    "        \n",
    "        # Store the training and testing data for each target column\n",
    "        X_trains[target_column] = X_train\n",
    "        X_tests[target_column] = X_test\n",
    "        y_trains[target_column] = y_train\n",
    "        y_tests[target_column] = y_test\n",
    "        y_year[target_column] = year.loc[y_trains.index]\n",
    "\n",
    "        # Train a RidgeCV model with cross-validation\n",
    "        cv = 5\n",
    "        ridge_cv = RidgeCV(cv=cv, alphas=np.logspace(-8, 8, base=10, num=75))\n",
    "        ridge_cv.fit(X_train, y_train)\n",
    "        \n",
    "        # Store the trained model for each target column\n",
    "        models[target_column] = ridge_cv\n",
    "        \n",
    "        # Make predictions on the training and validation data\n",
    "        y_val_pred = ridge_cv.predict(X_val)\n",
    "        y_train_pred = ridge_cv.predict(X_train)\n",
    "\n",
    "        # Perform evaluation for categorical target columns\n",
    "        if target_column in categorical_columns:\n",
    "            for decision_boundary in decision_boundaries:\n",
    "                # Calculate confusion matrix\n",
    "                tn, fp, fn, tp = calculate_confusion_matrix(y_val, y_val_pred, decision_boundary)\n",
    "\n",
    "                # Calculate the false positive rate\n",
    "                false_positive_rate = fp / (fp + tn)\n",
    "\n",
    "                # Calculate AUC-ROC\n",
    "                auc_roc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "                # Print evaluation metrics for categorical columns\n",
    "                print(f\"Target variable: {target_column} (Categorical)\")\n",
    "                print(f\"Decision boundary: {decision_boundary}\")\n",
    "                print(f\"False positive rate: {false_positive_rate:0.2f}\")\n",
    "                print(f\"AUC-ROC: {auc_roc:0.2f}\")\n",
    "                print()\n",
    "        else:\n",
    "            # Calculate Pearson's correlation coefficient\n",
    "            pearson_coeff, _ = pearsonr(y_val, y_val_pred)\n",
    "\n",
    "            # Calculate training R squared\n",
    "            train_r_squared = ridge_cv.score(X_train, y_train)\n",
    "\n",
    "            # Calculate validation R squared\n",
    "            val_r_squared = ridge_cv.score(X_val, y_val)\n",
    "            \n",
    "            # Append metrics to the metrics DataFrame\n",
    "            metrics_df = metrics_df.append({\n",
    "                'target_column': target_column,\n",
    "                'train_score': train_r_squared,\n",
    "                'val_score': val_r_squared,\n",
    "                'pearson_coeff': pearson_coeff}, ignore_index=True)\n",
    "                \n",
    "            # Print evaluation metrics for non-categorical columns\n",
    "            print()\n",
    "            print(f\"Target variable: {target_column}\")\n",
    "            print(f\"Estimated regularization parameter: {ridge_cv.alpha_}\")\n",
    "            print(f\"Training R2 performance: {train_r_squared:0.2f}\")\n",
    "            print(f\"Validation R2 performance: {val_r_squared:0.2f}\")\n",
    "            print(f\"Pearson's correlation coefficient: {pearson_coeff:0.2f}\")\n",
    "            print()\n",
    "\n",
    "    # Return the collected data and results\n",
    "    return X_trains, X_tests, y_trains, y_tests, metrics_df, models, y_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6414f7ab-c9a8-4788-be39-7a2762cd58fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model with the following parameters:\n",
      "Target columns: ['total_area_harv_ha', 'total_area_lost_ha', 'total_harv_kg', 'yield_kgha', 'frac_area_harv', 'frac_area_loss', 'area_lost_fire', 'maize', 'groundnuts', 'mixed_beans', 'popcorn', 'sorghum', 'soybeans', 'sweet_potatoes', 'bunding', 'monocrop', 'mixture', 'frac_loss_drought', 'frac_loss_flood', 'frac_loss_animal', 'frac_loss_pests', 'frac_loss_soil', 'frac_loss_fert', 'prop_till_plough', 'prop_till_ridge', 'prop_notill', 'prop_hand', 'prop_mono', 'prop_mix', 'log_maize', 'log_sweetpotatoes', 'log_groundnuts', 'log_soybeans', 'loss_ind', 'drought_loss_ind', 'flood_loss_ind', 'animal_loss_ind', 'pest_loss_ind']\n",
      "Test size: 0.1 Validation size: 0.1\n",
      "Random State: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: total_area_harv_ha\n",
      "Estimated regularization parameter: 4.45295850994266\n",
      "Training R2 performance: 0.71\n",
      "Validation R2 performance: 0.46\n",
      "Pearson's correlation coefficient: 0.69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: total_area_lost_ha\n",
      "Estimated regularization parameter: 2.706652070033247\n",
      "Training R2 performance: 0.75\n",
      "Validation R2 performance: 0.50\n",
      "Pearson's correlation coefficient: 0.72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: total_harv_kg\n",
      "Estimated regularization parameter: 0.22456979955397763\n",
      "Training R2 performance: 0.86\n",
      "Validation R2 performance: 0.45\n",
      "Pearson's correlation coefficient: 0.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: yield_kgha\n",
      "Estimated regularization parameter: 1.6451905877536674\n",
      "Training R2 performance: 0.74\n",
      "Validation R2 performance: 0.62\n",
      "Pearson's correlation coefficient: 0.80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_area_harv\n",
      "Estimated regularization parameter: 4.45295850994266\n",
      "Training R2 performance: 0.64\n",
      "Validation R2 performance: 0.46\n",
      "Pearson's correlation coefficient: 0.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_area_loss\n",
      "Estimated regularization parameter: 4.45295850994266\n",
      "Training R2 performance: 0.64\n",
      "Validation R2 performance: 0.46\n",
      "Pearson's correlation coefficient: 0.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellesmith/.conda/envs/mosaiks/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: area_lost_fire\n",
      "Estimated regularization parameter: 100000000.0\n",
      "Training R2 performance: 0.00\n",
      "Validation R2 performance: 0.00\n",
      "Pearson's correlation coefficient: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: maize\n",
      "Estimated regularization parameter: 1.0\n",
      "Training R2 performance: 0.77\n",
      "Validation R2 performance: 0.61\n",
      "Pearson's correlation coefficient: 0.79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: groundnuts\n",
      "Estimated regularization parameter: 32.62222009711673\n",
      "Training R2 performance: 0.52\n",
      "Validation R2 performance: 0.44\n",
      "Pearson's correlation coefficient: 0.67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: mixed_beans\n",
      "Estimated regularization parameter: 53.66976945540476\n",
      "Training R2 performance: 0.34\n",
      "Validation R2 performance: 0.22\n",
      "Pearson's correlation coefficient: 0.49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: popcorn\n",
      "Estimated regularization parameter: 646.8607661546321\n",
      "Training R2 performance: 0.13\n",
      "Validation R2 performance: -0.04\n",
      "Pearson's correlation coefficient: 0.08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: sorghum\n",
      "Estimated regularization parameter: 393.18287557057704\n",
      "Training R2 performance: 0.12\n",
      "Validation R2 performance: -0.01\n",
      "Pearson's correlation coefficient: 0.10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: soybeans\n",
      "Estimated regularization parameter: 19.828839491270752\n",
      "Training R2 performance: 0.42\n",
      "Validation R2 performance: 0.17\n",
      "Pearson's correlation coefficient: 0.44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: sweet_potatoes\n",
      "Estimated regularization parameter: 32.62222009711673\n",
      "Training R2 performance: 0.46\n",
      "Validation R2 performance: 0.30\n",
      "Pearson's correlation coefficient: 0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: bunding\n",
      "Estimated regularization parameter: 100000000.0\n",
      "Training R2 performance: 0.00\n",
      "Validation R2 performance: -0.02\n",
      "Pearson's correlation coefficient: 0.10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: monocrop\n",
      "Estimated regularization parameter: 12.052609368708413\n",
      "Training R2 performance: 0.59\n",
      "Validation R2 performance: 0.51\n",
      "Pearson's correlation coefficient: 0.73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: mixture\n",
      "Estimated regularization parameter: 1064.2092440647268\n",
      "Training R2 performance: 0.08\n",
      "Validation R2 performance: 0.06\n",
      "Pearson's correlation coefficient: 0.29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_loss_drought\n",
      "Estimated regularization parameter: 238.98925662310526\n",
      "Training R2 performance: 0.42\n",
      "Validation R2 performance: 0.38\n",
      "Pearson's correlation coefficient: 0.62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_loss_flood\n",
      "Estimated regularization parameter: 688395.206964551\n",
      "Training R2 performance: 0.00\n",
      "Validation R2 performance: -0.00\n",
      "Pearson's correlation coefficient: -0.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_loss_animal\n",
      "Estimated regularization parameter: 21102.034285685964\n",
      "Training R2 performance: 0.10\n",
      "Validation R2 performance: -0.12\n",
      "Pearson's correlation coefficient: -0.10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_loss_pests\n",
      "Estimated regularization parameter: 100000000.0\n",
      "Training R2 performance: 0.00\n",
      "Validation R2 performance: -0.03\n",
      "Pearson's correlation coefficient: -0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_loss_soil\n",
      "Estimated regularization parameter: 7796.360130405253\n",
      "Training R2 performance: 0.07\n",
      "Validation R2 performance: 0.01\n",
      "Pearson's correlation coefficient: 0.12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_loss_fert\n",
      "Estimated regularization parameter: 254334.57613046587\n",
      "Training R2 performance: 0.03\n",
      "Validation R2 performance: 0.01\n",
      "Pearson's correlation coefficient: 0.29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: prop_till_plough\n",
      "Estimated regularization parameter: 7.3259654282152304\n",
      "Training R2 performance: 0.78\n",
      "Validation R2 performance: 0.71\n",
      "Pearson's correlation coefficient: 0.85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: prop_till_ridge\n",
      "Estimated regularization parameter: 0.6078323128297236\n",
      "Training R2 performance: 0.77\n",
      "Validation R2 performance: 0.54\n",
      "Pearson's correlation coefficient: 0.74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: prop_notill\n",
      "Estimated regularization parameter: 100000000.0\n",
      "Training R2 performance: 0.00\n",
      "Validation R2 performance: -0.75\n",
      "Pearson's correlation coefficient: 0.05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: prop_hand\n",
      "Estimated regularization parameter: 2.706652070033247\n",
      "Training R2 performance: 0.60\n",
      "Validation R2 performance: 0.33\n",
      "Pearson's correlation coefficient: 0.58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: prop_mono\n",
      "Estimated regularization parameter: 0.369460120519931\n",
      "Training R2 performance: 0.90\n",
      "Validation R2 performance: 0.56\n",
      "Pearson's correlation coefficient: 0.76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: prop_mix\n",
      "Estimated regularization parameter: 154592.77364194783\n",
      "Training R2 performance: 0.02\n",
      "Validation R2 performance: -0.09\n",
      "Pearson's correlation coefficient: -0.02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: log_maize\n",
      "Estimated regularization parameter: 1.6451905877536674\n",
      "Training R2 performance: 0.77\n",
      "Validation R2 performance: 0.71\n",
      "Pearson's correlation coefficient: 0.84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: log_sweetpotatoes\n",
      "Estimated regularization parameter: 7.3259654282152304\n",
      "Training R2 performance: 0.51\n",
      "Validation R2 performance: 0.36\n",
      "Pearson's correlation coefficient: 0.60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: log_groundnuts\n",
      "Estimated regularization parameter: 7.3259654282152304\n",
      "Training R2 performance: 0.58\n",
      "Validation R2 performance: 0.42\n",
      "Pearson's correlation coefficient: 0.66\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064546/1409447999.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: log_soybeans\n",
      "Estimated regularization parameter: 12.052609368708413\n",
      "Training R2 performance: 0.40\n",
      "Validation R2 performance: -0.07\n",
      "Pearson's correlation coefficient: 0.20\n",
      "\n",
      "Target variable: loss_ind (Categorical)\n",
      "Decision boundary: 0.3\n",
      "False positive rate: 0.83\n",
      "AUC-ROC: 0.84\n",
      "\n",
      "Target variable: loss_ind (Categorical)\n",
      "Decision boundary: 0.5\n",
      "False positive rate: 0.33\n",
      "AUC-ROC: 0.84\n",
      "\n",
      "Target variable: loss_ind (Categorical)\n",
      "Decision boundary: 0.7\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.84\n",
      "\n",
      "Target variable: drought_loss_ind (Categorical)\n",
      "Decision boundary: 0.3\n",
      "False positive rate: 0.33\n",
      "AUC-ROC: 0.79\n",
      "\n",
      "Target variable: drought_loss_ind (Categorical)\n",
      "Decision boundary: 0.5\n",
      "False positive rate: 0.03\n",
      "AUC-ROC: 0.79\n",
      "\n",
      "Target variable: drought_loss_ind (Categorical)\n",
      "Decision boundary: 0.7\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.79\n",
      "\n",
      "Target variable: flood_loss_ind (Categorical)\n",
      "Decision boundary: 0.3\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.46\n",
      "\n",
      "Target variable: flood_loss_ind (Categorical)\n",
      "Decision boundary: 0.5\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.46\n",
      "\n",
      "Target variable: flood_loss_ind (Categorical)\n",
      "Decision boundary: 0.7\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.46\n",
      "\n",
      "Target variable: animal_loss_ind (Categorical)\n",
      "Decision boundary: 0.3\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.42\n",
      "\n",
      "Target variable: animal_loss_ind (Categorical)\n",
      "Decision boundary: 0.5\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.42\n",
      "\n",
      "Target variable: animal_loss_ind (Categorical)\n",
      "Decision boundary: 0.7\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.42\n",
      "\n",
      "Target variable: pest_loss_ind (Categorical)\n",
      "Decision boundary: 0.3\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.42\n",
      "\n",
      "Target variable: pest_loss_ind (Categorical)\n",
      "Decision boundary: 0.5\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.42\n",
      "\n",
      "Target variable: pest_loss_ind (Categorical)\n",
      "Decision boundary: 0.7\n",
      "False positive rate: 0.00\n",
      "AUC-ROC: 0.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_trains, X_tests, y_trains, y_tests, metrics_df, models, y_year  = train_and_evaluate_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30906c",
   "metadata": {},
   "source": [
    "### Train Set\n",
    "\n",
    "After training models for each specified target variable in `target_columns`, we employ these models to create and store predictions and R^2 scores for each target column on our training data. Our training data has been aggregated by survey enumeration area (SEA) and year, which means that each of the 436 rows of `y_pred_train` represents a prediction made for a particular SEA during a particular year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eed876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dataframes for storing the predicted values and R2 scores\n",
    "y_pred_train = pd.DataFrame()\n",
    "r2_train = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Get the training data for the target column\n",
    "    X_train_column = X_trains[target_column]\n",
    "    y_train_column = y_trains[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred_train_column = np.maximum(model.predict(X_train_column), 0)\n",
    "    \n",
    "    # Compute the R2 score for the target column\n",
    "    r2_train_column = r2_score(y_train_column, y_pred_train_column)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred_train[target_column] = y_pred_train_column\n",
    "    r2_train[target_column] = [r2_train_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dca86fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>total_harv_kg</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>area_lost_fire</th>\n",
       "      <th>maize</th>\n",
       "      <th>groundnuts</th>\n",
       "      <th>mixed_beans</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>935.813979</td>\n",
       "      <td>1289.657304</td>\n",
       "      <td>35053.226702</td>\n",
       "      <td>156.162266</td>\n",
       "      <td>0.443569</td>\n",
       "      <td>0.556431</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>218.023574</td>\n",
       "      <td>82.502810</td>\n",
       "      <td>238.919371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030480</td>\n",
       "      <td>3.209652</td>\n",
       "      <td>4.319458</td>\n",
       "      <td>3.250281</td>\n",
       "      <td>4.029624</td>\n",
       "      <td>0.953530</td>\n",
       "      <td>0.307020</td>\n",
       "      <td>0.038384</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.045872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1233.538655</td>\n",
       "      <td>2082.036541</td>\n",
       "      <td>47873.340030</td>\n",
       "      <td>38.363936</td>\n",
       "      <td>0.372473</td>\n",
       "      <td>0.627527</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1064.982263</td>\n",
       "      <td>531.659898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>3.106022</td>\n",
       "      <td>3.847343</td>\n",
       "      <td>2.992500</td>\n",
       "      <td>5.859174</td>\n",
       "      <td>1.007499</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>0.012468</td>\n",
       "      <td>0.045877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621.752010</td>\n",
       "      <td>500.072322</td>\n",
       "      <td>107092.754235</td>\n",
       "      <td>1373.119866</td>\n",
       "      <td>0.676181</td>\n",
       "      <td>0.323819</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>1628.506074</td>\n",
       "      <td>2000.871383</td>\n",
       "      <td>518.657605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>6.483269</td>\n",
       "      <td>6.436786</td>\n",
       "      <td>5.588523</td>\n",
       "      <td>5.917981</td>\n",
       "      <td>0.882286</td>\n",
       "      <td>0.688257</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>616.200430</td>\n",
       "      <td>900.484352</td>\n",
       "      <td>82401.302522</td>\n",
       "      <td>2307.667465</td>\n",
       "      <td>0.758817</td>\n",
       "      <td>0.241183</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>2230.649639</td>\n",
       "      <td>3670.513302</td>\n",
       "      <td>906.540039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>6.507477</td>\n",
       "      <td>6.202475</td>\n",
       "      <td>7.400402</td>\n",
       "      <td>7.839794</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>0.253419</td>\n",
       "      <td>0.038917</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.045877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125761.251107</td>\n",
       "      <td>2429.729313</td>\n",
       "      <td>1.012649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013501</td>\n",
       "      <td>2417.996095</td>\n",
       "      <td>3546.945204</td>\n",
       "      <td>1197.419294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>8.397025</td>\n",
       "      <td>9.730469</td>\n",
       "      <td>9.246450</td>\n",
       "      <td>8.069045</td>\n",
       "      <td>0.404031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.045869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_area_harv_ha  total_area_lost_ha  total_harv_kg   yield_kgha  \\\n",
       "0          935.813979         1289.657304   35053.226702   156.162266   \n",
       "1         1233.538655         2082.036541   47873.340030    38.363936   \n",
       "2          621.752010          500.072322  107092.754235  1373.119866   \n",
       "3          616.200430          900.484352   82401.302522  2307.667465   \n",
       "4            0.000000            0.000000  125761.251107  2429.729313   \n",
       "\n",
       "   frac_area_harv  frac_area_loss  area_lost_fire        maize   groundnuts  \\\n",
       "0        0.443569        0.556431        0.013532   218.023574    82.502810   \n",
       "1        0.372473        0.627527        0.013496     0.000000  1064.982263   \n",
       "2        0.676181        0.323819        0.013581  1628.506074  2000.871383   \n",
       "3        0.758817        0.241183        0.013554  2230.649639  3670.513302   \n",
       "4        1.012649        0.000000        0.013501  2417.996095  3546.945204   \n",
       "\n",
       "   mixed_beans  ...  prop_mix  log_maize  log_sweetpotatoes  log_groundnuts  \\\n",
       "0   238.919371  ...  0.030480   3.209652           4.319458        3.250281   \n",
       "1   531.659898  ...  0.037534   3.106022           3.847343        2.992500   \n",
       "2   518.657605  ...  0.019694   6.483269           6.436786        5.588523   \n",
       "3   906.540039  ...  0.022664   6.507477           6.202475        7.400402   \n",
       "4  1197.419294  ...  0.035116   8.397025           9.730469        9.246450   \n",
       "\n",
       "   log_soybeans  loss_ind  drought_loss_ind  flood_loss_ind  animal_loss_ind  \\\n",
       "0      4.029624  0.953530          0.307020        0.038384         0.027210   \n",
       "1      5.859174  1.007499          0.084682        0.031714         0.012468   \n",
       "2      5.917981  0.882286          0.688257        0.044518         0.000000   \n",
       "3      7.839794  0.523251          0.253419        0.038917         0.005693   \n",
       "4      8.069045  0.404031          0.000000        0.034460         0.031894   \n",
       "\n",
       "   pest_loss_ind  \n",
       "0       0.045872  \n",
       "1       0.045877  \n",
       "2       0.045868  \n",
       "3       0.045877  \n",
       "4       0.045869  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cafff",
   "metadata": {},
   "source": [
    "### Visualize Performance of Train Set \n",
    "\n",
    "We visualize performances of the training set through scatterplots of our predicted values versus ground-truthed values. These scatterplots include a regression line, and display the R^2 value for the selected variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e49e967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc527d6a60014389b3f829e218905e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Variable:', options=('total_area_harv_ha', 'total_area_lost_ha', 'total_hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of variable names from the dataframes\n",
    "variable_names = list(y_pred_train.columns)\n",
    "\n",
    "# Create the dropdown widget\n",
    "variable_dropdown = widgets.Dropdown(options=variable_names, description='Variable:')\n",
    "\n",
    "# create a container widget to hold the dropdown and the plot\n",
    "container = widgets.VBox(children=[variable_dropdown])\n",
    "\n",
    "# Create an output widget to display the plot\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "# Define a function to update the plot based on the selected variable\n",
    "def update_plot_train(variable):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        # Create the scatterplot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(y_pred_train[variable], y_trains[variable])\n",
    "        ax.axline([0, 0], [1, 1], c=\"k\")\n",
    "\n",
    "        # Extract the R2 value from the r2_train dataframe\n",
    "        r2_value = r2_train[variable]\n",
    "        r2_value = round(r2_value, 2)\n",
    "\n",
    "        # Set the title with the current title as a subtitle and the new title as \"Variable: [variable]\"\n",
    "        sub_title = f\"Model applied to train data n = {len(y_trains)}, R$^2$ = {r2_value}\"\n",
    "        title = f\"Variable: {variable}\"\n",
    "        plt.title(sub_title, fontsize=12, y=1.0, loc='left')\n",
    "        plt.title(title, fontsize=14, y=1.15, loc='center')\n",
    "\n",
    "        # Set x and y axis labels\n",
    "        ax.set_xlabel(\"Predicted\", fontsize=15)\n",
    "        ax.set_ylabel(\"Ground Truth\", fontsize=15)\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "# Define a function to update the dropdown options when the variable names change\n",
    "def update_dropdown_options(change):\n",
    "    variable_dropdown.options = variable_names\n",
    "\n",
    "# Call the update_plot_train function with the initial value of the dropdown\n",
    "update_plot_train(variable_dropdown.value)\n",
    "\n",
    "# Register the event handler to update the dropdown options\n",
    "variable_dropdown.observe(update_dropdown_options, 'options')\n",
    "\n",
    "# Set up the interaction between the dropdown and the plot\n",
    "def dropdown_eventhandler(change):\n",
    "    variable = change.new\n",
    "    update_plot_train(variable)\n",
    "\n",
    "variable_dropdown.observe(dropdown_eventhandler, 'value')\n",
    "\n",
    "# Display the dropdown and the plot\n",
    "display(widgets.VBox([variable_dropdown, plot_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878d7f6",
   "metadata": {},
   "source": [
    "### Test Set \n",
    "\n",
    "Next, we employ these models to create and store predictions and R^2 scores for each target column on our testing data. Again, our testing data has been aggregated by survey enumeration area (SEA) and year, which means that each of the 436 rows of `y_pred_test` represents a prediction made for a particular SEA during a particular year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "309523bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred_test = pd.DataFrame()\n",
    "r2_test = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Get the training data for the target column\n",
    "    X_test_column = X_tests[target_column]\n",
    "    y_test_column = y_tests[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred_test_column = np.maximum(model.predict(X_test_column), 0)\n",
    "    \n",
    "    # Compute the R2 score for the target column\n",
    "    r2_test_column = r2_score(y_test_column, y_pred_test_column)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred_test[target_column] = y_pred_test_column\n",
    "    r2_test[target_column] = [r2_test_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fe58c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>total_harv_kg</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>area_lost_fire</th>\n",
       "      <th>maize</th>\n",
       "      <th>groundnuts</th>\n",
       "      <th>mixed_beans</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917.813698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111435.011634</td>\n",
       "      <td>341.454985</td>\n",
       "      <td>0.976549</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>377.651780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>4.555314</td>\n",
       "      <td>6.258815</td>\n",
       "      <td>3.184263</td>\n",
       "      <td>4.502035</td>\n",
       "      <td>1.226299</td>\n",
       "      <td>1.027636</td>\n",
       "      <td>0.048856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>791.052135</td>\n",
       "      <td>11.192504</td>\n",
       "      <td>45102.609459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683158</td>\n",
       "      <td>0.316842</td>\n",
       "      <td>0.013655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.951948</td>\n",
       "      <td>5.282578</td>\n",
       "      <td>3.860021</td>\n",
       "      <td>5.214353</td>\n",
       "      <td>1.272964</td>\n",
       "      <td>1.019560</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>391.878285</td>\n",
       "      <td>254.997234</td>\n",
       "      <td>102768.847047</td>\n",
       "      <td>1233.565136</td>\n",
       "      <td>0.658221</td>\n",
       "      <td>0.341779</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>1362.083833</td>\n",
       "      <td>1948.804512</td>\n",
       "      <td>376.208639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>6.484091</td>\n",
       "      <td>7.141421</td>\n",
       "      <td>6.322030</td>\n",
       "      <td>5.899069</td>\n",
       "      <td>0.915167</td>\n",
       "      <td>0.657961</td>\n",
       "      <td>0.044257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.230064</td>\n",
       "      <td>1257.836838</td>\n",
       "      <td>52782.728788</td>\n",
       "      <td>1007.351629</td>\n",
       "      <td>0.545082</td>\n",
       "      <td>0.454918</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>1035.826396</td>\n",
       "      <td>1341.860010</td>\n",
       "      <td>620.285469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>3.937893</td>\n",
       "      <td>4.197342</td>\n",
       "      <td>3.719265</td>\n",
       "      <td>5.937764</td>\n",
       "      <td>0.760854</td>\n",
       "      <td>0.097803</td>\n",
       "      <td>0.035037</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>0.045877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>782.274013</td>\n",
       "      <td>939.409659</td>\n",
       "      <td>88759.321211</td>\n",
       "      <td>604.816086</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.495730</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>663.225058</td>\n",
       "      <td>970.482632</td>\n",
       "      <td>10.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015720</td>\n",
       "      <td>5.068544</td>\n",
       "      <td>7.069180</td>\n",
       "      <td>5.034843</td>\n",
       "      <td>5.354388</td>\n",
       "      <td>1.140324</td>\n",
       "      <td>0.812087</td>\n",
       "      <td>0.046157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1012.046607</td>\n",
       "      <td>1648.383404</td>\n",
       "      <td>25370.726266</td>\n",
       "      <td>360.449625</td>\n",
       "      <td>0.526944</td>\n",
       "      <td>0.473056</td>\n",
       "      <td>0.013562</td>\n",
       "      <td>518.124264</td>\n",
       "      <td>17.648074</td>\n",
       "      <td>9.207263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023304</td>\n",
       "      <td>3.477883</td>\n",
       "      <td>5.547287</td>\n",
       "      <td>2.951858</td>\n",
       "      <td>5.661399</td>\n",
       "      <td>0.812376</td>\n",
       "      <td>0.366215</td>\n",
       "      <td>0.039943</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.045873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>477.660820</td>\n",
       "      <td>680.724448</td>\n",
       "      <td>106965.723669</td>\n",
       "      <td>2283.333963</td>\n",
       "      <td>0.764828</td>\n",
       "      <td>0.235172</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>2649.313718</td>\n",
       "      <td>2604.863987</td>\n",
       "      <td>1012.033003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036449</td>\n",
       "      <td>7.163687</td>\n",
       "      <td>6.449258</td>\n",
       "      <td>7.386272</td>\n",
       "      <td>6.430003</td>\n",
       "      <td>0.633261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031394</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.045878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2406.583182</td>\n",
       "      <td>3806.406288</td>\n",
       "      <td>8009.244938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323951</td>\n",
       "      <td>0.676049</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270.207776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>3.225395</td>\n",
       "      <td>1.285908</td>\n",
       "      <td>3.208963</td>\n",
       "      <td>1.155907</td>\n",
       "      <td>1.018510</td>\n",
       "      <td>0.043463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124372.652236</td>\n",
       "      <td>3315.658773</td>\n",
       "      <td>0.957808</td>\n",
       "      <td>0.042192</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>3789.423892</td>\n",
       "      <td>3797.084231</td>\n",
       "      <td>1320.336113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031279</td>\n",
       "      <td>9.312883</td>\n",
       "      <td>8.896121</td>\n",
       "      <td>9.544446</td>\n",
       "      <td>8.501795</td>\n",
       "      <td>0.558353</td>\n",
       "      <td>0.283116</td>\n",
       "      <td>0.038429</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1023.940828</td>\n",
       "      <td>1303.896108</td>\n",
       "      <td>15499.150907</td>\n",
       "      <td>42.101692</td>\n",
       "      <td>0.610987</td>\n",
       "      <td>0.389013</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>804.269856</td>\n",
       "      <td>420.579618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038884</td>\n",
       "      <td>3.313278</td>\n",
       "      <td>5.392915</td>\n",
       "      <td>5.632121</td>\n",
       "      <td>5.263136</td>\n",
       "      <td>0.976424</td>\n",
       "      <td>0.032197</td>\n",
       "      <td>0.032195</td>\n",
       "      <td>0.034917</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2087.606010</td>\n",
       "      <td>2903.670758</td>\n",
       "      <td>12814.638768</td>\n",
       "      <td>276.356046</td>\n",
       "      <td>0.524615</td>\n",
       "      <td>0.475385</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>347.996476</td>\n",
       "      <td>204.098585</td>\n",
       "      <td>320.954164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022144</td>\n",
       "      <td>2.263307</td>\n",
       "      <td>3.255160</td>\n",
       "      <td>3.503113</td>\n",
       "      <td>5.579981</td>\n",
       "      <td>0.855655</td>\n",
       "      <td>0.701376</td>\n",
       "      <td>0.043062</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.045872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>246.642609</td>\n",
       "      <td>295.384218</td>\n",
       "      <td>73567.331600</td>\n",
       "      <td>1953.788787</td>\n",
       "      <td>0.745532</td>\n",
       "      <td>0.254468</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>2324.035855</td>\n",
       "      <td>1568.900435</td>\n",
       "      <td>1001.552036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>6.846642</td>\n",
       "      <td>6.949398</td>\n",
       "      <td>5.998092</td>\n",
       "      <td>5.973284</td>\n",
       "      <td>0.506431</td>\n",
       "      <td>0.313606</td>\n",
       "      <td>0.039617</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.045871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>211.865431</td>\n",
       "      <td>153.358853</td>\n",
       "      <td>106898.560812</td>\n",
       "      <td>1351.147317</td>\n",
       "      <td>0.630341</td>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>1383.686812</td>\n",
       "      <td>2729.175940</td>\n",
       "      <td>210.789878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>6.975495</td>\n",
       "      <td>8.462320</td>\n",
       "      <td>7.513970</td>\n",
       "      <td>5.180537</td>\n",
       "      <td>1.073497</td>\n",
       "      <td>1.000065</td>\n",
       "      <td>0.050542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135781.862503</td>\n",
       "      <td>1828.535407</td>\n",
       "      <td>0.771858</td>\n",
       "      <td>0.228142</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>1888.996652</td>\n",
       "      <td>2578.726344</td>\n",
       "      <td>541.614588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024347</td>\n",
       "      <td>7.343236</td>\n",
       "      <td>8.790256</td>\n",
       "      <td>6.575817</td>\n",
       "      <td>7.349766</td>\n",
       "      <td>0.544167</td>\n",
       "      <td>0.296758</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>337.653329</td>\n",
       "      <td>391.567155</td>\n",
       "      <td>38811.943291</td>\n",
       "      <td>1350.159361</td>\n",
       "      <td>0.898466</td>\n",
       "      <td>0.101534</td>\n",
       "      <td>0.013526</td>\n",
       "      <td>1446.951540</td>\n",
       "      <td>1985.864104</td>\n",
       "      <td>759.061478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>5.418756</td>\n",
       "      <td>8.274494</td>\n",
       "      <td>6.837206</td>\n",
       "      <td>7.786200</td>\n",
       "      <td>0.417380</td>\n",
       "      <td>0.153828</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>0.025182</td>\n",
       "      <td>0.045871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>887.544742</td>\n",
       "      <td>1342.588616</td>\n",
       "      <td>125552.332799</td>\n",
       "      <td>1153.169715</td>\n",
       "      <td>0.615922</td>\n",
       "      <td>0.384078</td>\n",
       "      <td>0.013604</td>\n",
       "      <td>1124.928859</td>\n",
       "      <td>2884.691763</td>\n",
       "      <td>200.420903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>5.518825</td>\n",
       "      <td>5.538723</td>\n",
       "      <td>6.820045</td>\n",
       "      <td>5.312323</td>\n",
       "      <td>0.776193</td>\n",
       "      <td>0.581857</td>\n",
       "      <td>0.039907</td>\n",
       "      <td>0.027084</td>\n",
       "      <td>0.045891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>456.483816</td>\n",
       "      <td>894.941753</td>\n",
       "      <td>68333.352586</td>\n",
       "      <td>1257.403058</td>\n",
       "      <td>0.579636</td>\n",
       "      <td>0.420364</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>1336.059679</td>\n",
       "      <td>910.683492</td>\n",
       "      <td>274.406938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>4.597920</td>\n",
       "      <td>5.421360</td>\n",
       "      <td>4.070116</td>\n",
       "      <td>6.098096</td>\n",
       "      <td>0.659131</td>\n",
       "      <td>0.131644</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>599.104697</td>\n",
       "      <td>648.774888</td>\n",
       "      <td>83709.964736</td>\n",
       "      <td>897.514041</td>\n",
       "      <td>0.664001</td>\n",
       "      <td>0.335999</td>\n",
       "      <td>0.013606</td>\n",
       "      <td>1283.326690</td>\n",
       "      <td>619.609989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>5.468874</td>\n",
       "      <td>6.623903</td>\n",
       "      <td>5.688185</td>\n",
       "      <td>6.340779</td>\n",
       "      <td>1.191541</td>\n",
       "      <td>0.866261</td>\n",
       "      <td>0.046186</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>69.609617</td>\n",
       "      <td>62.961193</td>\n",
       "      <td>96840.306740</td>\n",
       "      <td>1885.195467</td>\n",
       "      <td>0.732238</td>\n",
       "      <td>0.267762</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>1885.028807</td>\n",
       "      <td>2682.487674</td>\n",
       "      <td>798.610392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>7.448874</td>\n",
       "      <td>7.165144</td>\n",
       "      <td>7.786471</td>\n",
       "      <td>6.862246</td>\n",
       "      <td>0.616496</td>\n",
       "      <td>0.538286</td>\n",
       "      <td>0.043068</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.045869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>390.055889</td>\n",
       "      <td>624.949924</td>\n",
       "      <td>48303.104900</td>\n",
       "      <td>1262.487637</td>\n",
       "      <td>0.835615</td>\n",
       "      <td>0.164385</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>1247.354538</td>\n",
       "      <td>1541.669367</td>\n",
       "      <td>775.987479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>5.078651</td>\n",
       "      <td>7.216555</td>\n",
       "      <td>6.441163</td>\n",
       "      <td>6.136288</td>\n",
       "      <td>0.510306</td>\n",
       "      <td>0.153104</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>843.589548</td>\n",
       "      <td>170.376636</td>\n",
       "      <td>50329.008979</td>\n",
       "      <td>104.400834</td>\n",
       "      <td>0.941261</td>\n",
       "      <td>0.058739</td>\n",
       "      <td>0.013589</td>\n",
       "      <td>215.857125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>3.495453</td>\n",
       "      <td>5.851540</td>\n",
       "      <td>3.803929</td>\n",
       "      <td>7.076280</td>\n",
       "      <td>0.882351</td>\n",
       "      <td>0.613510</td>\n",
       "      <td>0.042883</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>0.045869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>550.719520</td>\n",
       "      <td>758.190677</td>\n",
       "      <td>96405.027139</td>\n",
       "      <td>2198.644818</td>\n",
       "      <td>0.798929</td>\n",
       "      <td>0.201071</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>1859.774255</td>\n",
       "      <td>2777.993902</td>\n",
       "      <td>609.016249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025768</td>\n",
       "      <td>6.422960</td>\n",
       "      <td>8.260820</td>\n",
       "      <td>6.678807</td>\n",
       "      <td>6.775273</td>\n",
       "      <td>0.568074</td>\n",
       "      <td>0.154772</td>\n",
       "      <td>0.040639</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.045866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>845.842910</td>\n",
       "      <td>778.108356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663120</td>\n",
       "      <td>0.336880</td>\n",
       "      <td>0.013524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>2.046280</td>\n",
       "      <td>0.529849</td>\n",
       "      <td>5.326981</td>\n",
       "      <td>8.492448</td>\n",
       "      <td>0.968612</td>\n",
       "      <td>1.009770</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.216427</td>\n",
       "      <td>0.045863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1276.713377</td>\n",
       "      <td>975.612574</td>\n",
       "      <td>37194.443699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701378</td>\n",
       "      <td>0.298622</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>2.564601</td>\n",
       "      <td>6.279308</td>\n",
       "      <td>3.762312</td>\n",
       "      <td>6.025932</td>\n",
       "      <td>1.067652</td>\n",
       "      <td>0.942968</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>377.152503</td>\n",
       "      <td>356.603209</td>\n",
       "      <td>152190.006962</td>\n",
       "      <td>2269.060483</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.255126</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>2416.808524</td>\n",
       "      <td>2232.310359</td>\n",
       "      <td>1408.261197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019792</td>\n",
       "      <td>8.127717</td>\n",
       "      <td>6.182218</td>\n",
       "      <td>7.222143</td>\n",
       "      <td>4.691123</td>\n",
       "      <td>0.899276</td>\n",
       "      <td>1.201639</td>\n",
       "      <td>0.045460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>525.534301</td>\n",
       "      <td>593.259734</td>\n",
       "      <td>59300.439097</td>\n",
       "      <td>1364.238503</td>\n",
       "      <td>0.695911</td>\n",
       "      <td>0.304089</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>1585.910933</td>\n",
       "      <td>1757.338521</td>\n",
       "      <td>1095.808342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>5.944029</td>\n",
       "      <td>5.970674</td>\n",
       "      <td>5.842817</td>\n",
       "      <td>6.954791</td>\n",
       "      <td>0.743477</td>\n",
       "      <td>0.529447</td>\n",
       "      <td>0.040943</td>\n",
       "      <td>0.012575</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>775.060962</td>\n",
       "      <td>1081.205030</td>\n",
       "      <td>91911.650393</td>\n",
       "      <td>1013.107656</td>\n",
       "      <td>0.659634</td>\n",
       "      <td>0.340366</td>\n",
       "      <td>0.013586</td>\n",
       "      <td>1444.087425</td>\n",
       "      <td>1264.067085</td>\n",
       "      <td>284.334153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>5.262298</td>\n",
       "      <td>6.512145</td>\n",
       "      <td>5.697985</td>\n",
       "      <td>6.819136</td>\n",
       "      <td>1.013178</td>\n",
       "      <td>0.750834</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>0.045877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>685.871220</td>\n",
       "      <td>455.991173</td>\n",
       "      <td>13439.693327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775257</td>\n",
       "      <td>0.224743</td>\n",
       "      <td>0.013503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045248</td>\n",
       "      <td>1.961009</td>\n",
       "      <td>6.117271</td>\n",
       "      <td>3.966425</td>\n",
       "      <td>4.952211</td>\n",
       "      <td>0.953349</td>\n",
       "      <td>0.564568</td>\n",
       "      <td>0.041701</td>\n",
       "      <td>0.115129</td>\n",
       "      <td>0.045851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>339.517302</td>\n",
       "      <td>495.824935</td>\n",
       "      <td>43176.115993</td>\n",
       "      <td>1667.822258</td>\n",
       "      <td>0.833559</td>\n",
       "      <td>0.166441</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>1886.525514</td>\n",
       "      <td>2127.128838</td>\n",
       "      <td>843.361463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027745</td>\n",
       "      <td>5.948853</td>\n",
       "      <td>7.445899</td>\n",
       "      <td>6.466916</td>\n",
       "      <td>7.495386</td>\n",
       "      <td>0.427354</td>\n",
       "      <td>0.115067</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99878.381851</td>\n",
       "      <td>3221.966937</td>\n",
       "      <td>0.900024</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>3479.624842</td>\n",
       "      <td>2179.811559</td>\n",
       "      <td>974.453678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>8.088861</td>\n",
       "      <td>9.094320</td>\n",
       "      <td>5.299040</td>\n",
       "      <td>7.858621</td>\n",
       "      <td>0.580968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.095408</td>\n",
       "      <td>0.045866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>292.377767</td>\n",
       "      <td>458.391306</td>\n",
       "      <td>102310.415215</td>\n",
       "      <td>1573.027340</td>\n",
       "      <td>0.623112</td>\n",
       "      <td>0.376888</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>1722.415388</td>\n",
       "      <td>2813.208796</td>\n",
       "      <td>220.548709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>7.091323</td>\n",
       "      <td>8.198421</td>\n",
       "      <td>7.693508</td>\n",
       "      <td>4.774155</td>\n",
       "      <td>1.054561</td>\n",
       "      <td>1.003049</td>\n",
       "      <td>0.050714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>500.137601</td>\n",
       "      <td>882.623776</td>\n",
       "      <td>81487.497016</td>\n",
       "      <td>1689.963087</td>\n",
       "      <td>0.674454</td>\n",
       "      <td>0.325546</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>2008.467944</td>\n",
       "      <td>2169.206682</td>\n",
       "      <td>753.012362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>5.729235</td>\n",
       "      <td>5.986064</td>\n",
       "      <td>6.003023</td>\n",
       "      <td>7.193015</td>\n",
       "      <td>0.631508</td>\n",
       "      <td>0.377202</td>\n",
       "      <td>0.039462</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47342.009019</td>\n",
       "      <td>1817.260689</td>\n",
       "      <td>0.821848</td>\n",
       "      <td>0.178152</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>1745.103185</td>\n",
       "      <td>2739.580385</td>\n",
       "      <td>807.989455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>6.823447</td>\n",
       "      <td>7.558014</td>\n",
       "      <td>7.803824</td>\n",
       "      <td>7.824645</td>\n",
       "      <td>0.520235</td>\n",
       "      <td>0.308698</td>\n",
       "      <td>0.039637</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.045876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>204.529646</td>\n",
       "      <td>682.061561</td>\n",
       "      <td>95893.281979</td>\n",
       "      <td>1481.903638</td>\n",
       "      <td>0.528654</td>\n",
       "      <td>0.471346</td>\n",
       "      <td>0.013604</td>\n",
       "      <td>1554.427525</td>\n",
       "      <td>2555.993379</td>\n",
       "      <td>1275.716870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>7.719481</td>\n",
       "      <td>6.571339</td>\n",
       "      <td>7.982946</td>\n",
       "      <td>5.646330</td>\n",
       "      <td>1.033975</td>\n",
       "      <td>1.154270</td>\n",
       "      <td>0.046235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>523.924293</td>\n",
       "      <td>715.266082</td>\n",
       "      <td>114387.786122</td>\n",
       "      <td>2328.168412</td>\n",
       "      <td>0.685147</td>\n",
       "      <td>0.314853</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>2616.511581</td>\n",
       "      <td>2047.876935</td>\n",
       "      <td>837.166836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035534</td>\n",
       "      <td>6.634959</td>\n",
       "      <td>6.864376</td>\n",
       "      <td>5.643307</td>\n",
       "      <td>5.782120</td>\n",
       "      <td>0.735042</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.038619</td>\n",
       "      <td>0.045873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>200.012140</td>\n",
       "      <td>340.738423</td>\n",
       "      <td>91525.928118</td>\n",
       "      <td>2351.409419</td>\n",
       "      <td>0.894766</td>\n",
       "      <td>0.105234</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>2471.569815</td>\n",
       "      <td>3156.790291</td>\n",
       "      <td>1348.463636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036583</td>\n",
       "      <td>7.218031</td>\n",
       "      <td>7.680205</td>\n",
       "      <td>7.239238</td>\n",
       "      <td>7.569912</td>\n",
       "      <td>0.425968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033798</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1236.487101</td>\n",
       "      <td>1869.127830</td>\n",
       "      <td>42062.541175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427003</td>\n",
       "      <td>0.572997</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>2.270470</td>\n",
       "      <td>4.117134</td>\n",
       "      <td>3.071590</td>\n",
       "      <td>4.893800</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.345531</td>\n",
       "      <td>0.040485</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>318.914420</td>\n",
       "      <td>445.834323</td>\n",
       "      <td>30899.921426</td>\n",
       "      <td>475.117660</td>\n",
       "      <td>0.628634</td>\n",
       "      <td>0.371366</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>635.937164</td>\n",
       "      <td>732.766886</td>\n",
       "      <td>183.633937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>4.142958</td>\n",
       "      <td>4.926599</td>\n",
       "      <td>4.089007</td>\n",
       "      <td>4.743519</td>\n",
       "      <td>0.592722</td>\n",
       "      <td>0.085490</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>0.030765</td>\n",
       "      <td>0.045872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>292.045660</td>\n",
       "      <td>131.119751</td>\n",
       "      <td>110450.823666</td>\n",
       "      <td>1900.109173</td>\n",
       "      <td>0.844891</td>\n",
       "      <td>0.155109</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>2103.819143</td>\n",
       "      <td>3284.469943</td>\n",
       "      <td>1039.125071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>7.592999</td>\n",
       "      <td>6.984941</td>\n",
       "      <td>8.004951</td>\n",
       "      <td>7.471054</td>\n",
       "      <td>0.731476</td>\n",
       "      <td>0.564906</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>410.596170</td>\n",
       "      <td>255.449685</td>\n",
       "      <td>67036.391685</td>\n",
       "      <td>2420.727554</td>\n",
       "      <td>0.753699</td>\n",
       "      <td>0.246301</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>2511.647232</td>\n",
       "      <td>2145.077313</td>\n",
       "      <td>477.290518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>6.876735</td>\n",
       "      <td>8.121219</td>\n",
       "      <td>4.321820</td>\n",
       "      <td>7.622167</td>\n",
       "      <td>0.749114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>0.101204</td>\n",
       "      <td>0.045863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2041.295219</td>\n",
       "      <td>2829.703758</td>\n",
       "      <td>36166.978500</td>\n",
       "      <td>142.226216</td>\n",
       "      <td>0.450900</td>\n",
       "      <td>0.549100</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>166.963937</td>\n",
       "      <td>543.610936</td>\n",
       "      <td>46.522017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019515</td>\n",
       "      <td>2.726089</td>\n",
       "      <td>4.423131</td>\n",
       "      <td>2.833598</td>\n",
       "      <td>6.616578</td>\n",
       "      <td>0.959126</td>\n",
       "      <td>0.782043</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>0.045866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>555.604086</td>\n",
       "      <td>710.989284</td>\n",
       "      <td>1359.458446</td>\n",
       "      <td>753.440801</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.239375</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>540.378980</td>\n",
       "      <td>1031.413333</td>\n",
       "      <td>373.960290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>4.152589</td>\n",
       "      <td>6.544868</td>\n",
       "      <td>6.037898</td>\n",
       "      <td>6.533017</td>\n",
       "      <td>0.539710</td>\n",
       "      <td>0.307709</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>0.045873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>782.973340</td>\n",
       "      <td>1274.570328</td>\n",
       "      <td>47695.923623</td>\n",
       "      <td>947.594961</td>\n",
       "      <td>0.502235</td>\n",
       "      <td>0.497765</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>1029.427358</td>\n",
       "      <td>835.301601</td>\n",
       "      <td>354.046572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>4.291771</td>\n",
       "      <td>5.106803</td>\n",
       "      <td>3.872008</td>\n",
       "      <td>6.365957</td>\n",
       "      <td>0.784855</td>\n",
       "      <td>0.268671</td>\n",
       "      <td>0.038081</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.045876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104894.132767</td>\n",
       "      <td>1917.282088</td>\n",
       "      <td>0.835953</td>\n",
       "      <td>0.164047</td>\n",
       "      <td>0.013525</td>\n",
       "      <td>2162.165595</td>\n",
       "      <td>2824.849485</td>\n",
       "      <td>998.558551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029915</td>\n",
       "      <td>7.093006</td>\n",
       "      <td>9.116202</td>\n",
       "      <td>6.800893</td>\n",
       "      <td>8.466469</td>\n",
       "      <td>0.433970</td>\n",
       "      <td>0.268925</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>843.215016</td>\n",
       "      <td>1011.882027</td>\n",
       "      <td>97056.360471</td>\n",
       "      <td>1053.702779</td>\n",
       "      <td>0.550029</td>\n",
       "      <td>0.449971</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>1217.937772</td>\n",
       "      <td>1615.125883</td>\n",
       "      <td>220.003098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>5.723497</td>\n",
       "      <td>6.632554</td>\n",
       "      <td>5.121036</td>\n",
       "      <td>5.727000</td>\n",
       "      <td>0.997685</td>\n",
       "      <td>0.853906</td>\n",
       "      <td>0.047042</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22.232508</td>\n",
       "      <td>377.034750</td>\n",
       "      <td>84925.038616</td>\n",
       "      <td>1867.663147</td>\n",
       "      <td>0.708697</td>\n",
       "      <td>0.291303</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>2082.383221</td>\n",
       "      <td>2271.638382</td>\n",
       "      <td>1139.856706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.309665</td>\n",
       "      <td>6.655977</td>\n",
       "      <td>6.778534</td>\n",
       "      <td>5.847746</td>\n",
       "      <td>0.380106</td>\n",
       "      <td>0.090243</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>697.665231</td>\n",
       "      <td>680.661838</td>\n",
       "      <td>58947.394769</td>\n",
       "      <td>1397.323967</td>\n",
       "      <td>0.803758</td>\n",
       "      <td>0.196242</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>1678.812072</td>\n",
       "      <td>898.955104</td>\n",
       "      <td>253.933938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>5.328951</td>\n",
       "      <td>5.243259</td>\n",
       "      <td>6.673061</td>\n",
       "      <td>6.699436</td>\n",
       "      <td>0.483830</td>\n",
       "      <td>0.298918</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>476.971881</td>\n",
       "      <td>768.375589</td>\n",
       "      <td>66935.654589</td>\n",
       "      <td>1024.385416</td>\n",
       "      <td>0.572357</td>\n",
       "      <td>0.427643</td>\n",
       "      <td>0.013505</td>\n",
       "      <td>997.726773</td>\n",
       "      <td>1948.546301</td>\n",
       "      <td>695.452676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035482</td>\n",
       "      <td>5.325527</td>\n",
       "      <td>5.169447</td>\n",
       "      <td>5.237457</td>\n",
       "      <td>5.817469</td>\n",
       "      <td>0.886290</td>\n",
       "      <td>0.128498</td>\n",
       "      <td>0.035032</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>0.045873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1491.304733</td>\n",
       "      <td>1933.962259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467806</td>\n",
       "      <td>0.532194</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029343</td>\n",
       "      <td>0.715572</td>\n",
       "      <td>4.967647</td>\n",
       "      <td>1.984183</td>\n",
       "      <td>5.127654</td>\n",
       "      <td>0.961091</td>\n",
       "      <td>0.358982</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1576.664549</td>\n",
       "      <td>2059.971179</td>\n",
       "      <td>52400.323253</td>\n",
       "      <td>709.831563</td>\n",
       "      <td>0.609991</td>\n",
       "      <td>0.390009</td>\n",
       "      <td>0.013552</td>\n",
       "      <td>876.781667</td>\n",
       "      <td>967.455428</td>\n",
       "      <td>418.574137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>3.549815</td>\n",
       "      <td>4.335755</td>\n",
       "      <td>3.971118</td>\n",
       "      <td>6.801314</td>\n",
       "      <td>0.763040</td>\n",
       "      <td>0.471095</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>0.029830</td>\n",
       "      <td>0.045869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>402.608900</td>\n",
       "      <td>585.285641</td>\n",
       "      <td>40799.228722</td>\n",
       "      <td>778.484121</td>\n",
       "      <td>0.604550</td>\n",
       "      <td>0.395450</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>1026.152137</td>\n",
       "      <td>730.999260</td>\n",
       "      <td>667.440328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>5.729948</td>\n",
       "      <td>5.450748</td>\n",
       "      <td>5.518752</td>\n",
       "      <td>5.591017</td>\n",
       "      <td>0.805535</td>\n",
       "      <td>0.767671</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.045862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>800.523145</td>\n",
       "      <td>1250.784704</td>\n",
       "      <td>45077.345668</td>\n",
       "      <td>683.188196</td>\n",
       "      <td>0.554113</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>0.013526</td>\n",
       "      <td>776.227065</td>\n",
       "      <td>723.914302</td>\n",
       "      <td>263.199802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>3.776789</td>\n",
       "      <td>5.144846</td>\n",
       "      <td>4.328353</td>\n",
       "      <td>6.303802</td>\n",
       "      <td>0.714269</td>\n",
       "      <td>0.165571</td>\n",
       "      <td>0.036993</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.045875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>702.004999</td>\n",
       "      <td>997.090426</td>\n",
       "      <td>33733.945409</td>\n",
       "      <td>1266.853802</td>\n",
       "      <td>0.666844</td>\n",
       "      <td>0.333156</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>1248.990829</td>\n",
       "      <td>1267.989955</td>\n",
       "      <td>608.072010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>4.267180</td>\n",
       "      <td>5.369780</td>\n",
       "      <td>5.811228</td>\n",
       "      <td>6.371552</td>\n",
       "      <td>0.681143</td>\n",
       "      <td>0.135049</td>\n",
       "      <td>0.035222</td>\n",
       "      <td>0.027065</td>\n",
       "      <td>0.045878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>216.406896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46284.387987</td>\n",
       "      <td>840.870226</td>\n",
       "      <td>1.008760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>803.179395</td>\n",
       "      <td>1002.942538</td>\n",
       "      <td>967.088416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045515</td>\n",
       "      <td>5.224433</td>\n",
       "      <td>7.247962</td>\n",
       "      <td>4.283422</td>\n",
       "      <td>7.786171</td>\n",
       "      <td>0.868363</td>\n",
       "      <td>0.742535</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.212245</td>\n",
       "      <td>0.045858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_area_harv_ha  total_area_lost_ha  total_harv_kg   yield_kgha  \\\n",
       "0           917.813698            0.000000  111435.011634   341.454985   \n",
       "1           791.052135           11.192504   45102.609459     0.000000   \n",
       "2           391.878285          254.997234  102768.847047  1233.565136   \n",
       "3           915.230064         1257.836838   52782.728788  1007.351629   \n",
       "4           782.274013          939.409659   88759.321211   604.816086   \n",
       "5          1012.046607         1648.383404   25370.726266   360.449625   \n",
       "6           477.660820          680.724448  106965.723669  2283.333963   \n",
       "7          2406.583182         3806.406288    8009.244938     0.000000   \n",
       "8             0.000000            0.000000  124372.652236  3315.658773   \n",
       "9          1023.940828         1303.896108   15499.150907    42.101692   \n",
       "10         2087.606010         2903.670758   12814.638768   276.356046   \n",
       "11          246.642609          295.384218   73567.331600  1953.788787   \n",
       "12          211.865431          153.358853  106898.560812  1351.147317   \n",
       "13            0.000000            0.000000  135781.862503  1828.535407   \n",
       "14          337.653329          391.567155   38811.943291  1350.159361   \n",
       "15          887.544742         1342.588616  125552.332799  1153.169715   \n",
       "16          456.483816          894.941753   68333.352586  1257.403058   \n",
       "17          599.104697          648.774888   83709.964736   897.514041   \n",
       "18           69.609617           62.961193   96840.306740  1885.195467   \n",
       "19          390.055889          624.949924   48303.104900  1262.487637   \n",
       "20          843.589548          170.376636   50329.008979   104.400834   \n",
       "21          550.719520          758.190677   96405.027139  2198.644818   \n",
       "22          845.842910          778.108356       0.000000     0.000000   \n",
       "23         1276.713377          975.612574   37194.443699     0.000000   \n",
       "24          377.152503          356.603209  152190.006962  2269.060483   \n",
       "25          525.534301          593.259734   59300.439097  1364.238503   \n",
       "26          775.060962         1081.205030   91911.650393  1013.107656   \n",
       "27          685.871220          455.991173   13439.693327     0.000000   \n",
       "28          339.517302          495.824935   43176.115993  1667.822258   \n",
       "29            0.000000            0.000000   99878.381851  3221.966937   \n",
       "30          292.377767          458.391306  102310.415215  1573.027340   \n",
       "31          500.137601          882.623776   81487.497016  1689.963087   \n",
       "32            0.000000            0.000000   47342.009019  1817.260689   \n",
       "33          204.529646          682.061561   95893.281979  1481.903638   \n",
       "34          523.924293          715.266082  114387.786122  2328.168412   \n",
       "35          200.012140          340.738423   91525.928118  2351.409419   \n",
       "36         1236.487101         1869.127830   42062.541175     0.000000   \n",
       "37          318.914420          445.834323   30899.921426   475.117660   \n",
       "38          292.045660          131.119751  110450.823666  1900.109173   \n",
       "39          410.596170          255.449685   67036.391685  2420.727554   \n",
       "40         2041.295219         2829.703758   36166.978500   142.226216   \n",
       "41          555.604086          710.989284    1359.458446   753.440801   \n",
       "42          782.973340         1274.570328   47695.923623   947.594961   \n",
       "43            0.000000            0.000000  104894.132767  1917.282088   \n",
       "44          843.215016         1011.882027   97056.360471  1053.702779   \n",
       "45           22.232508          377.034750   84925.038616  1867.663147   \n",
       "46          697.665231          680.661838   58947.394769  1397.323967   \n",
       "47          476.971881          768.375589   66935.654589  1024.385416   \n",
       "48         1491.304733         1933.962259       0.000000     0.000000   \n",
       "49         1576.664549         2059.971179   52400.323253   709.831563   \n",
       "50          402.608900          585.285641   40799.228722   778.484121   \n",
       "51          800.523145         1250.784704   45077.345668   683.188196   \n",
       "52          702.004999          997.090426   33733.945409  1266.853802   \n",
       "53          216.406896            0.000000   46284.387987   840.870226   \n",
       "\n",
       "    frac_area_harv  frac_area_loss  area_lost_fire        maize   groundnuts  \\\n",
       "0         0.976549        0.023451        0.013659   377.651780     0.000000   \n",
       "1         0.683158        0.316842        0.013655     0.000000     0.000000   \n",
       "2         0.658221        0.341779        0.013583  1362.083833  1948.804512   \n",
       "3         0.545082        0.454918        0.013512  1035.826396  1341.860010   \n",
       "4         0.504270        0.495730        0.013592   663.225058   970.482632   \n",
       "5         0.526944        0.473056        0.013562   518.124264    17.648074   \n",
       "6         0.764828        0.235172        0.013498  2649.313718  2604.863987   \n",
       "7         0.323951        0.676049        0.013583     0.000000     0.000000   \n",
       "8         0.957808        0.042192        0.013533  3789.423892  3797.084231   \n",
       "9         0.610987        0.389013        0.013489     0.000000   804.269856   \n",
       "10        0.524615        0.475385        0.013573   347.996476   204.098585   \n",
       "11        0.745532        0.254468        0.013549  2324.035855  1568.900435   \n",
       "12        0.630341        0.369659        0.013638  1383.686812  2729.175940   \n",
       "13        0.771858        0.228142        0.013540  1888.996652  2578.726344   \n",
       "14        0.898466        0.101534        0.013526  1446.951540  1985.864104   \n",
       "15        0.615922        0.384078        0.013604  1124.928859  2884.691763   \n",
       "16        0.579636        0.420364        0.013531  1336.059679   910.683492   \n",
       "17        0.664001        0.335999        0.013606  1283.326690   619.609989   \n",
       "18        0.732238        0.267762        0.013574  1885.028807  2682.487674   \n",
       "19        0.835615        0.164385        0.013533  1247.354538  1541.669367   \n",
       "20        0.941261        0.058739        0.013589   215.857125     0.000000   \n",
       "21        0.798929        0.201071        0.013544  1859.774255  2777.993902   \n",
       "22        0.663120        0.336880        0.013524     0.000000     0.000000   \n",
       "23        0.701378        0.298622        0.013619     0.000000     0.000000   \n",
       "24        0.744874        0.255126        0.013588  2416.808524  2232.310359   \n",
       "25        0.695911        0.304089        0.013549  1585.910933  1757.338521   \n",
       "26        0.659634        0.340366        0.013586  1444.087425  1264.067085   \n",
       "27        0.775257        0.224743        0.013503     0.000000     0.000000   \n",
       "28        0.833559        0.166441        0.013535  1886.525514  2127.128838   \n",
       "29        0.900024        0.099976        0.013508  3479.624842  2179.811559   \n",
       "30        0.623112        0.376888        0.013634  1722.415388  2813.208796   \n",
       "31        0.674454        0.325546        0.013540  2008.467944  2169.206682   \n",
       "32        0.821848        0.178152        0.013557  1745.103185  2739.580385   \n",
       "33        0.528654        0.471346        0.013604  1554.427525  2555.993379   \n",
       "34        0.685147        0.314853        0.013495  2616.511581  2047.876935   \n",
       "35        0.894766        0.105234        0.013500  2471.569815  3156.790291   \n",
       "36        0.427003        0.572997        0.013549     0.000000     0.000000   \n",
       "37        0.628634        0.371366        0.013507   635.937164   732.766886   \n",
       "38        0.844891        0.155109        0.013588  2103.819143  3284.469943   \n",
       "39        0.753699        0.246301        0.013471  2511.647232  2145.077313   \n",
       "40        0.450900        0.549100        0.013582   166.963937   543.610936   \n",
       "41        0.760625        0.239375        0.013550   540.378980  1031.413333   \n",
       "42        0.502235        0.497765        0.013536  1029.427358   835.301601   \n",
       "43        0.835953        0.164047        0.013525  2162.165595  2824.849485   \n",
       "44        0.550029        0.449971        0.013593  1217.937772  1615.125883   \n",
       "45        0.708697        0.291303        0.013632  2082.383221  2271.638382   \n",
       "46        0.803758        0.196242        0.013561  1678.812072   898.955104   \n",
       "47        0.572357        0.427643        0.013505   997.726773  1948.546301   \n",
       "48        0.467806        0.532194        0.013538     0.000000     0.000000   \n",
       "49        0.609991        0.390009        0.013552   876.781667   967.455428   \n",
       "50        0.604550        0.395450        0.013565  1026.152137   730.999260   \n",
       "51        0.554113        0.445887        0.013526   776.227065   723.914302   \n",
       "52        0.666844        0.333156        0.013510  1248.990829  1267.989955   \n",
       "53        1.008760        0.000000        0.013487   803.179395  1002.942538   \n",
       "\n",
       "    mixed_beans  ...  prop_mix  log_maize  log_sweetpotatoes  log_groundnuts  \\\n",
       "0      0.000000  ...  0.000404   4.555314           6.258815        3.184263   \n",
       "1      0.000000  ...  0.000000   2.951948           5.282578        3.860021   \n",
       "2    376.208639  ...  0.018646   6.484091           7.141421        6.322030   \n",
       "3    620.285469  ...  0.034321   3.937893           4.197342        3.719265   \n",
       "4     10.045635  ...  0.015720   5.068544           7.069180        5.034843   \n",
       "5      9.207263  ...  0.023304   3.477883           5.547287        2.951858   \n",
       "6   1012.033003  ...  0.036449   7.163687           6.449258        7.386272   \n",
       "7    270.207776  ...  0.020733   0.686500           3.225395        1.285908   \n",
       "8   1320.336113  ...  0.031279   9.312883           8.896121        9.544446   \n",
       "9    420.579618  ...  0.038884   3.313278           5.392915        5.632121   \n",
       "10   320.954164  ...  0.022144   2.263307           3.255160        3.503113   \n",
       "11  1001.552036  ...  0.025345   6.846642           6.949398        5.998092   \n",
       "12   210.789878  ...  0.003469   6.975495           8.462320        7.513970   \n",
       "13   541.614588  ...  0.024347   7.343236           8.790256        6.575817   \n",
       "14   759.061478  ...  0.029292   5.418756           8.274494        6.837206   \n",
       "15   200.420903  ...  0.011239   5.518825           5.538723        6.820045   \n",
       "16   274.406938  ...  0.028797   4.597920           5.421360        4.070116   \n",
       "17     0.000000  ...  0.011199   5.468874           6.623903        5.688185   \n",
       "18   798.610392  ...  0.019935   7.448874           7.165144        7.786471   \n",
       "19   775.987479  ...  0.029052   5.078651           7.216555        6.441163   \n",
       "20     0.000000  ...  0.016608   3.495453           5.851540        3.803929   \n",
       "21   609.016249  ...  0.025768   6.422960           8.260820        6.678807   \n",
       "22     0.000000  ...  0.036940   2.046280           0.529849        5.326981   \n",
       "23     0.000000  ...  0.010099   2.564601           6.279308        3.762312   \n",
       "24  1408.261197  ...  0.019792   8.127717           6.182218        7.222143   \n",
       "25  1095.808342  ...  0.027268   5.944029           5.970674        5.842817   \n",
       "26   284.334153  ...  0.017309   5.262298           6.512145        5.697985   \n",
       "27     0.000000  ...  0.045248   1.961009           6.117271        3.966425   \n",
       "28   843.361463  ...  0.027745   5.948853           7.445899        6.466916   \n",
       "29   974.453678  ...  0.023332   8.088861           9.094320        5.299040   \n",
       "30   220.548709  ...  0.004944   7.091323           8.198421        7.693508   \n",
       "31   753.012362  ...  0.027205   5.729235           5.986064        6.003023   \n",
       "32   807.989455  ...  0.022471   6.823447           7.558014        7.803824   \n",
       "33  1275.716870  ...  0.013668   7.719481           6.571339        7.982946   \n",
       "34   837.166836  ...  0.035534   6.634959           6.864376        5.643307   \n",
       "35  1348.463636  ...  0.036583   7.218031           7.680205        7.239238   \n",
       "36     0.000000  ...  0.025362   2.270470           4.117134        3.071590   \n",
       "37   183.633937  ...  0.034599   4.142958           4.926599        4.089007   \n",
       "38  1039.125071  ...  0.016897   7.592999           6.984941        8.004951   \n",
       "39   477.290518  ...  0.035088   6.876735           8.121219        4.321820   \n",
       "40    46.522017  ...  0.019515   2.726089           4.423131        2.833598   \n",
       "41   373.960290  ...  0.025061   4.152589           6.544868        6.037898   \n",
       "42   354.046572  ...  0.028725   4.291771           5.106803        3.872008   \n",
       "43   998.558551  ...  0.029915   7.093006           9.116202        6.800893   \n",
       "44   220.003098  ...  0.015543   5.723497           6.632554        5.121036   \n",
       "45  1139.856706  ...  0.000000   6.309665           6.655977        6.778534   \n",
       "46   253.933938  ...  0.024038   5.328951           5.243259        6.673061   \n",
       "47   695.452676  ...  0.035482   5.325527           5.169447        5.237457   \n",
       "48     0.000000  ...  0.029343   0.715572           4.967647        1.984183   \n",
       "49   418.574137  ...  0.024587   3.549815           4.335755        3.971118   \n",
       "50   667.440328  ...  0.022510   5.729948           5.450748        5.518752   \n",
       "51   263.199802  ...  0.032164   3.776789           5.144846        4.328353   \n",
       "52   608.072010  ...  0.035007   4.267180           5.369780        5.811228   \n",
       "53   967.088416  ...  0.045515   5.224433           7.247962        4.283422   \n",
       "\n",
       "    log_soybeans  loss_ind  drought_loss_ind  flood_loss_ind  animal_loss_ind  \\\n",
       "0       4.502035  1.226299          1.027636        0.048856         0.000000   \n",
       "1       5.214353  1.272964          1.019560        0.049430         0.010031   \n",
       "2       5.899069  0.915167          0.657961        0.044257         0.000000   \n",
       "3       5.937764  0.760854          0.097803        0.035037         0.023696   \n",
       "4       5.354388  1.140324          0.812087        0.046157         0.000000   \n",
       "5       5.661399  0.812376          0.366215        0.039943         0.001973   \n",
       "6       6.430003  0.633261          0.000000        0.031394         0.012443   \n",
       "7       3.208963  1.155907          1.018510        0.043463         0.000000   \n",
       "8       8.501795  0.558353          0.283116        0.038429         0.003849   \n",
       "9       5.263136  0.976424          0.032197        0.032195         0.034917   \n",
       "10      5.579981  0.855655          0.701376        0.043062         0.005216   \n",
       "11      5.973284  0.506431          0.313606        0.039617         0.002098   \n",
       "12      5.180537  1.073497          1.000065        0.050542         0.000000   \n",
       "13      7.349766  0.544167          0.296758        0.040426         0.025346   \n",
       "14      7.786200  0.417380          0.153828        0.037443         0.025182   \n",
       "15      5.312323  0.776193          0.581857        0.039907         0.027084   \n",
       "16      6.098096  0.659131          0.131644        0.037988         0.016812   \n",
       "17      6.340779  1.191541          0.866261        0.046186         0.033262   \n",
       "18      6.862246  0.616496          0.538286        0.043068         0.009385   \n",
       "19      6.136288  0.510306          0.153104        0.036779         0.011955   \n",
       "20      7.076280  0.882351          0.613510        0.042883         0.019265   \n",
       "21      6.775273  0.568074          0.154772        0.040639         0.023302   \n",
       "22      8.492448  0.968612          1.009770        0.039573         0.216427   \n",
       "23      6.025932  1.067652          0.942968        0.046570         0.012921   \n",
       "24      4.691123  0.899276          1.201639        0.045460         0.000000   \n",
       "25      6.954791  0.743477          0.529447        0.040943         0.012575   \n",
       "26      6.819136  1.013178          0.750834        0.043038         0.024959   \n",
       "27      4.952211  0.953349          0.564568        0.041701         0.115129   \n",
       "28      7.495386  0.427354          0.115067        0.037261         0.005244   \n",
       "29      7.858621  0.580968          0.000000        0.035387         0.095408   \n",
       "30      4.774155  1.054561          1.003049        0.050714         0.000000   \n",
       "31      7.193015  0.631508          0.377202        0.039462         0.010568   \n",
       "32      7.824645  0.520235          0.308698        0.039637         0.005438   \n",
       "33      5.646330  1.033975          1.154270        0.046235         0.000000   \n",
       "34      5.782120  0.735042          0.005678        0.033910         0.038619   \n",
       "35      7.569912  0.425968          0.000000        0.033798         0.016897   \n",
       "36      4.893800  0.900730          0.345531        0.040485         0.017854   \n",
       "37      4.743519  0.592722          0.085490        0.035633         0.030765   \n",
       "38      7.471054  0.731476          0.564906        0.042655         0.003707   \n",
       "39      7.622167  0.749114          0.000000        0.034814         0.101204   \n",
       "40      6.616578  0.959126          0.782043        0.046012         0.013169   \n",
       "41      6.533017  0.539710          0.307709        0.039282         0.004970   \n",
       "42      6.365957  0.784855          0.268671        0.038081         0.008636   \n",
       "43      8.466469  0.433970          0.268925        0.038103         0.022467   \n",
       "44      5.727000  0.997685          0.853906        0.047042         0.008295   \n",
       "45      5.847746  0.380106          0.090243        0.033868         0.000000   \n",
       "46      6.699436  0.483830          0.298918        0.041497         0.000000   \n",
       "47      5.817469  0.886290          0.128498        0.035032         0.034429   \n",
       "48      5.127654  0.961091          0.358982        0.038997         0.018658   \n",
       "49      6.801314  0.763040          0.471095        0.042255         0.029830   \n",
       "50      5.591017  0.805535          0.767671        0.041772         0.010946   \n",
       "51      6.303802  0.714269          0.165571        0.036993         0.012943   \n",
       "52      6.371552  0.681143          0.135049        0.035222         0.027065   \n",
       "53      7.786171  0.868363          0.742535        0.038497         0.212245   \n",
       "\n",
       "    pest_loss_ind  \n",
       "0        0.045864  \n",
       "1        0.045870  \n",
       "2        0.045868  \n",
       "3        0.045877  \n",
       "4        0.045871  \n",
       "5        0.045873  \n",
       "6        0.045878  \n",
       "7        0.045871  \n",
       "8        0.045870  \n",
       "9        0.045875  \n",
       "10       0.045872  \n",
       "11       0.045871  \n",
       "12       0.045868  \n",
       "13       0.045870  \n",
       "14       0.045871  \n",
       "15       0.045891  \n",
       "16       0.045875  \n",
       "17       0.045875  \n",
       "18       0.045869  \n",
       "19       0.045875  \n",
       "20       0.045869  \n",
       "21       0.045866  \n",
       "22       0.045863  \n",
       "23       0.045870  \n",
       "24       0.045864  \n",
       "25       0.045868  \n",
       "26       0.045877  \n",
       "27       0.045851  \n",
       "28       0.045875  \n",
       "29       0.045866  \n",
       "30       0.045865  \n",
       "31       0.045868  \n",
       "32       0.045876  \n",
       "33       0.045866  \n",
       "34       0.045873  \n",
       "35       0.045870  \n",
       "36       0.045875  \n",
       "37       0.045872  \n",
       "38       0.045868  \n",
       "39       0.045863  \n",
       "40       0.045866  \n",
       "41       0.045873  \n",
       "42       0.045876  \n",
       "43       0.045868  \n",
       "44       0.045870  \n",
       "45       0.045899  \n",
       "46       0.045870  \n",
       "47       0.045873  \n",
       "48       0.045868  \n",
       "49       0.045869  \n",
       "50       0.045862  \n",
       "51       0.045875  \n",
       "52       0.045878  \n",
       "53       0.045858  \n",
       "\n",
       "[54 rows x 38 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a0179",
   "metadata": {},
   "source": [
    "### Visualize Performance of Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b60be005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa436396a1e416e91156e4f5bfb0a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Variable:', options=('total_area_harv_ha', 'total_area_lost_ha', 'total_hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of variable names from the dataframes\n",
    "variable_names = list(y_pred_test.columns)\n",
    "\n",
    "# create a container widget to hold the dropdown and the plot\n",
    "container = widgets.VBox(children=[variable_dropdown])\n",
    "\n",
    "# Create the dropdown widget\n",
    "variable_dropdown = widgets.Dropdown(options=variable_names, description='Variable:')\n",
    "\n",
    "# Create an output widget to display the plot\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "\n",
    "# Define a function to update the plot based on the selected variable\n",
    "def update_plot_test(variable):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        # Create the scatterplot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(y_pred_test[variable], y_tests[variable])\n",
    "        ax.axline([0, 0], [1, 1], c=\"k\")\n",
    "\n",
    "        # Extract the R2 value from the r2_train dataframe\n",
    "        r2_value = r2_test[variable]\n",
    "        r2_value = round(r2_value, 2)\n",
    "\n",
    "        # Set the title with the current title as a subtitle and the new title as \"Variable: [variable]\"\n",
    "        sub_title = f\"Model applied to test data n = {len(y_tests)}, R$^2$ = {r2_value}\"\n",
    "        title = f\"Variable: {variable}\"\n",
    "        plt.title(sub_title, fontsize=12, y=1.0, loc='left')\n",
    "        plt.title(title, fontsize=14, y=1.15, loc='center')\n",
    "\n",
    "        # Set x and y axis labels\n",
    "        ax.set_xlabel(\"Predicted\", fontsize=15)\n",
    "        ax.set_ylabel(\"Ground Truth\", fontsize=15)\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "# Define a function to update the dropdown options when the variable names change\n",
    "def update_dropdown_options(change):\n",
    "    variable_dropdown.options = variable_names\n",
    "\n",
    "# Call the update_plot_train function with the initial value of the dropdown\n",
    "update_plot_test(variable_dropdown.value)\n",
    "\n",
    "# Register the event handler to update the dropdown options\n",
    "variable_dropdown.observe(update_dropdown_options, 'options')\n",
    "\n",
    "# Set up the interaction between the dropdown and the plot\n",
    "def dropdown_eventhandler(change):\n",
    "    variable = change.new\n",
    "    update_plot_test(variable)\n",
    "\n",
    "variable_dropdown.observe(dropdown_eventhandler, 'value')\n",
    "\n",
    "# Display the dropdown and the plot\n",
    "display(widgets.VBox([variable_dropdown, plot_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e47064",
   "metadata": {},
   "source": [
    "### Apply Model to Ungrouped SEA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb1b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sea_ungrouped = pd.read_feather(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_ungroup_features_simple_impute_mean.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "da0f0c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>0.532948</td>\n",
       "      <td>0.469076</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>0.494736</td>\n",
       "      <td>0.474246</td>\n",
       "      <td>0.417571</td>\n",
       "      <td>0.135569</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.156783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021665</td>\n",
       "      <td>0.324015</td>\n",
       "      <td>0.490193</td>\n",
       "      <td>0.392582</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>0.718919</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>0.673485</td>\n",
       "      <td>0.631725</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.052683</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72278</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72279</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72280</th>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.004205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72281</th>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.004801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72282</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.014430</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.012770</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.011526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72283 rows Ã— 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0_1       0_2       0_3       0_4       0_5       0_6       0_7  \\\n",
       "0      0.001143  0.000751  0.000000  0.000346  0.000000  0.000000  0.000000   \n",
       "1      0.001143  0.000000  0.000776  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.001143  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.001143  0.000751  0.000776  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000751  0.000776  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "72278  0.001143  0.003581  0.003867  0.001019  0.001521  0.000000  0.002637   \n",
       "72279  0.000000  0.000000  0.000000  0.000000  0.000000  0.002137  0.003117   \n",
       "72280  0.002399  0.000751  0.000000  0.000000  0.001860  0.002130  0.002149   \n",
       "72281  0.003386  0.000000  0.000000  0.000000  0.000923  0.002777  0.003057   \n",
       "72282  0.000022  0.000876  0.000507  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            0_8       0_9      0_10  ...     999_3     999_4     999_5  \\\n",
       "0      0.000000  0.000000  0.001020  ...  0.034016  0.071989  0.532948   \n",
       "1      0.000000  0.000002  0.000308  ...  0.043530  0.494736  0.474246   \n",
       "2      0.000000  0.000234  0.000039  ...  0.021665  0.324015  0.490193   \n",
       "3      0.000000  0.000657  0.000894  ...  0.043530  0.718919  0.645601   \n",
       "4      0.000000  0.000002  0.001360  ...  0.043530  1.000000  0.679722   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "72278  0.003194  0.004948  0.005988  ...  0.008950  0.013373  0.009622   \n",
       "72279  0.004004  0.004732  0.000000  ...  0.013883  0.014116  0.009862   \n",
       "72280  0.000000  0.004094  0.006669  ...  0.012160  0.011552  0.013037   \n",
       "72281  0.004031  0.000000  0.000000  ...  0.005391  0.004631  0.007071   \n",
       "72282  0.000000  0.000000  0.000000  ...  0.019932  0.014430  0.013566   \n",
       "\n",
       "          999_6     999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0      0.469076  0.007786  0.006779  0.004811  0.001675  0.029891  0.033437  \n",
       "1      0.417571  0.135569  0.003355  0.004876  0.003185  0.187867  0.156783  \n",
       "2      0.392582  0.325692  0.004587  0.002309  0.002191  0.002333  0.033437  \n",
       "3      0.673485  0.631725  0.004959  0.001359  0.001627  0.052683  0.033437  \n",
       "4      1.000000  0.324600  0.006641  0.003481  0.003071  0.004119  1.000000  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "72278  0.008655  0.003418  0.001569  0.000234  0.000054  0.000039  0.000276  \n",
       "72279  0.002694  0.000432  0.000132  0.000086  0.000063  0.000060  0.033437  \n",
       "72280  0.007480  0.002309  0.000083  0.000194  0.000100  0.000016  0.004205  \n",
       "72281  0.001832  0.001039  0.000223  0.000081  0.000324  0.001030  0.004801  \n",
       "72282  0.012770  0.008013  0.003928  0.001690  0.000192  0.002576  0.011526  \n",
       "\n",
       "[72283 rows x 12000 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sea = features_sea_ungrouped.iloc[:, 2:12002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b3219dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred_sea = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred_sea_column = np.maximum(model.predict(features_sea), 0)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred_sea[target_column] = y_pred_sea_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "da11d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns from features\n",
    "selected_columns_sea = features_ungrouped[['lat', 'lon', 'year']]\n",
    "\n",
    "# Concatenate selected_columns with y_preds\n",
    "sea_preds = pd.concat([selected_columns_sea, y_pred_sea], axis=1)\n",
    "\n",
    "# Display the combined dataframe\n",
    "sea_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_preds.to_feather(\"/capstone/mosaiks/repos/modeling/data/predictions/SEA_predictions_ungrouped.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b165d",
   "metadata": {},
   "source": [
    "## Apply Model to Zambia 10% Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a71096b5-bd08-42c2-854d-655f56b6b2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zambia = pd.read_feather(\"/capstone/mosaiks/repos/modeling/data/model_directory/zambia_10percent_features_simple_impute_modelpredict.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "363e43dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.005276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.075393</td>\n",
       "      <td>0.056347</td>\n",
       "      <td>0.056281</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.075393</td>\n",
       "      <td>0.056347</td>\n",
       "      <td>0.056281</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.035491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5       0_6       0_7  \\\n",
       "0  0.002994  0.003749  0.002417  0.001449  0.001208  0.002577  0.002151   \n",
       "1  0.002030  0.000743  0.000000  0.000000  0.000000  0.000007  0.000035   \n",
       "2  0.001111  0.003541  0.003555  0.001752  0.001398  0.001469  0.002361   \n",
       "3  0.001111  0.000743  0.000706  0.000395  0.000185  0.000202  0.000298   \n",
       "4  0.001111  0.000743  0.000706  0.000395  0.000185  0.000202  0.000298   \n",
       "\n",
       "        0_8       0_9      0_10  ...     999_3     999_4     999_5     999_6  \\\n",
       "0  0.003231  0.004019  0.001838  ...  0.000653  0.001410  0.001619  0.000461   \n",
       "1  0.000189  0.000664  0.002471  ...  0.012280  0.009524  0.006202  0.004043   \n",
       "2  0.002198  0.003063  0.005263  ...  0.001252  0.004579  0.003310  0.002417   \n",
       "3  0.000640  0.001207  0.004661  ...  0.055707  0.075393  0.056347  0.056281   \n",
       "4  0.000640  0.004295  0.001444  ...  0.055707  0.075393  0.056347  0.056281   \n",
       "\n",
       "      999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0  0.000611  0.000226  0.000138  0.000562  0.000503  0.000406  \n",
       "1  0.003652  0.002408  0.001475  0.000435  0.000302  0.005276  \n",
       "2  0.001392  0.001687  0.000812  0.000241  0.000365  0.000645  \n",
       "3  0.036438  0.004060  0.008108  0.000633  0.000496  0.000598  \n",
       "4  0.036438  0.004060  0.000187  0.002911  0.004108  0.035491  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zambia_features = zambia.iloc[:,2:12002]\n",
    "zambia_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "591764c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred_zambia = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred_zambia_column = np.maximum(model.predict(zambia_features), 0)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred_zambia[target_column] = y_pred_zambia_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e03c71ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>maize</th>\n",
       "      <th>frac_loss_drought</th>\n",
       "      <th>prop_till_plough</th>\n",
       "      <th>prop_mono</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1735.397458</td>\n",
       "      <td>0.813706</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>1722.112146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447.061644</td>\n",
       "      <td>256.229862</td>\n",
       "      <td>2331.179534</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>2405.568184</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.400076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1206.135845</td>\n",
       "      <td>2076.177727</td>\n",
       "      <td>1970.026901</td>\n",
       "      <td>0.587526</td>\n",
       "      <td>0.412474</td>\n",
       "      <td>1764.996532</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>0.100866</td>\n",
       "      <td>0.471011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670.181614</td>\n",
       "      <td>898.956082</td>\n",
       "      <td>1155.632228</td>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>1093.192949</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.632547</td>\n",
       "      <td>0.714045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>588.095553</td>\n",
       "      <td>878.123450</td>\n",
       "      <td>1066.901627</td>\n",
       "      <td>0.603163</td>\n",
       "      <td>0.396837</td>\n",
       "      <td>1051.265307</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.513613</td>\n",
       "      <td>0.712723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_area_harv_ha  total_area_lost_ha   yield_kgha  frac_area_harv  \\\n",
       "0            0.000000            0.000000  1735.397458        0.813706   \n",
       "1          447.061644          256.229862  2331.179534        0.935772   \n",
       "2         1206.135845         2076.177727  1970.026901        0.587526   \n",
       "3          670.181614          898.956082  1155.632228        0.622778   \n",
       "4          588.095553          878.123450  1066.901627        0.603163   \n",
       "\n",
       "   frac_area_loss        maize  frac_loss_drought  prop_till_plough  prop_mono  \n",
       "0        0.186294  1722.112146           0.000000          0.000000   1.073670  \n",
       "1        0.064228  2405.568184           0.046058          0.550284   0.400076  \n",
       "2        0.412474  1764.996532           0.053027          0.100866   0.471011  \n",
       "3        0.377222  1093.192949           0.096518          0.632547   0.714045  \n",
       "4        0.396837  1051.265307           0.052540          0.513613   0.712723  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_zambia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "29dd32e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>maize</th>\n",
       "      <th>frac_loss_drought</th>\n",
       "      <th>prop_till_plough</th>\n",
       "      <th>prop_mono</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1735.397458</td>\n",
       "      <td>0.813706</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>1722.112146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>447.061644</td>\n",
       "      <td>256.229862</td>\n",
       "      <td>2331.179534</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>2405.568184</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.400076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1206.135845</td>\n",
       "      <td>2076.177727</td>\n",
       "      <td>1970.026901</td>\n",
       "      <td>0.587526</td>\n",
       "      <td>0.412474</td>\n",
       "      <td>1764.996532</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>0.100866</td>\n",
       "      <td>0.471011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>670.181614</td>\n",
       "      <td>898.956082</td>\n",
       "      <td>1155.632228</td>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>1093.192949</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.632547</td>\n",
       "      <td>0.714045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>588.095553</td>\n",
       "      <td>878.123450</td>\n",
       "      <td>1066.901627</td>\n",
       "      <td>0.603163</td>\n",
       "      <td>0.396837</td>\n",
       "      <td>1051.265307</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.513613</td>\n",
       "      <td>0.712723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680651</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.193086</td>\n",
       "      <td>1.145336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>352.100772</td>\n",
       "      <td>0.165099</td>\n",
       "      <td>1.075864</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680652</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>102.839855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3497.057246</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.186295</td>\n",
       "      <td>4081.543865</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.556807</td>\n",
       "      <td>1.361831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680653</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>102.839855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3497.057246</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.186295</td>\n",
       "      <td>4081.543865</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.556807</td>\n",
       "      <td>1.361831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680654</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>768.755230</td>\n",
       "      <td>983.689961</td>\n",
       "      <td>987.401820</td>\n",
       "      <td>0.665632</td>\n",
       "      <td>0.334368</td>\n",
       "      <td>1079.121809</td>\n",
       "      <td>0.144083</td>\n",
       "      <td>0.831311</td>\n",
       "      <td>0.631516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680655</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>768.755230</td>\n",
       "      <td>983.689961</td>\n",
       "      <td>987.401820</td>\n",
       "      <td>0.665632</td>\n",
       "      <td>0.334368</td>\n",
       "      <td>1079.121809</td>\n",
       "      <td>0.144083</td>\n",
       "      <td>0.831311</td>\n",
       "      <td>0.631516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680656 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lat        lon    year  total_area_harv_ha  total_area_lost_ha  \\\n",
       "0      -15.053257  22.730588  2019.0            0.000000            0.000000   \n",
       "1      -15.053257  22.730588  2018.0          447.061644          256.229862   \n",
       "2      -15.053257  22.730588  2022.0         1206.135845         2076.177727   \n",
       "3      -15.053257  22.730588  2023.0          670.181614          898.956082   \n",
       "4      -15.053257  22.730588  2015.0          588.095553          878.123450   \n",
       "...           ...        ...     ...                 ...                 ...   \n",
       "680651 -17.473257  26.080588  2016.0            0.000000            0.000000   \n",
       "680652 -17.473257  26.080588  2015.0          102.839855            0.000000   \n",
       "680653 -17.473257  26.080588  2015.0          102.839855            0.000000   \n",
       "680654 -17.473257  26.080588  2018.0          768.755230          983.689961   \n",
       "680655 -17.473257  26.080588  2018.0          768.755230          983.689961   \n",
       "\n",
       "         yield_kgha  frac_area_harv  frac_area_loss        maize  \\\n",
       "0       1735.397458        0.813706        0.186294  1722.112146   \n",
       "1       2331.179534        0.935772        0.064228  2405.568184   \n",
       "2       1970.026901        0.587526        0.412474  1764.996532   \n",
       "3       1155.632228        0.622778        0.377222  1093.192949   \n",
       "4       1066.901627        0.603163        0.396837  1051.265307   \n",
       "...             ...             ...             ...          ...   \n",
       "680651   596.193086        1.145336        0.000000   352.100772   \n",
       "680652  3497.057246        0.813705        0.186295  4081.543865   \n",
       "680653  3497.057246        0.813705        0.186295  4081.543865   \n",
       "680654   987.401820        0.665632        0.334368  1079.121809   \n",
       "680655   987.401820        0.665632        0.334368  1079.121809   \n",
       "\n",
       "        frac_loss_drought  prop_till_plough  prop_mono  \n",
       "0                0.000000          0.000000   1.073670  \n",
       "1                0.046058          0.550284   0.400076  \n",
       "2                0.053027          0.100866   0.471011  \n",
       "3                0.096518          0.632547   0.714045  \n",
       "4                0.052540          0.513613   0.712723  \n",
       "...                   ...               ...        ...  \n",
       "680651           0.165099          1.075864   0.000000  \n",
       "680652           0.027710          0.556807   1.361831  \n",
       "680653           0.027710          0.556807   1.361831  \n",
       "680654           0.144083          0.831311   0.631516  \n",
       "680655           0.144083          0.831311   0.631516  \n",
       "\n",
       "[680656 rows x 12 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the columns from features\n",
    "selected_columns_zambia = zambia[['lat', 'lon', 'year']]\n",
    "\n",
    "# Concatenate selected_columns with y_preds\n",
    "zambia_preds = pd.concat([selected_columns_zambia, y_pred_zambia], axis=1)\n",
    "\n",
    "# Display the combined dataframe\n",
    "zambia_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fb04cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zambia_preds.to_feather(\"/capstone/mosaiks/repos/modeling/data/predictions/zambia_10perc_predictions.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_preds = pd.read_csv('capstone/mosaiks/repos/modeling/data/predictions/SEA_predictions_ungrouped.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476b4e-d3b5-4f79-8d2d-651d6416900a",
   "metadata": {},
   "source": [
    "### Congratulations on completing this analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks_modeling",
   "language": "python",
   "name": "mosaiks_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
