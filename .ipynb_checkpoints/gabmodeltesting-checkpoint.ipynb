{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe56655",
   "metadata": {},
   "source": [
    "# Modeling Agricultural Variables\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5b4f19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyarrow\n",
    "\n",
    "from IPython.display import display\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.axes import Axes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, r2_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import check_random_state, resample\n",
    "\n",
    "\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0591f-583f-4945-b1d2-0323ae715531",
   "metadata": {},
   "source": [
    "## Read in Data\n",
    "\n",
    "We first read in the aggregated features and ground-truth data joined in  feature_preprocessing.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3f593b6f-5740-41de-b785-3a4555428899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_averaged_features_simple_impute_modeltrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "50344858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sea_unq</th>\n",
       "      <th>index_left</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46302.000000</td>\n",
       "      <td>27.807993</td>\n",
       "      <td>-13.659357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058626</td>\n",
       "      <td>5.269229</td>\n",
       "      <td>7.640386</td>\n",
       "      <td>6.977090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>7</td>\n",
       "      <td>51611.666667</td>\n",
       "      <td>28.634660</td>\n",
       "      <td>-13.772690</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>3.387211</td>\n",
       "      <td>0.689155</td>\n",
       "      <td>7.707512</td>\n",
       "      <td>7.113191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>9</td>\n",
       "      <td>44806.714286</td>\n",
       "      <td>27.406446</td>\n",
       "      <td>-12.905428</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>2.703935</td>\n",
       "      <td>8.486127</td>\n",
       "      <td>-1.408767</td>\n",
       "      <td>7.141370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>10</td>\n",
       "      <td>44644.411765</td>\n",
       "      <td>27.381719</td>\n",
       "      <td>-12.962298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714757</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.354421</td>\n",
       "      <td>6.929734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>12</td>\n",
       "      <td>47769.000000</td>\n",
       "      <td>28.014660</td>\n",
       "      <td>-12.889357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786884</td>\n",
       "      <td>8.509161</td>\n",
       "      <td>2.852125</td>\n",
       "      <td>0.798508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>347</td>\n",
       "      <td>22038.000000</td>\n",
       "      <td>25.204660</td>\n",
       "      <td>-14.879357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.952872</td>\n",
       "      <td>8.294050</td>\n",
       "      <td>8.079163</td>\n",
       "      <td>7.021973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>348</td>\n",
       "      <td>19562.000000</td>\n",
       "      <td>24.774660</td>\n",
       "      <td>-14.799357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.642350</td>\n",
       "      <td>8.070906</td>\n",
       "      <td>8.429997</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>355</td>\n",
       "      <td>15659.538462</td>\n",
       "      <td>24.260045</td>\n",
       "      <td>-14.563972</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.508878</td>\n",
       "      <td>7.665441</td>\n",
       "      <td>8.211719</td>\n",
       "      <td>5.238174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>356</td>\n",
       "      <td>19411.000000</td>\n",
       "      <td>24.752993</td>\n",
       "      <td>-14.764357</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.608263</td>\n",
       "      <td>9.042113</td>\n",
       "      <td>8.224773</td>\n",
       "      <td>8.028346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>388</td>\n",
       "      <td>21710.181818</td>\n",
       "      <td>25.116478</td>\n",
       "      <td>-14.652084</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.939201</td>\n",
       "      <td>9.367183</td>\n",
       "      <td>8.098897</td>\n",
       "      <td>7.336848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 12044 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  sea_unq    index_left        lon        lat       0_1       0_2  \\\n",
       "0    2016.0        1  46302.000000  27.807993 -13.659357  0.000000  0.000000   \n",
       "1    2016.0        7  51611.666667  28.634660 -13.772690  0.001141  0.000329   \n",
       "2    2016.0        9  44806.714286  27.406446 -12.905428  0.000006  0.000006   \n",
       "3    2016.0       10  44644.411765  27.381719 -12.962298  0.000000  0.000000   \n",
       "4    2016.0       12  47769.000000  28.014660 -12.889357  0.000000  0.000000   \n",
       "..      ...      ...           ...        ...        ...       ...       ...   \n",
       "534  2021.0      347  22038.000000  25.204660 -14.879357  0.000000  0.000000   \n",
       "535  2021.0      348  19562.000000  24.774660 -14.799357  0.000000  0.000000   \n",
       "536  2021.0      355  15659.538462  24.260045 -14.563972  0.000038  0.000038   \n",
       "537  2021.0      356  19411.000000  24.752993 -14.764357  0.000158  0.000158   \n",
       "538  2021.0      388  21710.181818  25.116478 -14.652084  0.000076  0.000076   \n",
       "\n",
       "          0_3       0_4       0_5  ...  prop_mix  log_maize  \\\n",
       "0    0.000000  0.000000  0.000000  ...  0.000000   4.058626   \n",
       "1    0.000329  0.000329  0.000000  ...  0.181102   3.387211   \n",
       "2    0.000006  0.000006  0.000004  ...  0.069018   2.703935   \n",
       "3    0.000000  0.000000  0.000000  ...  0.000000   3.714757   \n",
       "4    0.000000  0.000000  0.000000  ...  0.000000   2.786884   \n",
       "..        ...       ...       ...  ...       ...        ...   \n",
       "534  0.000000  0.000000  0.000000  ...  0.000000   7.952872   \n",
       "535  0.000018  0.000039  0.000071  ...  0.000000   7.642350   \n",
       "536  0.001014  0.000033  0.000028  ...  0.000000   7.508878   \n",
       "537  0.000246  0.000040  0.000038  ...  0.000000   7.608263   \n",
       "538  0.000106  0.000075  0.000046  ...  0.000000   7.939201   \n",
       "\n",
       "     log_sweetpotatoes  log_groundnuts  log_soybeans  loss_ind  \\\n",
       "0             5.269229        7.640386      6.977090       0.0   \n",
       "1             0.689155        7.707512      7.113191       1.0   \n",
       "2             8.486127       -1.408767      7.141370       1.0   \n",
       "3             2.525729        3.354421      6.929734       1.0   \n",
       "4             8.509161        2.852125      0.798508       1.0   \n",
       "..                 ...             ...           ...       ...   \n",
       "534           8.294050        8.079163      7.021973       1.0   \n",
       "535           8.070906        8.429997      8.006368       1.0   \n",
       "536           7.665441        8.211719      5.238174       1.0   \n",
       "537           9.042113        8.224773      8.028346       1.0   \n",
       "538           9.367183        8.098897      7.336848       0.0   \n",
       "\n",
       "     drought_loss_ind  flood_loss_ind  animal_loss_ind  pest_loss_ind  \n",
       "0                 0.0             0.0              0.0            0.0  \n",
       "1                 1.0             0.0              0.0            0.0  \n",
       "2                 0.0             0.0              0.0            0.0  \n",
       "3                 0.0             0.0              0.0            0.0  \n",
       "4                 0.0             0.0              0.0            0.0  \n",
       "..                ...             ...              ...            ...  \n",
       "534               1.0             0.0              0.0            0.0  \n",
       "535               1.0             0.0              0.0            0.0  \n",
       "536               0.0             0.0              0.0            0.0  \n",
       "537               0.0             0.0              0.0            0.0  \n",
       "538               0.0             0.0              0.0            0.0  \n",
       "\n",
       "[539 rows x 12044 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dbe3e8ca-f209-4c76-a209-1c49d83c81a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.157999e-06</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008277e-03</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.590917e-05</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.005251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.113844e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.007540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.700000e-06</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.018616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5      0_6       0_7  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.001141  0.000329  0.000329  0.000329  0.000000  0.00000  0.000000   \n",
       "2  0.000006  0.000006  0.000006  0.000006  0.000004  0.00001  0.000014   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "            0_8       0_9      0_10  ...     999_3     999_4     999_5  \\\n",
       "0  6.157999e-06  0.000207  0.000000  ...  1.000000  1.000000  0.274676   \n",
       "1  1.008277e-03  0.001360  0.002211  ...  0.006789  0.006789  1.000000   \n",
       "2  2.590917e-05  0.000110  0.000109  ...  0.005561  0.005561  0.006391   \n",
       "3  3.113844e-07  0.000012  0.000000  ...  0.005570  0.005570  0.006739   \n",
       "4  9.700000e-06  0.000186  0.000166  ...  1.000000  1.000000  1.000000   \n",
       "\n",
       "      999_6     999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0  1.000000  0.115388  0.002708  0.001319  1.000000  1.000000  1.000000  \n",
       "1  1.000000  1.000000  0.000517  0.000343  0.000396  0.000327  0.004724  \n",
       "2  0.004212  0.003235  0.001937  0.001683  0.001970  0.002340  0.005251  \n",
       "3  0.003991  0.002857  0.001979  0.001435  0.001284  0.001814  0.007540  \n",
       "4  1.000000  0.002690  0.001603  0.000820  0.001269  0.001692  0.018616  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = grouped_features.iloc[:,5:12005]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e0640f9c-6682-4d85-866c-f7d2be3135cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_area_harv_ha', 'total_area_lost_ha', 'total_harv_kg',\n",
      "       'yield_kgha', 'frac_area_harv', 'frac_area_loss', 'area_lost_fire',\n",
      "       'maize', 'groundnuts', 'mixed_beans', 'popcorn', 'sorghum', 'soybeans',\n",
      "       'sweet_potatoes', 'bunding', 'monocrop', 'mixture', 'frac_loss_drought',\n",
      "       'frac_loss_flood', 'frac_loss_animal', 'frac_loss_pests',\n",
      "       'frac_loss_soil', 'frac_loss_fert', 'prop_till_plough',\n",
      "       'prop_till_ridge', 'prop_notill', 'prop_hand', 'prop_mono', 'prop_mix',\n",
      "       'log_maize', 'log_sweetpotatoes', 'log_groundnuts', 'log_soybeans',\n",
      "       'loss_ind', 'drought_loss_ind', 'flood_loss_ind', 'animal_loss_ind',\n",
      "       'pest_loss_ind'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "outcomes = grouped_features.iloc[:,12006:]\n",
    "\n",
    "outcomes[\"loss_ind\"].astype('category')\n",
    "outcomes[\"drought_loss_ind\"].astype('category')\n",
    "outcomes['pest_loss_ind'].astype('category')\n",
    "outcomes['animal_loss_ind'].astype('category')\n",
    "outcomes['flood_loss_ind'].astype('category')\n",
    "outcomes.head()\n",
    "\n",
    "print(outcomes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3288b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "We define a model to predict each of our outcome variables on our features for each SEA/year. The `train_and_evaluate_models` function trains and evaluates Ridge Linear Regression models for each target variable specified in the `target_columns` parameter. It handles both categorical and continuous target variables and provides the option to block sample on specific SEAs (Survey Enumeration Areas) by providing the SEA IDs to hold out for the validation set.\n",
    "\n",
    "The function works as follows:\n",
    "\n",
    "1. Read the grouped features and outcomes from a CSV file.\n",
    "2. Define a helper function `block_sampling` to perform block sampling based on the provided SEA IDs.\n",
    "3. For each target variable in `target_columns`, select the corresponding target variable data.\n",
    "4. If `block_sea_ids` is provided and not empty, perform block sampling using the `block_sampling` helper function. Otherwise, use `train_test_split` to split the data into training and testing sets.\n",
    "5. Train a Ridge Linear Regression model using RidgeCV with 5-fold cross-validation and a range of alpha values.\n",
    "6. If the target variable is categorical, calculate and print the false positive rate and AUC-ROC. If the target variable is continuous, calculate and print the estimated regularization parameter, training R2 performance, validation R2 performance, and Pearson's correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4870dc-25d2-4eab-8bae-f752633f0150",
   "metadata": {},
   "source": [
    "### Helper Function for Confusion Matrix for Categorical Variables\n",
    "`calculate_confusion_matrix`:\n",
    "This function calculates the confusion matrix for binary classification problems based on the given true labels (`y_true`), predicted values (`y_pred`), and a decision boundary (`decision_boundary`). The decision boundary is used to threshold the predicted values to obtain binary predictions.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "`y_true`: The true labels of the target variable (a pandas Series or numpy array).\n",
    "\n",
    "`y_pred`: The predicted values of the target variable (a numpy array).\n",
    "\n",
    "`decision_boundary`: A float value that serves as the threshold for classifying the predicted values into two classes (0 or 1).\n",
    "\n",
    "\n",
    "The function performs the following steps:\n",
    "1. It adjusts the predicted values by setting them to 1 if they are greater than or equal to the decision boundary, and 0 otherwise.\n",
    "2. It calculates the confusion matrix using the true labels and adjusted predicted values.\n",
    "3. Depending on the shape of the confusion matrix, it extracts the true negatives (tn), false positives (fp), false negatives (fn), and true positives (tp).\n",
    "4. If the shape of the confusion matrix is not (1, 1) or (2, 2), it raises an error.\n",
    "\n",
    "Output: The function returns the values of tn, fp, fn, and tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e5ac3bf3-e040-420d-8290-7c1aa96c7f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(y_true, y_pred, decision_boundary):\n",
    "    y_pred_adj = np.where(y_pred >= decision_boundary, 1, 0)\n",
    "    cm = confusion_matrix(y_true, y_pred_adj)\n",
    "    if cm.shape == (1, 1):\n",
    "        if y_true.iloc[0] == 0:\n",
    "            tn, fp, fn, tp = cm[0, 0], 0, 0, 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
    "    elif cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        print(\"Unexpected confusion matrix:\")\n",
    "        print(cm)\n",
    "        raise ValueError('Unexpected confusion matrix shape.')\n",
    "    return tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404d188-5f43-4ebb-a248-23fb763ebe6a",
   "metadata": {},
   "source": [
    "### Helper Function for Block Sampling on SEAs\n",
    "\n",
    "This function randomly selects a specified number of unique SEA IDs from the `grouped_features` DataFrame.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "1. n: The number of unique SEA IDs to select.\n",
    "\n",
    "2. `grouped_features`: A DataFrame containing the feature data with a column '`sea_unq`' that stores the unique SEA IDs.\n",
    "\n",
    "The function performs the following steps:\n",
    "\n",
    "1. It extracts the unique SEA IDs from the '`sea_unq`' column of the `grouped_features` DataFrame.\n",
    "\n",
    "2. It randomly selects n SEA IDs from the unique SEA IDs without replacement.\n",
    "\n",
    "Output: The function returns a numpy array of the randomly selected SEA IDs.\n",
    "\n",
    "These helper functions are used in the main model as follows:\n",
    "\n",
    "`calculate_confusion_matrix` is used to calculate the confusion matrix for the categorical target variables. It is called in the `train_and_evaluate_models` function to compute the false positive rate and AUC-ROC for different decision boundaries.\n",
    "\n",
    "`randomly_select_seas` is not used in the current implementation of the main model. However, it can be used to randomly select SEA IDs if you want to implement a custom sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2f762185-2e35-48c4-b203-cd5b5c7cd7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomly_select_seas(n, grouped_features):\n",
    "    unique_seas = grouped_features['sea_unq'].unique()\n",
    "    selected_seas = np.random.choice(unique_seas, n, replace=False)\n",
    "    return selected_seas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f34a8-0a0a-471f-9aba-b44699b0cb4d",
   "metadata": {},
   "source": [
    "## Cross-Validator Custom Class\n",
    "\n",
    "This custom cross-validator class, BlockSamplingCV, inherits from the BaseCrossValidator class in scikit-learn. It is designed to perform block sampling for cross-validation, holding out specific groups of observations (in this case, SEA IDs) during each split. This ensures that all observations with the same SEA ID are either in the training set or the test set, but not both.\n",
    "\n",
    "Here's a detailed explanation of the class:\n",
    "\n",
    "__init__(self, n_splits=5, n_seas_to_hold_out=10, sea_ids=None, random_state=None):\n",
    "The constructor takes the following arguments:\n",
    "\n",
    "n_splits: The number of cross-validation splits (default is 5).\n",
    "n_seas_to_hold_out: The number of SEAs to hold out in each cross-validation split (default is 10).\n",
    "sea_ids: A list or array of SEA IDs corresponding to the rows of the dataset (default is None).\n",
    "random_state: An integer seed or a RandomState instance for reproducible results (default is None).\n",
    "The constructor initializes the class with these arguments.\n",
    "\n",
    "_iter_test_indices(self, X=None, y=None, groups=None):\n",
    "This method generates test indices for each cross-validation split. It takes the following optional arguments:\n",
    "\n",
    "X: Feature matrix (not used in this method but included for compatibility with scikit-learn).\n",
    "y: Target variable (not used in this method but included for compatibility with scikit-learn).\n",
    "groups: Group labels for the samples used to ensure that each group is either entirely in the training or test set (not used in this method but included for compatibility with scikit-learn).\n",
    "The method performs the following steps:\n",
    "\n",
    "a. It calculates the total number of samples and extracts the unique SEA IDs from the sea_ids attribute.\n",
    "b. It initializes a random number generator with the specified random_state.\n",
    "c. For each split, it randomly selects a set of n_seas_to_hold_out SEA IDs without replacement.\n",
    "d. It finds the indices of the observations with the selected SEA IDs and yields them as test indices for the current split.\n",
    "\n",
    "The BlockSamplingCV class is designed to perform cross-validation with block sampling, where groups of observations (in this case, SEA IDs) are held out together during each split. This is useful because it ensures that all observations with the same SEA ID are either in the training set or the test set, but not both. This can help prevent leakage of information between the training and test sets when observations with the same SEA ID are strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "103c6d0b-6ef4-45cf-a477-748618b6d4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the arguments as a dictionary\n",
    "args = {\n",
    "    'target_columns': ['total_area_harv_ha', 'total_area_lost_ha', 'yield_kgha', 'frac_area_harv', 'frac_area_loss',\n",
    "                       'maize', 'frac_loss_drought', 'prop_till_plough', 'prop_mono'],\n",
    "    'test_size': 0.1,\n",
    "    'categorical_columns':['loss_ind','drought_loss_ind', 'flood_loss_ind','animal_loss_ind','pest_loss_ind'],\n",
    "    'decision_boundaries': [0.3,0.5,0.7],\n",
    "    'sea_ids': grouped_features['sea_unq'],\n",
    "    'validation_size' : 0.1,\n",
    "    'random_state': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d5ea5f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(args):\n",
    "    target_columns = args['target_columns']\n",
    "    test_size = args.get('test_size', 0.1)\n",
    "    categorical_columns = args['categorical_columns']\n",
    "    decision_boundaries = args['decision_boundaries']\n",
    "    sea_ids = args['sea_ids']\n",
    "    validation_size = args.get('validation_size', 0.1)\n",
    "    random_state = args.get('random_state', False)\n",
    "    \n",
    "    \n",
    "    grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_averaged_features_simple_impute_modeltrain.csv\")\n",
    "\n",
    "    features = grouped_features.iloc[:, 5:12005]\n",
    "    outcomes = grouped_features.iloc[:, 12006:]\n",
    "    \n",
    "    \n",
    "    # Initialize an empty DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame(columns=['target_column', 'train_score', 'val_score', 'pearson_coeff'])\n",
    "    # Initialize an empty DataFrame to store groundtruth\n",
    "    models = {}\n",
    "    X_trains = {}\n",
    "    X_tests = {}\n",
    "    y_trains = pd.DataFrame()\n",
    "    y_tests = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    print(f\"\\nRunning model with the following parameters:\")\n",
    "    print(f\"Target columns: {target_columns}\")\n",
    "    print(f\"Test size: {test_size}\", f\"Validation size: {validation_size}\")\n",
    "    print(f\"Random State: {random_state}\")\n",
    "\n",
    "    for target_column in target_columns:\n",
    "        \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, outcomes[target_column], test_size=test_size, random_state = random_state)\n",
    "            # Split the training data again to create a validation set\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size, random_state = random_state)\n",
    "            \n",
    "            X_trains[target_column] = X_train\n",
    "            X_tests[target_column] = X_test\n",
    "            y_trains[target_column] = y_train\n",
    "            y_tests[target_column] = y_test\n",
    "\n",
    "            cv = 5\n",
    "            ridge_cv = RidgeCV(cv=cv, alphas=np.logspace(-8, 8, base=10, num=75))\n",
    "            ridge_cv.fit(X_train, y_train)\n",
    "            \n",
    "            models[target_column] = ridge_cv\n",
    "            \n",
    "            # Make predictions on the training and validation data\n",
    "            y_val_pred = ridge_cv.predict(X_val)\n",
    "            y_train_pred = ridge_cv.predict(X_train)\n",
    "    \n",
    "            if target_column in categorical_columns:\n",
    "                for decision_boundary in decision_boundaries:\n",
    "                    # Calculate confusion matrix\n",
    "                    tn, fp, fn, tp = calculate_confusion_matrix(y_val, y_val_pred, decision_boundary)\n",
    "\n",
    "                # Calculate the false positive rate\n",
    "                    false_positive_rate = fp / (fp + tn)\n",
    "\n",
    "                # Calculate AUC-ROC\n",
    "                    auc_roc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "                    print(f\"Target variable: {target_column} (Categorical)\")\n",
    "                    print(f\"Decision boundary: {decision_boundary}\")\n",
    "                    print(f\"False positive rate: {false_positive_rate:0.2f}\")\n",
    "                    print(f\"AUC-ROC: {auc_roc:0.2f}\")\n",
    "                    print()\n",
    "            else:\n",
    "                # Calculate Pearson's correlation coefficient\n",
    "                pearson_coeff, _ = pearsonr(y_val, y_val_pred)\n",
    "\n",
    "                # Calculate training R squared\n",
    "                train_r_squared = ridge_cv.score(X_train, y_train)\n",
    "\n",
    "                # Calculate validation R squared\n",
    "                val_r_squared = ridge_cv.score(X_val, y_val)\n",
    "                \n",
    "                metrics_df = metrics_df.append({\n",
    "                'target_column': target_column,\n",
    "                'train_score': train_r_squared,\n",
    "                'val_score': val_r_squared,\n",
    "                'pearson_coeff': pearson_coeff}, ignore_index=True)\n",
    "                    \n",
    "                print()\n",
    "                print(f\"Target variable: {target_column}\")\n",
    "                print(f\"Estimated regularization parameter: {ridge_cv.alpha_}\")\n",
    "                print(f\"Training R2 performance: {train_r_squared:0.2f}\")\n",
    "                print(f\"Validation R2 performance: {val_r_squared:0.2f}\")\n",
    "                print(f\"Pearson's correlation coefficient: {pearson_coeff:0.2f}\")\n",
    "                print()\n",
    "                \n",
    "\n",
    "    return X_trains, X_tests, y_trains, y_tests, metrics_df, models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414f7ab-c9a8-4788-be39-7a2762cd58fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model with the following parameters:\n",
      "Target columns: ['total_area_harv_ha', 'total_area_lost_ha', 'yield_kgha', 'frac_area_harv', 'frac_area_loss', 'maize', 'frac_loss_drought', 'prop_till_plough', 'prop_mono']\n",
      "Test size: 0.1 Validation size: 0.1\n",
      "Random State: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1377110/4270161684.py:79: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: total_area_harv_ha\n",
      "Estimated regularization parameter: 4.45295850994266\n",
      "Training R2 performance: 0.71\n",
      "Validation R2 performance: 0.46\n",
      "Pearson's correlation coefficient: 0.69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1377110/4270161684.py:79: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: total_area_lost_ha\n",
      "Estimated regularization parameter: 2.706652070033247\n",
      "Training R2 performance: 0.75\n",
      "Validation R2 performance: 0.50\n",
      "Pearson's correlation coefficient: 0.72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1377110/4270161684.py:79: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: yield_kgha\n",
      "Estimated regularization parameter: 1.6451905877536674\n",
      "Training R2 performance: 0.74\n",
      "Validation R2 performance: 0.62\n",
      "Pearson's correlation coefficient: 0.80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1377110/4270161684.py:79: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_area_harv\n",
      "Estimated regularization parameter: 4.45295850994266\n",
      "Training R2 performance: 0.64\n",
      "Validation R2 performance: 0.46\n",
      "Pearson's correlation coefficient: 0.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1377110/4270161684.py:79: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable: frac_area_loss\n",
      "Estimated regularization parameter: 4.45295850994266\n",
      "Training R2 performance: 0.64\n",
      "Validation R2 performance: 0.46\n",
      "Pearson's correlation coefficient: 0.71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_trains, X_tests, y_trains, y_tests, metrics_df, models  = train_and_evaluate_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af40d7",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f42e76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred_train = pd.DataFrame()\n",
    "r2_train = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Get the training data for the target column\n",
    "    X_train_column = X_trains[target_column]\n",
    "    y_train_column = y_trains[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred__train_column = np.maximum(model.predict(X_train_column), 0)\n",
    "    \n",
    "    # Compute the R2 score for the target column\n",
    "    r2_train_column = r2_score(y_train_column, y_pred_train_column)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred_train[target_column] = y_pred_train_column\n",
    "    r2_train[target_column] = [r2_train_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2dfcab",
   "metadata": {},
   "source": [
    "### Visualize Performance of Train Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de344f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of variable names from the dataframes\n",
    "variable_names = list(y_pred_train.columns)\n",
    "\n",
    "# create a container widget to hold the dropdown and the plot\n",
    "container = widgets.VBox(children=[variable_dropdown])\n",
    "\n",
    "# Define a function to update the plot based on the selected variable\n",
    "def update_plot_train(variable):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        # Create the scatterplot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(y_pred_train[variable], y_trains[variable])\n",
    "        ax.axline([0, 0], [1, 1], c=\"k\")\n",
    "\n",
    "        # Extract the R2 value from the r2_train dataframe\n",
    "        r2_value = r2_train[variable]\n",
    "        r2_value = round(r2_value, 2)\n",
    "\n",
    "        # Set the title with the R2 value and selected variable\n",
    "        plt.title(f\"Model applied to train data n = {len(y_trains)}, R$^2$ = {r2_value}\",\n",
    "          fontsize=12, y=1)\n",
    "\n",
    "        # Set x and y axis labels\n",
    "        ax.set_xlabel(\"Predicted\", fontsize=15)\n",
    "        ax.set_ylabel(\"Ground Truth\", fontsize=15)\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "# call the update_plot function with the initial value of the dropdown\n",
    "plot_output = widgets.Output()\n",
    "update_plot_train(variable_dropdown.value)\n",
    "container.children = [variable_dropdown, plot_output]\n",
    "\n",
    "# set up the interaction between the dropdown and the plot\n",
    "def dropdown_eventhandler(change):\n",
    "    variable = change.new\n",
    "    update_plot(variable)\n",
    "\n",
    "variable_dropdown.observe(dropdown_eventhandler, names='value')\n",
    "\n",
    "# display the dropdown and the plot\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630faaf",
   "metadata": {},
   "source": [
    "### Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred_test = pd.DataFrame()\n",
    "r2_test = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Get the training data for the target column\n",
    "    X_test_column = X_tests[target_column]\n",
    "    y_test_column = y_tests[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred__test_column = np.maximum(model.predict(X_test_column), 0)\n",
    "    \n",
    "    # Compute the R2 score for the target column\n",
    "    r2_test_column = r2_score(y_test_column, y_pred_test_column)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred_test[target_column] = y_pred_test_column\n",
    "    r2_test[target_column] = [r2_test_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65097177",
   "metadata": {},
   "source": [
    "### Visualize Performance of Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b606a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of variable names from the dataframes\n",
    "variable_names = list(y_pred_test.columns)\n",
    "\n",
    "# create a container widget to hold the dropdown and the plot\n",
    "container = widgets.VBox(children=[variable_dropdown])\n",
    "\n",
    "# Define a function to update the plot based on the selected variable\n",
    "def update_plot_test(variable):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        # Create the scatterplot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(y_pred_test[variable], y_tests[variable])\n",
    "        ax.axline([0, 0], [1, 1], c=\"k\")\n",
    "\n",
    "        # Extract the R2 value from the r2_train dataframe\n",
    "        r2_value = r2_test[variable]\n",
    "        r2_value = round(r2_value, 2)\n",
    "\n",
    "        # Set the title with the R2 value and selected variable\n",
    "        plt.title(f\"Model applied to test data n = {len(y_tests)}, R$^2$ = {r2_value}\",\n",
    "          fontsize=12, y=1)\n",
    "\n",
    "        # Set x and y axis labels\n",
    "        ax.set_xlabel(\"Predicted\", fontsize=15)\n",
    "        ax.set_ylabel(\"Ground Truth\", fontsize=15)\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "# call the update_plot function with the initial value of the dropdown\n",
    "plot_output = widgets.Output()\n",
    "update_plot_test(variable_dropdown.value)\n",
    "container.children = [variable_dropdown, plot_output]\n",
    "\n",
    "# set up the interaction between the dropdown and the plot\n",
    "def dropdown_eventhandler(change):\n",
    "    variable = change.new\n",
    "    update_plot(variable)\n",
    "\n",
    "variable_dropdown.observe(dropdown_eventhandler, names='value')\n",
    "\n",
    "# display the dropdown and the plot\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350506a9",
   "metadata": {},
   "source": [
    "### Apply Model to Ungrouped SEA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "df1f04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ungrouped = pd.read_feather(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_ungroup_features_simple_impute.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1098e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>0.532948</td>\n",
       "      <td>0.469076</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>0.494736</td>\n",
       "      <td>0.474246</td>\n",
       "      <td>0.417571</td>\n",
       "      <td>0.135569</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.156783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021665</td>\n",
       "      <td>0.324015</td>\n",
       "      <td>0.490193</td>\n",
       "      <td>0.392582</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>0.718919</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>0.673485</td>\n",
       "      <td>0.631725</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.052683</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72278</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72279</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72280</th>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.004205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72281</th>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.004801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72282</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.014430</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.012770</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.011526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72283 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0_1       0_2       0_3       0_4       0_5       0_6       0_7  \\\n",
       "0      0.001143  0.000751  0.000000  0.000346  0.000000  0.000000  0.000000   \n",
       "1      0.001143  0.000000  0.000776  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.001143  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.001143  0.000751  0.000776  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000751  0.000776  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "72278  0.001143  0.003581  0.003867  0.001019  0.001521  0.000000  0.002637   \n",
       "72279  0.000000  0.000000  0.000000  0.000000  0.000000  0.002137  0.003117   \n",
       "72280  0.002399  0.000751  0.000000  0.000000  0.001860  0.002130  0.002149   \n",
       "72281  0.003386  0.000000  0.000000  0.000000  0.000923  0.002777  0.003057   \n",
       "72282  0.000022  0.000876  0.000507  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            0_8       0_9      0_10  ...     999_3     999_4     999_5  \\\n",
       "0      0.000000  0.000000  0.001020  ...  0.034016  0.071989  0.532948   \n",
       "1      0.000000  0.000002  0.000308  ...  0.043530  0.494736  0.474246   \n",
       "2      0.000000  0.000234  0.000039  ...  0.021665  0.324015  0.490193   \n",
       "3      0.000000  0.000657  0.000894  ...  0.043530  0.718919  0.645601   \n",
       "4      0.000000  0.000002  0.001360  ...  0.043530  1.000000  0.679722   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "72278  0.003194  0.004948  0.005988  ...  0.008950  0.013373  0.009622   \n",
       "72279  0.004004  0.004732  0.000000  ...  0.013883  0.014116  0.009862   \n",
       "72280  0.000000  0.004094  0.006669  ...  0.012160  0.011552  0.013037   \n",
       "72281  0.004031  0.000000  0.000000  ...  0.005391  0.004631  0.007071   \n",
       "72282  0.000000  0.000000  0.000000  ...  0.019932  0.014430  0.013566   \n",
       "\n",
       "          999_6     999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0      0.469076  0.007786  0.006779  0.004811  0.001675  0.029891  0.033437  \n",
       "1      0.417571  0.135569  0.003355  0.004876  0.003185  0.187867  0.156783  \n",
       "2      0.392582  0.325692  0.004587  0.002309  0.002191  0.002333  0.033437  \n",
       "3      0.673485  0.631725  0.004959  0.001359  0.001627  0.052683  0.033437  \n",
       "4      1.000000  0.324600  0.006641  0.003481  0.003071  0.004119  1.000000  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "72278  0.008655  0.003418  0.001569  0.000234  0.000054  0.000039  0.000276  \n",
       "72279  0.002694  0.000432  0.000132  0.000086  0.000063  0.000060  0.033437  \n",
       "72280  0.007480  0.002309  0.000083  0.000194  0.000100  0.000016  0.004205  \n",
       "72281  0.001832  0.001039  0.000223  0.000081  0.000324  0.001030  0.004801  \n",
       "72282  0.012770  0.008013  0.003928  0.001690  0.000192  0.002576  0.011526  \n",
       "\n",
       "[72283 rows x 12000 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features_ungrouped.iloc[:, 2:12002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8820a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred_column = np.maximum(model.predict(features), 0)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred[target_column] = y_pred_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5818d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns from features\n",
    "selected_columns = features_ungrouped[['lat', 'lon', 'year']]\n",
    "\n",
    "# Concatenate selected_columns with y_preds\n",
    "combined_df = pd.concat([selected_columns, y_pred], axis=1)\n",
    "\n",
    "# Display the combined dataframe\n",
    "combined_df\n",
    "combined_df.to_csv(\"/capstone/mosaiks/repos/modeling/data/predictions/SEA_predictions_ungrouped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82032b7e",
   "metadata": {},
   "source": [
    "## Apply Model to Zambia 10% Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a71096b5-bd08-42c2-854d-655f56b6b2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zambia = pd.read_feather(\"/capstone/mosaiks/repos/modeling/data/model_directory/zambia_10percent_features_simple_impute_modelpredict.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4b2a3ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.005276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.075393</td>\n",
       "      <td>0.056347</td>\n",
       "      <td>0.056281</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.075393</td>\n",
       "      <td>0.056347</td>\n",
       "      <td>0.056281</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.035491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5       0_6       0_7  \\\n",
       "0  0.002994  0.003749  0.002417  0.001449  0.001208  0.002577  0.002151   \n",
       "1  0.002030  0.000743  0.000000  0.000000  0.000000  0.000007  0.000035   \n",
       "2  0.001111  0.003541  0.003555  0.001752  0.001398  0.001469  0.002361   \n",
       "3  0.001111  0.000743  0.000706  0.000395  0.000185  0.000202  0.000298   \n",
       "4  0.001111  0.000743  0.000706  0.000395  0.000185  0.000202  0.000298   \n",
       "\n",
       "        0_8       0_9      0_10  ...     999_3     999_4     999_5     999_6  \\\n",
       "0  0.003231  0.004019  0.001838  ...  0.000653  0.001410  0.001619  0.000461   \n",
       "1  0.000189  0.000664  0.002471  ...  0.012280  0.009524  0.006202  0.004043   \n",
       "2  0.002198  0.003063  0.005263  ...  0.001252  0.004579  0.003310  0.002417   \n",
       "3  0.000640  0.001207  0.004661  ...  0.055707  0.075393  0.056347  0.056281   \n",
       "4  0.000640  0.004295  0.001444  ...  0.055707  0.075393  0.056347  0.056281   \n",
       "\n",
       "      999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0  0.000611  0.000226  0.000138  0.000562  0.000503  0.000406  \n",
       "1  0.003652  0.002408  0.001475  0.000435  0.000302  0.005276  \n",
       "2  0.001392  0.001687  0.000812  0.000241  0.000365  0.000645  \n",
       "3  0.036438  0.004060  0.008108  0.000633  0.000496  0.000598  \n",
       "4  0.036438  0.004060  0.000187  0.002911  0.004108  0.035491  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zambia_features = zambia.iloc[:,2:12002]\n",
    "zambia_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "591764c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for storing the predicted values and R2 scores\n",
    "y_pred = pd.DataFrame()\n",
    "\n",
    "# Iterate over the keys in models dictionary\n",
    "for target_column in models.keys():\n",
    "    # Get the corresponding trained model for the target column\n",
    "    model = models[target_column]\n",
    "    \n",
    "    # Make predictions for the target column\n",
    "    y_pred_column = np.maximum(model.predict(zambia_features), 0)\n",
    "    \n",
    "    # Store the predicted values and R2 score in their respective dictionaries\n",
    "    y_pred[target_column] = y_pred_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c8d9c55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>maize</th>\n",
       "      <th>frac_loss_drought</th>\n",
       "      <th>prop_till_plough</th>\n",
       "      <th>prop_mono</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1735.397458</td>\n",
       "      <td>0.813706</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>1722.112146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447.061644</td>\n",
       "      <td>256.229862</td>\n",
       "      <td>2331.179534</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>2405.568184</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.400076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1206.135845</td>\n",
       "      <td>2076.177727</td>\n",
       "      <td>1970.026901</td>\n",
       "      <td>0.587526</td>\n",
       "      <td>0.412474</td>\n",
       "      <td>1764.996532</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>0.100866</td>\n",
       "      <td>0.471011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670.181614</td>\n",
       "      <td>898.956082</td>\n",
       "      <td>1155.632228</td>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>1093.192949</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.632547</td>\n",
       "      <td>0.714045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>588.095553</td>\n",
       "      <td>878.123450</td>\n",
       "      <td>1066.901627</td>\n",
       "      <td>0.603163</td>\n",
       "      <td>0.396837</td>\n",
       "      <td>1051.265307</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.513613</td>\n",
       "      <td>0.712723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_area_harv_ha  total_area_lost_ha   yield_kgha  frac_area_harv  \\\n",
       "0            0.000000            0.000000  1735.397458        0.813706   \n",
       "1          447.061644          256.229862  2331.179534        0.935772   \n",
       "2         1206.135845         2076.177727  1970.026901        0.587526   \n",
       "3          670.181614          898.956082  1155.632228        0.622778   \n",
       "4          588.095553          878.123450  1066.901627        0.603163   \n",
       "\n",
       "   frac_area_loss        maize  frac_loss_drought  prop_till_plough  prop_mono  \n",
       "0        0.186294  1722.112146           0.000000          0.000000   1.073670  \n",
       "1        0.064228  2405.568184           0.046058          0.550284   0.400076  \n",
       "2        0.412474  1764.996532           0.053027          0.100866   0.471011  \n",
       "3        0.377222  1093.192949           0.096518          0.632547   0.714045  \n",
       "4        0.396837  1051.265307           0.052540          0.513613   0.712723  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "29dd32e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>maize</th>\n",
       "      <th>frac_loss_drought</th>\n",
       "      <th>prop_till_plough</th>\n",
       "      <th>prop_mono</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1735.397458</td>\n",
       "      <td>0.813706</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>1722.112146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>447.061644</td>\n",
       "      <td>256.229862</td>\n",
       "      <td>2331.179534</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>2405.568184</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.400076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1206.135845</td>\n",
       "      <td>2076.177727</td>\n",
       "      <td>1970.026901</td>\n",
       "      <td>0.587526</td>\n",
       "      <td>0.412474</td>\n",
       "      <td>1764.996532</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>0.100866</td>\n",
       "      <td>0.471011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>670.181614</td>\n",
       "      <td>898.956082</td>\n",
       "      <td>1155.632228</td>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>1093.192949</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.632547</td>\n",
       "      <td>0.714045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.053257</td>\n",
       "      <td>22.730588</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>588.095553</td>\n",
       "      <td>878.123450</td>\n",
       "      <td>1066.901627</td>\n",
       "      <td>0.603163</td>\n",
       "      <td>0.396837</td>\n",
       "      <td>1051.265307</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.513613</td>\n",
       "      <td>0.712723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680651</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.193086</td>\n",
       "      <td>1.145336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>352.100772</td>\n",
       "      <td>0.165099</td>\n",
       "      <td>1.075864</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680652</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>102.839855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3497.057246</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.186295</td>\n",
       "      <td>4081.543865</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.556807</td>\n",
       "      <td>1.361831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680653</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>102.839855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3497.057246</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.186295</td>\n",
       "      <td>4081.543865</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.556807</td>\n",
       "      <td>1.361831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680654</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>768.755230</td>\n",
       "      <td>983.689961</td>\n",
       "      <td>987.401820</td>\n",
       "      <td>0.665632</td>\n",
       "      <td>0.334368</td>\n",
       "      <td>1079.121809</td>\n",
       "      <td>0.144083</td>\n",
       "      <td>0.831311</td>\n",
       "      <td>0.631516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680655</th>\n",
       "      <td>-17.473257</td>\n",
       "      <td>26.080588</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>768.755230</td>\n",
       "      <td>983.689961</td>\n",
       "      <td>987.401820</td>\n",
       "      <td>0.665632</td>\n",
       "      <td>0.334368</td>\n",
       "      <td>1079.121809</td>\n",
       "      <td>0.144083</td>\n",
       "      <td>0.831311</td>\n",
       "      <td>0.631516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680656 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lat        lon    year  total_area_harv_ha  total_area_lost_ha  \\\n",
       "0      -15.053257  22.730588  2019.0            0.000000            0.000000   \n",
       "1      -15.053257  22.730588  2018.0          447.061644          256.229862   \n",
       "2      -15.053257  22.730588  2022.0         1206.135845         2076.177727   \n",
       "3      -15.053257  22.730588  2023.0          670.181614          898.956082   \n",
       "4      -15.053257  22.730588  2015.0          588.095553          878.123450   \n",
       "...           ...        ...     ...                 ...                 ...   \n",
       "680651 -17.473257  26.080588  2016.0            0.000000            0.000000   \n",
       "680652 -17.473257  26.080588  2015.0          102.839855            0.000000   \n",
       "680653 -17.473257  26.080588  2015.0          102.839855            0.000000   \n",
       "680654 -17.473257  26.080588  2018.0          768.755230          983.689961   \n",
       "680655 -17.473257  26.080588  2018.0          768.755230          983.689961   \n",
       "\n",
       "         yield_kgha  frac_area_harv  frac_area_loss        maize  \\\n",
       "0       1735.397458        0.813706        0.186294  1722.112146   \n",
       "1       2331.179534        0.935772        0.064228  2405.568184   \n",
       "2       1970.026901        0.587526        0.412474  1764.996532   \n",
       "3       1155.632228        0.622778        0.377222  1093.192949   \n",
       "4       1066.901627        0.603163        0.396837  1051.265307   \n",
       "...             ...             ...             ...          ...   \n",
       "680651   596.193086        1.145336        0.000000   352.100772   \n",
       "680652  3497.057246        0.813705        0.186295  4081.543865   \n",
       "680653  3497.057246        0.813705        0.186295  4081.543865   \n",
       "680654   987.401820        0.665632        0.334368  1079.121809   \n",
       "680655   987.401820        0.665632        0.334368  1079.121809   \n",
       "\n",
       "        frac_loss_drought  prop_till_plough  prop_mono  \n",
       "0                0.000000          0.000000   1.073670  \n",
       "1                0.046058          0.550284   0.400076  \n",
       "2                0.053027          0.100866   0.471011  \n",
       "3                0.096518          0.632547   0.714045  \n",
       "4                0.052540          0.513613   0.712723  \n",
       "...                   ...               ...        ...  \n",
       "680651           0.165099          1.075864   0.000000  \n",
       "680652           0.027710          0.556807   1.361831  \n",
       "680653           0.027710          0.556807   1.361831  \n",
       "680654           0.144083          0.831311   0.631516  \n",
       "680655           0.144083          0.831311   0.631516  \n",
       "\n",
       "[680656 rows x 12 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the columns from features\n",
    "selected_columns = zambia[['lat', 'lon', 'year']]\n",
    "\n",
    "# Concatenate selected_columns with y_preds\n",
    "combined_df = pd.concat([selected_columns, y_pred], axis=1)\n",
    "\n",
    "# Display the combined dataframe\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fb04cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"/capstone/mosaiks/repos/modeling/data/predictions/zambia_10perc_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476b4e-d3b5-4f79-8d2d-651d6416900a",
   "metadata": {},
   "source": [
    "### Congratulations on completing this analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks_modeling",
   "language": "python",
   "name": "mosaiks_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
